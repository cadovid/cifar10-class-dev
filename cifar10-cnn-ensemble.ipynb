{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_CLASES = 10\n",
    "EPOCHS = 200\n",
    "NUM_NETS = 1       # Solo una red para hacer pruebas\n",
    "VERBOSE = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Carga de los datos\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Guardamos x_test original para imprimir figuras\n",
    "xx_test = x_test\n",
    "\n",
    "# Guardamos la codificacion de clases explicitas inicial, nos hará falta\n",
    "yy_test = y_test\n",
    "\n",
    "x_train = np.reshape(x_train, (50000, 32, 32, 3))\t\t  ## para CNN\n",
    "x_test = np.reshape(x_test, (10000, 32, 32, 3))\t\t    ## para CNN\n",
    "\n",
    "# Normalizamos los valores de píxeles del rango 0-255 a 0.0-1.0\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Para problemas Multiclase conviene usar One Hot Encoding (y categorical_crossentropy+softmax)\n",
    "# Cada valor de clase (0-9) se convierte en un vector de 0s y un 1\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASES)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_72 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_80 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_96 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_104 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_112 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_120 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_128 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_136 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_144 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_152 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# Creamos el conjunto de modelos a entrenar\n",
    "model = [0] * NUM_NETS\n",
    "\n",
    "for j in range(NUM_NETS):\n",
    "    model[j] = Sequential()\n",
    "    # model[j].add(Conv2D(320, (2, 2), padding='same', input_shape=(32, 32, 3)))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Conv2D(320, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Conv2D(320, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Conv2D(640, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.1))\n",
    "    # model[j].add(Conv2D(640, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.1))\n",
    "    # model[j].add(Conv2D(640, (2, 2), strides=2, padding='same'))\n",
    "    # model[j].add(Conv2D(960, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.2))\n",
    "    # model[j].add(Conv2D(960, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.2))\n",
    "    # model[j].add(Conv2D(960, (2, 2), strides=2, padding='same'))\n",
    "    # model[j].add(Conv2D(1280, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.3))\n",
    "    # model[j].add(Conv2D(1280, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.3))\n",
    "    # model[j].add(Conv2D(1280, (2, 2), strides=2, padding='same'))\n",
    "    # model[j].add(Conv2D(1600, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.4))\n",
    "    # model[j].add(Conv2D(1600, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.4))\n",
    "    # model[j].add(Conv2D(1600, (2, 2), strides=2, padding='same'))\n",
    "    # model[j].add(Conv2D(1920, (2, 2), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.5))\n",
    "    # model[j].add(Conv2D(1920, (1, 1), padding='same'))\n",
    "    # model[j].add(LeakyReLU(alpha=0.05))\n",
    "    # model[j].add(Dropout(0.5))\n",
    "    # model[j].add(Flatten())\n",
    "    # model[j].add(Dense(NUM_CLASES, activation='softmax'))\n",
    "\n",
    "    model[j].add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same', input_shape=(32, 32, 3)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(MaxPooling2D((2, 2)))\n",
    "    model[j].add(Dropout(0.2))\n",
    "    model[j].add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(MaxPooling2D((2, 2)))\n",
    "    model[j].add(Dropout(0.3))\n",
    "    model[j].add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(MaxPooling2D((2, 2)))\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(MaxPooling2D((2, 2)))\n",
    "    model[j].add(Dropout(0.5))\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)))\n",
    "    model[j].add(Dropout(0.5))\n",
    "    model[j].add(Dense(NUM_CLASES, activation='softmax'))\n",
    "\n",
    "    model[j].summary()\n",
    "    model[j].compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET  1\n",
      "Epoch 1/100\n",
      "196/196 - 5s - loss: 2.5649 - accuracy: 0.1351 - val_loss: 2.3168 - val_accuracy: 0.2013\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 1.9926 - accuracy: 0.3154 - val_loss: 1.8345 - val_accuracy: 0.4024\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.7215 - accuracy: 0.4397 - val_loss: 1.6152 - val_accuracy: 0.4862\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.5234 - accuracy: 0.5297 - val_loss: 1.3574 - val_accuracy: 0.5883\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.3852 - accuracy: 0.5833 - val_loss: 1.2657 - val_accuracy: 0.6160\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.2866 - accuracy: 0.6175 - val_loss: 1.2314 - val_accuracy: 0.6331\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.2058 - accuracy: 0.6507 - val_loss: 1.1172 - val_accuracy: 0.6754\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.1337 - accuracy: 0.6761 - val_loss: 1.0646 - val_accuracy: 0.6972\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.0722 - accuracy: 0.6978 - val_loss: 0.9990 - val_accuracy: 0.7228\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.0193 - accuracy: 0.7143 - val_loss: 0.9575 - val_accuracy: 0.7355\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 0.9818 - accuracy: 0.7296 - val_loss: 0.9953 - val_accuracy: 0.7243\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 0.9525 - accuracy: 0.7434 - val_loss: 0.9041 - val_accuracy: 0.7573\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 0.9049 - accuracy: 0.7592 - val_loss: 0.8637 - val_accuracy: 0.7686\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 0.8848 - accuracy: 0.7654 - val_loss: 0.8608 - val_accuracy: 0.7739\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 0.8521 - accuracy: 0.7789 - val_loss: 0.9140 - val_accuracy: 0.7540\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 0.8303 - accuracy: 0.7849 - val_loss: 0.8058 - val_accuracy: 0.7898\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.8101 - accuracy: 0.7916 - val_loss: 0.8127 - val_accuracy: 0.7914\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.7854 - accuracy: 0.8011 - val_loss: 0.7961 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.7675 - accuracy: 0.8084 - val_loss: 0.8236 - val_accuracy: 0.7902\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.7519 - accuracy: 0.8132 - val_loss: 0.7706 - val_accuracy: 0.8052\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.7323 - accuracy: 0.8199 - val_loss: 0.7650 - val_accuracy: 0.8074\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.7346 - accuracy: 0.8208 - val_loss: 0.7385 - val_accuracy: 0.8195\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.7149 - accuracy: 0.8280 - val_loss: 0.7519 - val_accuracy: 0.8128\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.7038 - accuracy: 0.8306 - val_loss: 0.7713 - val_accuracy: 0.8113\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.6942 - accuracy: 0.8345 - val_loss: 0.7617 - val_accuracy: 0.8217\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.6832 - accuracy: 0.8407 - val_loss: 0.7537 - val_accuracy: 0.8224\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.6666 - accuracy: 0.8452 - val_loss: 0.7688 - val_accuracy: 0.8197\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.6663 - accuracy: 0.8464 - val_loss: 0.7405 - val_accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.6551 - accuracy: 0.8498 - val_loss: 0.7384 - val_accuracy: 0.8295\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.6519 - accuracy: 0.8518 - val_loss: 0.7740 - val_accuracy: 0.8208\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.6426 - accuracy: 0.8566 - val_loss: 0.7135 - val_accuracy: 0.8386\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.6355 - accuracy: 0.8600 - val_loss: 0.7832 - val_accuracy: 0.8193\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.6341 - accuracy: 0.8596 - val_loss: 0.7452 - val_accuracy: 0.8372\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.6250 - accuracy: 0.8633 - val_loss: 0.7369 - val_accuracy: 0.8365\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.6214 - accuracy: 0.8647 - val_loss: 0.7587 - val_accuracy: 0.8286\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.6190 - accuracy: 0.8676 - val_loss: 0.7407 - val_accuracy: 0.8355\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.6111 - accuracy: 0.8704 - val_loss: 0.7390 - val_accuracy: 0.8346\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.6017 - accuracy: 0.8736 - val_loss: 0.7742 - val_accuracy: 0.8355\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6082 - accuracy: 0.8697 - val_loss: 0.7287 - val_accuracy: 0.8464\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.5950 - accuracy: 0.8754 - val_loss: 0.7400 - val_accuracy: 0.8440\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6054 - accuracy: 0.8712 - val_loss: 0.7089 - val_accuracy: 0.8474\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.5925 - accuracy: 0.8775 - val_loss: 0.7049 - val_accuracy: 0.8477\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.5854 - accuracy: 0.8800 - val_loss: 0.7245 - val_accuracy: 0.8440\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.5845 - accuracy: 0.8807 - val_loss: 0.7317 - val_accuracy: 0.8418\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.5802 - accuracy: 0.8810 - val_loss: 0.7512 - val_accuracy: 0.8388\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.5665 - accuracy: 0.8862 - val_loss: 0.7298 - val_accuracy: 0.8497\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.5725 - accuracy: 0.8842 - val_loss: 0.7318 - val_accuracy: 0.8491\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.5733 - accuracy: 0.8850 - val_loss: 0.7020 - val_accuracy: 0.8536\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.5679 - accuracy: 0.8875 - val_loss: 0.7531 - val_accuracy: 0.8473\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.5558 - accuracy: 0.8921 - val_loss: 0.7606 - val_accuracy: 0.8443\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.5612 - accuracy: 0.8898 - val_loss: 0.7643 - val_accuracy: 0.8358\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.5539 - accuracy: 0.8918 - val_loss: 0.7271 - val_accuracy: 0.8519\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.5601 - accuracy: 0.8899 - val_loss: 0.7454 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.5612 - accuracy: 0.8906 - val_loss: 0.7388 - val_accuracy: 0.8534\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.5500 - accuracy: 0.8946 - val_loss: 0.7534 - val_accuracy: 0.8409\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.5479 - accuracy: 0.8955 - val_loss: 0.7290 - val_accuracy: 0.8554\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.5382 - accuracy: 0.9005 - val_loss: 0.7668 - val_accuracy: 0.8366\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.5477 - accuracy: 0.8969 - val_loss: 0.7326 - val_accuracy: 0.8517\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.5474 - accuracy: 0.8978 - val_loss: 0.7218 - val_accuracy: 0.8553\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.5402 - accuracy: 0.9005 - val_loss: 0.7336 - val_accuracy: 0.8507\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.5469 - accuracy: 0.8987 - val_loss: 0.7237 - val_accuracy: 0.8591\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5331 - accuracy: 0.9008 - val_loss: 0.7240 - val_accuracy: 0.8559\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5276 - accuracy: 0.9037 - val_loss: 0.7323 - val_accuracy: 0.8545\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5313 - accuracy: 0.9027 - val_loss: 0.7168 - val_accuracy: 0.8528\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5308 - accuracy: 0.9025 - val_loss: 0.7300 - val_accuracy: 0.8574\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5303 - accuracy: 0.9020 - val_loss: 0.7653 - val_accuracy: 0.8457\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5297 - accuracy: 0.9042 - val_loss: 0.8153 - val_accuracy: 0.8376\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5325 - accuracy: 0.9041 - val_loss: 0.7745 - val_accuracy: 0.8473\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5233 - accuracy: 0.9058 - val_loss: 0.7081 - val_accuracy: 0.8605\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5244 - accuracy: 0.9062 - val_loss: 0.7291 - val_accuracy: 0.8600\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5220 - accuracy: 0.9088 - val_loss: 0.7176 - val_accuracy: 0.8577\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5158 - accuracy: 0.9092 - val_loss: 0.7668 - val_accuracy: 0.8427\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5176 - accuracy: 0.9090 - val_loss: 0.7333 - val_accuracy: 0.8583\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5169 - accuracy: 0.9107 - val_loss: 0.7242 - val_accuracy: 0.8593\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5162 - accuracy: 0.9084 - val_loss: 0.7371 - val_accuracy: 0.8605\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5137 - accuracy: 0.9094 - val_loss: 0.7209 - val_accuracy: 0.8607\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5185 - accuracy: 0.9091 - val_loss: 0.7345 - val_accuracy: 0.8618\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5150 - accuracy: 0.9113 - val_loss: 0.7387 - val_accuracy: 0.8536\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5121 - accuracy: 0.9116 - val_loss: 0.7426 - val_accuracy: 0.8563\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5105 - accuracy: 0.9125 - val_loss: 0.7091 - val_accuracy: 0.8651\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5026 - accuracy: 0.9147 - val_loss: 0.7567 - val_accuracy: 0.8539\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5130 - accuracy: 0.9106 - val_loss: 0.7396 - val_accuracy: 0.8575\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5054 - accuracy: 0.9128 - val_loss: 0.7098 - val_accuracy: 0.8624\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5106 - accuracy: 0.9120 - val_loss: 0.7354 - val_accuracy: 0.8591\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5018 - accuracy: 0.9164 - val_loss: 0.7739 - val_accuracy: 0.8527\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5049 - accuracy: 0.9149 - val_loss: 0.7460 - val_accuracy: 0.8575\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5054 - accuracy: 0.9143 - val_loss: 0.7460 - val_accuracy: 0.8608\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5019 - accuracy: 0.9156 - val_loss: 0.7500 - val_accuracy: 0.8524\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5025 - accuracy: 0.9147 - val_loss: 0.6968 - val_accuracy: 0.8691\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.4994 - accuracy: 0.9169 - val_loss: 0.7387 - val_accuracy: 0.8599\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.4925 - accuracy: 0.9182 - val_loss: 0.7103 - val_accuracy: 0.8666\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.4959 - accuracy: 0.9181 - val_loss: 0.7484 - val_accuracy: 0.8596\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5010 - accuracy: 0.9166 - val_loss: 0.7222 - val_accuracy: 0.8601\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.4937 - accuracy: 0.9184 - val_loss: 0.7192 - val_accuracy: 0.8707\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.4977 - accuracy: 0.9165 - val_loss: 0.7723 - val_accuracy: 0.8564\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.4973 - accuracy: 0.9180 - val_loss: 0.7180 - val_accuracy: 0.8613\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.4955 - accuracy: 0.9193 - val_loss: 0.7703 - val_accuracy: 0.8525\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.4884 - accuracy: 0.9201 - val_loss: 0.7630 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.4917 - accuracy: 0.9192 - val_loss: 0.7405 - val_accuracy: 0.8654\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.4879 - accuracy: 0.9200 - val_loss: 0.7450 - val_accuracy: 0.8610\n",
      "313/313 - 1s - loss: 0.7450 - accuracy: 0.8610\n",
      "Test accuracy: 0.8610000014305115\n",
      "NET  2\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.7005 - accuracy: 0.1159 - val_loss: 2.4844 - val_accuracy: 0.1840\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.3133 - accuracy: 0.2008 - val_loss: 2.1311 - val_accuracy: 0.2364\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 2.1152 - accuracy: 0.2488 - val_loss: 1.9974 - val_accuracy: 0.2993\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 2.0006 - accuracy: 0.3001 - val_loss: 1.8776 - val_accuracy: 0.3790\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.8203 - accuracy: 0.3908 - val_loss: 1.6696 - val_accuracy: 0.4690\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6379 - accuracy: 0.4632 - val_loss: 1.5003 - val_accuracy: 0.5109\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5468 - accuracy: 0.5047 - val_loss: 1.4389 - val_accuracy: 0.5277\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4484 - accuracy: 0.5415 - val_loss: 1.3511 - val_accuracy: 0.5755\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3877 - accuracy: 0.5637 - val_loss: 1.3418 - val_accuracy: 0.5725\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3182 - accuracy: 0.5893 - val_loss: 1.2383 - val_accuracy: 0.6129\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2666 - accuracy: 0.6065 - val_loss: 1.3116 - val_accuracy: 0.5657\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2125 - accuracy: 0.6288 - val_loss: 1.1711 - val_accuracy: 0.6336\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1711 - accuracy: 0.6415 - val_loss: 1.0829 - val_accuracy: 0.6672\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1320 - accuracy: 0.6522 - val_loss: 1.1325 - val_accuracy: 0.6352\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1015 - accuracy: 0.6651 - val_loss: 0.9955 - val_accuracy: 0.6970\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0584 - accuracy: 0.6766 - val_loss: 1.0302 - val_accuracy: 0.6888\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0350 - accuracy: 0.6877 - val_loss: 0.9465 - val_accuracy: 0.7154\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9995 - accuracy: 0.6980 - val_loss: 0.9327 - val_accuracy: 0.7175\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9810 - accuracy: 0.7030 - val_loss: 0.8869 - val_accuracy: 0.7275\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9569 - accuracy: 0.7101 - val_loss: 0.9071 - val_accuracy: 0.7189\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9443 - accuracy: 0.7169 - val_loss: 0.8787 - val_accuracy: 0.7315\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9199 - accuracy: 0.7249 - val_loss: 0.8871 - val_accuracy: 0.7270\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8971 - accuracy: 0.7321 - val_loss: 0.8493 - val_accuracy: 0.7355\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8854 - accuracy: 0.7382 - val_loss: 0.8408 - val_accuracy: 0.7447\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8664 - accuracy: 0.7445 - val_loss: 0.8608 - val_accuracy: 0.7329\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8505 - accuracy: 0.7489 - val_loss: 0.8324 - val_accuracy: 0.7503\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8452 - accuracy: 0.7531 - val_loss: 0.7978 - val_accuracy: 0.7615\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8224 - accuracy: 0.7599 - val_loss: 0.7865 - val_accuracy: 0.7691\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8129 - accuracy: 0.7630 - val_loss: 0.7714 - val_accuracy: 0.7701\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7996 - accuracy: 0.7650 - val_loss: 0.7870 - val_accuracy: 0.7683\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7916 - accuracy: 0.7700 - val_loss: 0.7993 - val_accuracy: 0.7629\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7823 - accuracy: 0.7744 - val_loss: 0.7607 - val_accuracy: 0.7797\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7750 - accuracy: 0.7787 - val_loss: 0.8392 - val_accuracy: 0.7461\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7671 - accuracy: 0.7809 - val_loss: 0.7872 - val_accuracy: 0.7750\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7658 - accuracy: 0.7831 - val_loss: 0.7538 - val_accuracy: 0.7802\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7495 - accuracy: 0.7881 - val_loss: 0.7414 - val_accuracy: 0.7883\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7372 - accuracy: 0.7907 - val_loss: 0.7475 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7365 - accuracy: 0.7906 - val_loss: 0.7479 - val_accuracy: 0.7869\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7250 - accuracy: 0.7980 - val_loss: 0.7327 - val_accuracy: 0.7880\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7168 - accuracy: 0.7996 - val_loss: 0.7226 - val_accuracy: 0.7905\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7132 - accuracy: 0.8003 - val_loss: 0.7023 - val_accuracy: 0.8012\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7026 - accuracy: 0.8049 - val_loss: 0.7090 - val_accuracy: 0.7994\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.7027 - accuracy: 0.8042 - val_loss: 0.7048 - val_accuracy: 0.8020\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.7015 - accuracy: 0.8050 - val_loss: 0.6939 - val_accuracy: 0.8051\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6927 - accuracy: 0.8084 - val_loss: 0.7588 - val_accuracy: 0.7896\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6877 - accuracy: 0.8095 - val_loss: 0.7334 - val_accuracy: 0.7910\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6858 - accuracy: 0.8121 - val_loss: 0.6854 - val_accuracy: 0.8076\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6739 - accuracy: 0.8170 - val_loss: 0.7203 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6634 - accuracy: 0.8184 - val_loss: 0.7682 - val_accuracy: 0.7895\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6725 - accuracy: 0.8180 - val_loss: 0.6665 - val_accuracy: 0.8164\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6621 - accuracy: 0.8191 - val_loss: 0.7060 - val_accuracy: 0.8017\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6646 - accuracy: 0.8214 - val_loss: 0.6734 - val_accuracy: 0.8147\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6587 - accuracy: 0.8208 - val_loss: 0.6745 - val_accuracy: 0.8136\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6633 - accuracy: 0.8225 - val_loss: 0.7235 - val_accuracy: 0.7928\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6550 - accuracy: 0.8216 - val_loss: 0.6771 - val_accuracy: 0.8158\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6453 - accuracy: 0.8266 - val_loss: 0.7113 - val_accuracy: 0.8080\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6456 - accuracy: 0.8268 - val_loss: 0.6897 - val_accuracy: 0.8083\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6473 - accuracy: 0.8278 - val_loss: 0.7072 - val_accuracy: 0.8077\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6344 - accuracy: 0.8328 - val_loss: 0.6774 - val_accuracy: 0.8171\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6367 - accuracy: 0.8301 - val_loss: 0.6598 - val_accuracy: 0.8198\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6370 - accuracy: 0.8306 - val_loss: 0.6752 - val_accuracy: 0.8148\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6299 - accuracy: 0.8336 - val_loss: 0.6822 - val_accuracy: 0.8128\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6240 - accuracy: 0.8354 - val_loss: 0.6554 - val_accuracy: 0.8263\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6204 - accuracy: 0.8355 - val_loss: 0.7126 - val_accuracy: 0.8078\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6240 - accuracy: 0.8376 - val_loss: 0.6696 - val_accuracy: 0.8219\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6144 - accuracy: 0.8372 - val_loss: 0.6692 - val_accuracy: 0.8170\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6149 - accuracy: 0.8384 - val_loss: 0.6540 - val_accuracy: 0.8256\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6112 - accuracy: 0.8395 - val_loss: 0.6712 - val_accuracy: 0.8217\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6101 - accuracy: 0.8435 - val_loss: 0.6719 - val_accuracy: 0.8207\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6099 - accuracy: 0.8416 - val_loss: 0.7142 - val_accuracy: 0.8127\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.6026 - accuracy: 0.8461 - val_loss: 0.7125 - val_accuracy: 0.8065\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.6076 - accuracy: 0.8420 - val_loss: 0.6581 - val_accuracy: 0.8234\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.6032 - accuracy: 0.8442 - val_loss: 0.6726 - val_accuracy: 0.8264\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.6039 - accuracy: 0.8444 - val_loss: 0.7401 - val_accuracy: 0.8016\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5915 - accuracy: 0.8463 - val_loss: 0.6342 - val_accuracy: 0.8362\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5888 - accuracy: 0.8468 - val_loss: 0.6898 - val_accuracy: 0.8258\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5986 - accuracy: 0.8459 - val_loss: 0.6733 - val_accuracy: 0.8240\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.6000 - accuracy: 0.8442 - val_loss: 0.6623 - val_accuracy: 0.8297\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5902 - accuracy: 0.8470 - val_loss: 0.6908 - val_accuracy: 0.8150\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5842 - accuracy: 0.8498 - val_loss: 0.6767 - val_accuracy: 0.8261\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5971 - accuracy: 0.8480 - val_loss: 0.6675 - val_accuracy: 0.8276\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5931 - accuracy: 0.8481 - val_loss: 0.7255 - val_accuracy: 0.8136\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5908 - accuracy: 0.8511 - val_loss: 0.6502 - val_accuracy: 0.8304\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5728 - accuracy: 0.8553 - val_loss: 0.6317 - val_accuracy: 0.8392\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5795 - accuracy: 0.8549 - val_loss: 0.6534 - val_accuracy: 0.8320\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5867 - accuracy: 0.8496 - val_loss: 0.6681 - val_accuracy: 0.8293\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5755 - accuracy: 0.8547 - val_loss: 0.6330 - val_accuracy: 0.8367\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5680 - accuracy: 0.8580 - val_loss: 0.6867 - val_accuracy: 0.8214\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5775 - accuracy: 0.8529 - val_loss: 0.6589 - val_accuracy: 0.8285\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5790 - accuracy: 0.8531 - val_loss: 0.6367 - val_accuracy: 0.8374\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5714 - accuracy: 0.8552 - val_loss: 0.6414 - val_accuracy: 0.8324\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5728 - accuracy: 0.8563 - val_loss: 0.6824 - val_accuracy: 0.8240\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5767 - accuracy: 0.8541 - val_loss: 0.6711 - val_accuracy: 0.8283\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5716 - accuracy: 0.8567 - val_loss: 0.6453 - val_accuracy: 0.8367\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5674 - accuracy: 0.8577 - val_loss: 0.6541 - val_accuracy: 0.8385\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5709 - accuracy: 0.8555 - val_loss: 0.6519 - val_accuracy: 0.8375\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5734 - accuracy: 0.8559 - val_loss: 0.7024 - val_accuracy: 0.8234\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5576 - accuracy: 0.8607 - val_loss: 0.6816 - val_accuracy: 0.8199\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5718 - accuracy: 0.8561 - val_loss: 0.6303 - val_accuracy: 0.8393\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5652 - accuracy: 0.8597 - val_loss: 0.6256 - val_accuracy: 0.8441\n",
      "313/313 - 1s - loss: 0.6256 - accuracy: 0.8441\n",
      "Test accuracy: 0.8440999984741211\n",
      "NET  3\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.4991 - accuracy: 0.1769 - val_loss: 2.8940 - val_accuracy: 0.1308\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0702 - accuracy: 0.2993 - val_loss: 2.1373 - val_accuracy: 0.3026\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.8881 - accuracy: 0.3740 - val_loss: 1.7617 - val_accuracy: 0.4278\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7467 - accuracy: 0.4341 - val_loss: 1.6488 - val_accuracy: 0.4607\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.6282 - accuracy: 0.4845 - val_loss: 1.5411 - val_accuracy: 0.5041\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.5349 - accuracy: 0.5210 - val_loss: 1.6498 - val_accuracy: 0.4888\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.4371 - accuracy: 0.5578 - val_loss: 1.4186 - val_accuracy: 0.5521\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.3615 - accuracy: 0.5875 - val_loss: 1.2332 - val_accuracy: 0.6238\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.2999 - accuracy: 0.6076 - val_loss: 1.3423 - val_accuracy: 0.5884\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2493 - accuracy: 0.6229 - val_loss: 1.1763 - val_accuracy: 0.6358\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.1915 - accuracy: 0.6447 - val_loss: 1.0881 - val_accuracy: 0.6738\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1379 - accuracy: 0.6580 - val_loss: 1.1076 - val_accuracy: 0.6650\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1063 - accuracy: 0.6690 - val_loss: 1.1104 - val_accuracy: 0.6637\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0649 - accuracy: 0.6822 - val_loss: 0.9801 - val_accuracy: 0.7051\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0348 - accuracy: 0.6914 - val_loss: 0.9926 - val_accuracy: 0.6982\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0080 - accuracy: 0.7026 - val_loss: 0.9830 - val_accuracy: 0.7041\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9880 - accuracy: 0.7078 - val_loss: 0.9511 - val_accuracy: 0.7147\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9472 - accuracy: 0.7219 - val_loss: 0.8833 - val_accuracy: 0.7396\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9271 - accuracy: 0.7269 - val_loss: 0.9088 - val_accuracy: 0.7367\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9110 - accuracy: 0.7344 - val_loss: 0.9644 - val_accuracy: 0.7160\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.8808 - accuracy: 0.7461 - val_loss: 0.8439 - val_accuracy: 0.7533\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8692 - accuracy: 0.7469 - val_loss: 0.8423 - val_accuracy: 0.7574\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8535 - accuracy: 0.7559 - val_loss: 0.7945 - val_accuracy: 0.7665\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8385 - accuracy: 0.7622 - val_loss: 0.7922 - val_accuracy: 0.7701\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8183 - accuracy: 0.7676 - val_loss: 0.8180 - val_accuracy: 0.7660\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8015 - accuracy: 0.7736 - val_loss: 0.7863 - val_accuracy: 0.7725\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.7897 - accuracy: 0.7777 - val_loss: 0.7533 - val_accuracy: 0.7873\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7811 - accuracy: 0.7813 - val_loss: 0.7666 - val_accuracy: 0.7801\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7651 - accuracy: 0.7856 - val_loss: 0.8030 - val_accuracy: 0.7687\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7551 - accuracy: 0.7923 - val_loss: 0.7521 - val_accuracy: 0.7845\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7498 - accuracy: 0.7928 - val_loss: 0.7558 - val_accuracy: 0.7834\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7340 - accuracy: 0.7983 - val_loss: 0.8178 - val_accuracy: 0.7748\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7290 - accuracy: 0.8001 - val_loss: 0.7313 - val_accuracy: 0.7994\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7119 - accuracy: 0.8062 - val_loss: 0.7293 - val_accuracy: 0.8008\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7014 - accuracy: 0.8107 - val_loss: 0.7578 - val_accuracy: 0.7948\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.6938 - accuracy: 0.8126 - val_loss: 0.7175 - val_accuracy: 0.8069\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.6932 - accuracy: 0.8136 - val_loss: 0.7314 - val_accuracy: 0.8056\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.6841 - accuracy: 0.8168 - val_loss: 0.7254 - val_accuracy: 0.8046\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6810 - accuracy: 0.8185 - val_loss: 0.7019 - val_accuracy: 0.8144\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6758 - accuracy: 0.8210 - val_loss: 0.6998 - val_accuracy: 0.8151\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6611 - accuracy: 0.8240 - val_loss: 0.7584 - val_accuracy: 0.7963\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6603 - accuracy: 0.8254 - val_loss: 0.7429 - val_accuracy: 0.7994\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6522 - accuracy: 0.8291 - val_loss: 0.7055 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6567 - accuracy: 0.8285 - val_loss: 0.7312 - val_accuracy: 0.8036\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6479 - accuracy: 0.8309 - val_loss: 0.7003 - val_accuracy: 0.8144\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6439 - accuracy: 0.8326 - val_loss: 0.6848 - val_accuracy: 0.8245\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6378 - accuracy: 0.8350 - val_loss: 0.7247 - val_accuracy: 0.8092\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6323 - accuracy: 0.8369 - val_loss: 0.6638 - val_accuracy: 0.8263\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6269 - accuracy: 0.8396 - val_loss: 0.6871 - val_accuracy: 0.8238\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6200 - accuracy: 0.8447 - val_loss: 0.7356 - val_accuracy: 0.8058\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6210 - accuracy: 0.8408 - val_loss: 0.6980 - val_accuracy: 0.8208\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6112 - accuracy: 0.8437 - val_loss: 0.6906 - val_accuracy: 0.8191\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6161 - accuracy: 0.8422 - val_loss: 0.7170 - val_accuracy: 0.8162\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6109 - accuracy: 0.8437 - val_loss: 0.6667 - val_accuracy: 0.8330\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6055 - accuracy: 0.8465 - val_loss: 0.7664 - val_accuracy: 0.7999\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6034 - accuracy: 0.8483 - val_loss: 0.6752 - val_accuracy: 0.8246\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.5993 - accuracy: 0.8489 - val_loss: 0.6637 - val_accuracy: 0.8344\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.5953 - accuracy: 0.8516 - val_loss: 0.6760 - val_accuracy: 0.8299\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.5903 - accuracy: 0.8525 - val_loss: 0.6807 - val_accuracy: 0.8291\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.5927 - accuracy: 0.8511 - val_loss: 0.7055 - val_accuracy: 0.8225\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.5884 - accuracy: 0.8547 - val_loss: 0.6878 - val_accuracy: 0.8252\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5931 - accuracy: 0.8529 - val_loss: 0.6587 - val_accuracy: 0.8357\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5798 - accuracy: 0.8560 - val_loss: 0.7032 - val_accuracy: 0.8267\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5760 - accuracy: 0.8588 - val_loss: 0.6884 - val_accuracy: 0.8293\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5736 - accuracy: 0.8575 - val_loss: 0.6740 - val_accuracy: 0.8285\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5766 - accuracy: 0.8566 - val_loss: 0.6548 - val_accuracy: 0.8354\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5730 - accuracy: 0.8592 - val_loss: 0.6800 - val_accuracy: 0.8302\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5645 - accuracy: 0.8617 - val_loss: 0.6556 - val_accuracy: 0.8378\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5613 - accuracy: 0.8641 - val_loss: 0.6782 - val_accuracy: 0.8371\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5662 - accuracy: 0.8620 - val_loss: 0.6522 - val_accuracy: 0.8448\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5586 - accuracy: 0.8657 - val_loss: 0.6500 - val_accuracy: 0.8446\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5496 - accuracy: 0.8683 - val_loss: 0.6717 - val_accuracy: 0.8368\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5493 - accuracy: 0.8685 - val_loss: 0.7180 - val_accuracy: 0.8212\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5482 - accuracy: 0.8683 - val_loss: 0.6597 - val_accuracy: 0.8460\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5546 - accuracy: 0.8668 - val_loss: 0.6674 - val_accuracy: 0.8405\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5531 - accuracy: 0.8676 - val_loss: 0.6623 - val_accuracy: 0.8389\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5590 - accuracy: 0.8656 - val_loss: 0.6713 - val_accuracy: 0.8364\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5437 - accuracy: 0.8702 - val_loss: 0.6467 - val_accuracy: 0.8474\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5433 - accuracy: 0.8699 - val_loss: 0.6487 - val_accuracy: 0.8419\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5427 - accuracy: 0.8722 - val_loss: 0.7034 - val_accuracy: 0.8269\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5389 - accuracy: 0.8720 - val_loss: 0.6706 - val_accuracy: 0.8396\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5407 - accuracy: 0.8728 - val_loss: 0.6883 - val_accuracy: 0.8294\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5340 - accuracy: 0.8735 - val_loss: 0.6679 - val_accuracy: 0.8318\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5370 - accuracy: 0.8755 - val_loss: 0.6792 - val_accuracy: 0.8348\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5383 - accuracy: 0.8746 - val_loss: 0.6859 - val_accuracy: 0.8345\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5294 - accuracy: 0.8762 - val_loss: 0.6879 - val_accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5385 - accuracy: 0.8745 - val_loss: 0.6370 - val_accuracy: 0.8469\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5277 - accuracy: 0.8768 - val_loss: 0.6311 - val_accuracy: 0.8521\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5322 - accuracy: 0.8754 - val_loss: 0.6612 - val_accuracy: 0.8391\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5309 - accuracy: 0.8768 - val_loss: 0.6404 - val_accuracy: 0.8470\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5287 - accuracy: 0.8781 - val_loss: 0.6743 - val_accuracy: 0.8389\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5205 - accuracy: 0.8797 - val_loss: 0.6728 - val_accuracy: 0.8406\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5217 - accuracy: 0.8807 - val_loss: 0.6601 - val_accuracy: 0.8436\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5207 - accuracy: 0.8799 - val_loss: 0.6816 - val_accuracy: 0.8427\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5225 - accuracy: 0.8797 - val_loss: 0.6730 - val_accuracy: 0.8347\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5167 - accuracy: 0.8826 - val_loss: 0.6580 - val_accuracy: 0.8455\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5263 - accuracy: 0.8788 - val_loss: 0.6490 - val_accuracy: 0.8446\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5128 - accuracy: 0.8834 - val_loss: 0.6403 - val_accuracy: 0.8419\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5185 - accuracy: 0.8819 - val_loss: 0.6554 - val_accuracy: 0.8384\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5190 - accuracy: 0.8809 - val_loss: 0.6674 - val_accuracy: 0.8407\n",
      "313/313 - 1s - loss: 0.6674 - accuracy: 0.8407\n",
      "Test accuracy: 0.8406999707221985\n",
      "NET  4\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.6200 - accuracy: 0.1564 - val_loss: 2.7355 - val_accuracy: 0.1166\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1193 - accuracy: 0.2640 - val_loss: 2.4219 - val_accuracy: 0.2093\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9567 - accuracy: 0.3209 - val_loss: 1.8902 - val_accuracy: 0.3741\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8140 - accuracy: 0.3891 - val_loss: 1.7773 - val_accuracy: 0.4316\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7040 - accuracy: 0.4365 - val_loss: 1.6456 - val_accuracy: 0.4736\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6032 - accuracy: 0.4827 - val_loss: 1.5452 - val_accuracy: 0.5179\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5200 - accuracy: 0.5213 - val_loss: 1.4873 - val_accuracy: 0.5503\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4508 - accuracy: 0.5450 - val_loss: 1.3624 - val_accuracy: 0.5784\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3969 - accuracy: 0.5681 - val_loss: 1.6050 - val_accuracy: 0.5063\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3371 - accuracy: 0.5907 - val_loss: 1.2584 - val_accuracy: 0.6231\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2770 - accuracy: 0.6082 - val_loss: 1.2298 - val_accuracy: 0.6241\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2346 - accuracy: 0.6243 - val_loss: 1.1668 - val_accuracy: 0.6426\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1897 - accuracy: 0.6365 - val_loss: 1.0831 - val_accuracy: 0.6744\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1441 - accuracy: 0.6530 - val_loss: 1.0436 - val_accuracy: 0.6870\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1139 - accuracy: 0.6625 - val_loss: 1.0333 - val_accuracy: 0.6962\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0795 - accuracy: 0.6718 - val_loss: 1.0700 - val_accuracy: 0.6724\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0641 - accuracy: 0.6766 - val_loss: 1.0161 - val_accuracy: 0.6944\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0209 - accuracy: 0.6921 - val_loss: 1.0787 - val_accuracy: 0.6705\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 1.0033 - accuracy: 0.6993 - val_loss: 0.9863 - val_accuracy: 0.6994\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9746 - accuracy: 0.7058 - val_loss: 0.9329 - val_accuracy: 0.7134\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9547 - accuracy: 0.7130 - val_loss: 1.0687 - val_accuracy: 0.6677\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9431 - accuracy: 0.7153 - val_loss: 0.8861 - val_accuracy: 0.7338\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.9113 - accuracy: 0.7269 - val_loss: 0.8943 - val_accuracy: 0.7264\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.9026 - accuracy: 0.7313 - val_loss: 0.9023 - val_accuracy: 0.7294\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8814 - accuracy: 0.7365 - val_loss: 0.9202 - val_accuracy: 0.7174\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8658 - accuracy: 0.7431 - val_loss: 0.8274 - val_accuracy: 0.7565\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8525 - accuracy: 0.7489 - val_loss: 0.8375 - val_accuracy: 0.7503\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8409 - accuracy: 0.7524 - val_loss: 0.7876 - val_accuracy: 0.7687\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8235 - accuracy: 0.7612 - val_loss: 0.8360 - val_accuracy: 0.7541\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.8191 - accuracy: 0.7626 - val_loss: 0.7679 - val_accuracy: 0.7761\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.8066 - accuracy: 0.7647 - val_loss: 0.7739 - val_accuracy: 0.7749\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7899 - accuracy: 0.7709 - val_loss: 0.8615 - val_accuracy: 0.7361\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7836 - accuracy: 0.7745 - val_loss: 0.7880 - val_accuracy: 0.7726\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7763 - accuracy: 0.7782 - val_loss: 0.8823 - val_accuracy: 0.7501\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7633 - accuracy: 0.7822 - val_loss: 0.7869 - val_accuracy: 0.7770\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7534 - accuracy: 0.7839 - val_loss: 0.7926 - val_accuracy: 0.7664\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7476 - accuracy: 0.7879 - val_loss: 0.7085 - val_accuracy: 0.7984\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7379 - accuracy: 0.7906 - val_loss: 0.7477 - val_accuracy: 0.7849\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7411 - accuracy: 0.7893 - val_loss: 0.7456 - val_accuracy: 0.7905\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7318 - accuracy: 0.7949 - val_loss: 0.7590 - val_accuracy: 0.7832\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7176 - accuracy: 0.7972 - val_loss: 0.6866 - val_accuracy: 0.8083\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7257 - accuracy: 0.7969 - val_loss: 0.7589 - val_accuracy: 0.7827\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.7034 - accuracy: 0.8042 - val_loss: 0.7402 - val_accuracy: 0.7929\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.7038 - accuracy: 0.8022 - val_loss: 0.7087 - val_accuracy: 0.8026\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6973 - accuracy: 0.8058 - val_loss: 0.6982 - val_accuracy: 0.8047\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6871 - accuracy: 0.8087 - val_loss: 0.6699 - val_accuracy: 0.8137\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6857 - accuracy: 0.8137 - val_loss: 0.6868 - val_accuracy: 0.8118\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6766 - accuracy: 0.8135 - val_loss: 0.7155 - val_accuracy: 0.8018\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6753 - accuracy: 0.8149 - val_loss: 0.6631 - val_accuracy: 0.8141\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6673 - accuracy: 0.8171 - val_loss: 0.6974 - val_accuracy: 0.8072\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6743 - accuracy: 0.8147 - val_loss: 0.6890 - val_accuracy: 0.8100\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6647 - accuracy: 0.8189 - val_loss: 0.6746 - val_accuracy: 0.8134\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6632 - accuracy: 0.8199 - val_loss: 0.6857 - val_accuracy: 0.8131\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6603 - accuracy: 0.8212 - val_loss: 0.7038 - val_accuracy: 0.8051\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6533 - accuracy: 0.8233 - val_loss: 0.7250 - val_accuracy: 0.7991\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6484 - accuracy: 0.8245 - val_loss: 0.7684 - val_accuracy: 0.7863\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6521 - accuracy: 0.8243 - val_loss: 0.6881 - val_accuracy: 0.8107\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6539 - accuracy: 0.8228 - val_loss: 0.6962 - val_accuracy: 0.8112\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6399 - accuracy: 0.8276 - val_loss: 0.6892 - val_accuracy: 0.8138\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6378 - accuracy: 0.8303 - val_loss: 0.6671 - val_accuracy: 0.8183\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6367 - accuracy: 0.8287 - val_loss: 0.6813 - val_accuracy: 0.8149\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6371 - accuracy: 0.8304 - val_loss: 0.6909 - val_accuracy: 0.8147\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6330 - accuracy: 0.8317 - val_loss: 0.6453 - val_accuracy: 0.8256\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6263 - accuracy: 0.8319 - val_loss: 0.7031 - val_accuracy: 0.8064\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6356 - accuracy: 0.8291 - val_loss: 0.6845 - val_accuracy: 0.8171\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6185 - accuracy: 0.8371 - val_loss: 0.7310 - val_accuracy: 0.8065\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6221 - accuracy: 0.8358 - val_loss: 0.6763 - val_accuracy: 0.8200\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6175 - accuracy: 0.8388 - val_loss: 0.6927 - val_accuracy: 0.8133\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6153 - accuracy: 0.8381 - val_loss: 0.6669 - val_accuracy: 0.8246\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6096 - accuracy: 0.8393 - val_loss: 0.6574 - val_accuracy: 0.8289\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.6138 - accuracy: 0.8401 - val_loss: 0.6700 - val_accuracy: 0.8233\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.6073 - accuracy: 0.8415 - val_loss: 0.6494 - val_accuracy: 0.8312\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.6144 - accuracy: 0.8381 - val_loss: 0.6481 - val_accuracy: 0.8313\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.6124 - accuracy: 0.8397 - val_loss: 0.7046 - val_accuracy: 0.8145\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.6048 - accuracy: 0.8430 - val_loss: 0.6385 - val_accuracy: 0.8317\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.6035 - accuracy: 0.8437 - val_loss: 0.7050 - val_accuracy: 0.8154\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.6019 - accuracy: 0.8422 - val_loss: 0.6425 - val_accuracy: 0.8301\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.6073 - accuracy: 0.8430 - val_loss: 0.6500 - val_accuracy: 0.8304\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5972 - accuracy: 0.8464 - val_loss: 0.6473 - val_accuracy: 0.8335\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5978 - accuracy: 0.8452 - val_loss: 0.6844 - val_accuracy: 0.8259\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.6051 - accuracy: 0.8430 - val_loss: 0.6971 - val_accuracy: 0.8147\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.6002 - accuracy: 0.8437 - val_loss: 0.6519 - val_accuracy: 0.8318\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5923 - accuracy: 0.8475 - val_loss: 0.6417 - val_accuracy: 0.8348\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5861 - accuracy: 0.8489 - val_loss: 0.6752 - val_accuracy: 0.8242\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5950 - accuracy: 0.8475 - val_loss: 0.6331 - val_accuracy: 0.8328\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5962 - accuracy: 0.8475 - val_loss: 0.6545 - val_accuracy: 0.8275\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5837 - accuracy: 0.8507 - val_loss: 0.6519 - val_accuracy: 0.8310\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5928 - accuracy: 0.8475 - val_loss: 0.6633 - val_accuracy: 0.8305\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5836 - accuracy: 0.8505 - val_loss: 0.6678 - val_accuracy: 0.8297\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5847 - accuracy: 0.8513 - val_loss: 0.6567 - val_accuracy: 0.8334\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5833 - accuracy: 0.8509 - val_loss: 0.6455 - val_accuracy: 0.8373\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5841 - accuracy: 0.8518 - val_loss: 0.6394 - val_accuracy: 0.8362\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5862 - accuracy: 0.8501 - val_loss: 0.6581 - val_accuracy: 0.8337\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5796 - accuracy: 0.8531 - val_loss: 0.7053 - val_accuracy: 0.8157\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5818 - accuracy: 0.8509 - val_loss: 0.6484 - val_accuracy: 0.8316\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5742 - accuracy: 0.8550 - val_loss: 0.6893 - val_accuracy: 0.8207\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5760 - accuracy: 0.8533 - val_loss: 0.6699 - val_accuracy: 0.8309\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5814 - accuracy: 0.8521 - val_loss: 0.7004 - val_accuracy: 0.8174\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5751 - accuracy: 0.8558 - val_loss: 0.6493 - val_accuracy: 0.8358\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5732 - accuracy: 0.8561 - val_loss: 0.6720 - val_accuracy: 0.8235\n",
      "313/313 - 1s - loss: 0.6720 - accuracy: 0.8235\n",
      "Test accuracy: 0.8234999775886536\n",
      "NET  5\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.7143 - accuracy: 0.1256 - val_loss: 2.4813 - val_accuracy: 0.1907\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.3545 - accuracy: 0.1979 - val_loss: 2.2053 - val_accuracy: 0.2375\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 2.1102 - accuracy: 0.2739 - val_loss: 2.0015 - val_accuracy: 0.3353\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.9289 - accuracy: 0.3450 - val_loss: 1.8150 - val_accuracy: 0.3838\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7936 - accuracy: 0.3952 - val_loss: 1.6912 - val_accuracy: 0.4525\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6670 - accuracy: 0.4551 - val_loss: 1.6709 - val_accuracy: 0.4718\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5536 - accuracy: 0.5064 - val_loss: 1.4486 - val_accuracy: 0.5536\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4742 - accuracy: 0.5396 - val_loss: 1.4061 - val_accuracy: 0.5720\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.4014 - accuracy: 0.5684 - val_loss: 1.4595 - val_accuracy: 0.5537\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3297 - accuracy: 0.5930 - val_loss: 1.2621 - val_accuracy: 0.6015\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2730 - accuracy: 0.6141 - val_loss: 1.1906 - val_accuracy: 0.6365\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2286 - accuracy: 0.6285 - val_loss: 1.2952 - val_accuracy: 0.6010\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1865 - accuracy: 0.6419 - val_loss: 1.0778 - val_accuracy: 0.6762\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1388 - accuracy: 0.6586 - val_loss: 1.1056 - val_accuracy: 0.6605\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1086 - accuracy: 0.6666 - val_loss: 1.0660 - val_accuracy: 0.6711\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0762 - accuracy: 0.6760 - val_loss: 1.0821 - val_accuracy: 0.6814\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0359 - accuracy: 0.6889 - val_loss: 0.9945 - val_accuracy: 0.6983\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0065 - accuracy: 0.6993 - val_loss: 0.9700 - val_accuracy: 0.6994\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9780 - accuracy: 0.7126 - val_loss: 0.8984 - val_accuracy: 0.7336\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9583 - accuracy: 0.7160 - val_loss: 0.9329 - val_accuracy: 0.7153\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9258 - accuracy: 0.7253 - val_loss: 0.9238 - val_accuracy: 0.7259\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9138 - accuracy: 0.7326 - val_loss: 0.8700 - val_accuracy: 0.7411\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8870 - accuracy: 0.7406 - val_loss: 0.8191 - val_accuracy: 0.7538\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8684 - accuracy: 0.7492 - val_loss: 0.8265 - val_accuracy: 0.7524\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8486 - accuracy: 0.7555 - val_loss: 0.8501 - val_accuracy: 0.7448\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8293 - accuracy: 0.7604 - val_loss: 0.8105 - val_accuracy: 0.7612\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8181 - accuracy: 0.7658 - val_loss: 0.7942 - val_accuracy: 0.7687\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8029 - accuracy: 0.7719 - val_loss: 0.8459 - val_accuracy: 0.7537\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8001 - accuracy: 0.7721 - val_loss: 0.7707 - val_accuracy: 0.7757\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7839 - accuracy: 0.7772 - val_loss: 0.7923 - val_accuracy: 0.7703\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7600 - accuracy: 0.7851 - val_loss: 0.7825 - val_accuracy: 0.7742\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7593 - accuracy: 0.7858 - val_loss: 0.7487 - val_accuracy: 0.7884\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7436 - accuracy: 0.7920 - val_loss: 0.7865 - val_accuracy: 0.7758\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7371 - accuracy: 0.7944 - val_loss: 0.7964 - val_accuracy: 0.7726\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7248 - accuracy: 0.7995 - val_loss: 0.7398 - val_accuracy: 0.7936\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7177 - accuracy: 0.8014 - val_loss: 0.7362 - val_accuracy: 0.7927\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7114 - accuracy: 0.8048 - val_loss: 0.7038 - val_accuracy: 0.8053\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7053 - accuracy: 0.8065 - val_loss: 0.7067 - val_accuracy: 0.8049\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6975 - accuracy: 0.8096 - val_loss: 0.7605 - val_accuracy: 0.7905\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6865 - accuracy: 0.8119 - val_loss: 0.7081 - val_accuracy: 0.8087\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6822 - accuracy: 0.8119 - val_loss: 0.6865 - val_accuracy: 0.8144\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6743 - accuracy: 0.8163 - val_loss: 0.7093 - val_accuracy: 0.8055\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6748 - accuracy: 0.8162 - val_loss: 0.7155 - val_accuracy: 0.8039\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6667 - accuracy: 0.8200 - val_loss: 0.6706 - val_accuracy: 0.8204\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6583 - accuracy: 0.8237 - val_loss: 0.7068 - val_accuracy: 0.8048\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6542 - accuracy: 0.8262 - val_loss: 0.6952 - val_accuracy: 0.8071\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6440 - accuracy: 0.8277 - val_loss: 0.7247 - val_accuracy: 0.8066\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6442 - accuracy: 0.8287 - val_loss: 0.7183 - val_accuracy: 0.8065\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6403 - accuracy: 0.8291 - val_loss: 0.7092 - val_accuracy: 0.8087\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6360 - accuracy: 0.8320 - val_loss: 0.6998 - val_accuracy: 0.8164\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6291 - accuracy: 0.8328 - val_loss: 0.7041 - val_accuracy: 0.8119\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6352 - accuracy: 0.8338 - val_loss: 0.7097 - val_accuracy: 0.8111\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6221 - accuracy: 0.8386 - val_loss: 0.7165 - val_accuracy: 0.8100\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6216 - accuracy: 0.8368 - val_loss: 0.6710 - val_accuracy: 0.8283\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6214 - accuracy: 0.8374 - val_loss: 0.6786 - val_accuracy: 0.8186\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6180 - accuracy: 0.8390 - val_loss: 0.6718 - val_accuracy: 0.8222\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6153 - accuracy: 0.8410 - val_loss: 0.6748 - val_accuracy: 0.8261\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6084 - accuracy: 0.8418 - val_loss: 0.6821 - val_accuracy: 0.8179\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6069 - accuracy: 0.8431 - val_loss: 0.6778 - val_accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6045 - accuracy: 0.8446 - val_loss: 0.6533 - val_accuracy: 0.8298\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.5960 - accuracy: 0.8475 - val_loss: 0.6482 - val_accuracy: 0.8339\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5978 - accuracy: 0.8466 - val_loss: 0.6880 - val_accuracy: 0.8176\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5945 - accuracy: 0.8468 - val_loss: 0.6917 - val_accuracy: 0.8241\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5887 - accuracy: 0.8496 - val_loss: 0.6863 - val_accuracy: 0.8283\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5930 - accuracy: 0.8482 - val_loss: 0.7090 - val_accuracy: 0.8128\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5904 - accuracy: 0.8495 - val_loss: 0.6706 - val_accuracy: 0.8293\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5843 - accuracy: 0.8521 - val_loss: 0.6991 - val_accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5927 - accuracy: 0.8485 - val_loss: 0.6809 - val_accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5830 - accuracy: 0.8514 - val_loss: 0.6700 - val_accuracy: 0.8360\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5827 - accuracy: 0.8518 - val_loss: 0.6543 - val_accuracy: 0.8286\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5812 - accuracy: 0.8541 - val_loss: 0.6870 - val_accuracy: 0.8159\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5746 - accuracy: 0.8538 - val_loss: 0.6525 - val_accuracy: 0.8376\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5756 - accuracy: 0.8532 - val_loss: 0.6659 - val_accuracy: 0.8255\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5739 - accuracy: 0.8545 - val_loss: 0.6522 - val_accuracy: 0.8352\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5796 - accuracy: 0.8531 - val_loss: 0.6689 - val_accuracy: 0.8304\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5619 - accuracy: 0.8589 - val_loss: 0.6577 - val_accuracy: 0.8346\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5686 - accuracy: 0.8598 - val_loss: 0.6685 - val_accuracy: 0.8298\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5624 - accuracy: 0.8616 - val_loss: 0.6909 - val_accuracy: 0.8316\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5631 - accuracy: 0.8605 - val_loss: 0.6628 - val_accuracy: 0.8371\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5636 - accuracy: 0.8629 - val_loss: 0.6604 - val_accuracy: 0.8317\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5669 - accuracy: 0.8592 - val_loss: 0.6569 - val_accuracy: 0.8357\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5648 - accuracy: 0.8594 - val_loss: 0.6756 - val_accuracy: 0.8310\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5610 - accuracy: 0.8617 - val_loss: 0.7121 - val_accuracy: 0.8213\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5532 - accuracy: 0.8637 - val_loss: 0.6964 - val_accuracy: 0.8255\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5596 - accuracy: 0.8612 - val_loss: 0.6802 - val_accuracy: 0.8257\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5605 - accuracy: 0.8617 - val_loss: 0.7000 - val_accuracy: 0.8257\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5541 - accuracy: 0.8634 - val_loss: 0.6831 - val_accuracy: 0.8266\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5480 - accuracy: 0.8655 - val_loss: 0.6945 - val_accuracy: 0.8297\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5511 - accuracy: 0.8657 - val_loss: 0.6749 - val_accuracy: 0.8275\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5533 - accuracy: 0.8636 - val_loss: 0.6459 - val_accuracy: 0.8376\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5478 - accuracy: 0.8657 - val_loss: 0.6386 - val_accuracy: 0.8437\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5467 - accuracy: 0.8671 - val_loss: 0.6549 - val_accuracy: 0.8407\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5491 - accuracy: 0.8664 - val_loss: 0.6890 - val_accuracy: 0.8282\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5473 - accuracy: 0.8687 - val_loss: 0.6623 - val_accuracy: 0.8331\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5377 - accuracy: 0.8688 - val_loss: 0.7123 - val_accuracy: 0.8250\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5420 - accuracy: 0.8704 - val_loss: 0.7411 - val_accuracy: 0.8215\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5435 - accuracy: 0.8690 - val_loss: 0.6679 - val_accuracy: 0.8419\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5412 - accuracy: 0.8682 - val_loss: 0.6639 - val_accuracy: 0.8390\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5469 - accuracy: 0.8679 - val_loss: 0.6763 - val_accuracy: 0.8331\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5441 - accuracy: 0.8686 - val_loss: 0.6559 - val_accuracy: 0.8409\n",
      "313/313 - 1s - loss: 0.6559 - accuracy: 0.8409\n",
      "Test accuracy: 0.8409000039100647\n",
      "NET  6\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5404 - accuracy: 0.1725 - val_loss: 2.6923 - val_accuracy: 0.1362\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0910 - accuracy: 0.2953 - val_loss: 2.0822 - val_accuracy: 0.3212\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9243 - accuracy: 0.3669 - val_loss: 1.8562 - val_accuracy: 0.4005\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7939 - accuracy: 0.4218 - val_loss: 1.6530 - val_accuracy: 0.4725\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.6733 - accuracy: 0.4743 - val_loss: 1.5098 - val_accuracy: 0.5235\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.5764 - accuracy: 0.5097 - val_loss: 1.4708 - val_accuracy: 0.5349\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.4827 - accuracy: 0.5499 - val_loss: 1.4377 - val_accuracy: 0.5446\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4090 - accuracy: 0.5737 - val_loss: 1.3765 - val_accuracy: 0.5836\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3478 - accuracy: 0.5949 - val_loss: 1.3668 - val_accuracy: 0.5617\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2909 - accuracy: 0.6141 - val_loss: 1.1437 - val_accuracy: 0.6579\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2384 - accuracy: 0.6297 - val_loss: 1.1140 - val_accuracy: 0.6600\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1910 - accuracy: 0.6443 - val_loss: 1.1236 - val_accuracy: 0.6584\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1569 - accuracy: 0.6533 - val_loss: 1.1752 - val_accuracy: 0.6252\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1159 - accuracy: 0.6681 - val_loss: 1.0060 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0670 - accuracy: 0.6832 - val_loss: 0.9994 - val_accuracy: 0.7011\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0463 - accuracy: 0.6891 - val_loss: 0.9286 - val_accuracy: 0.7254\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0207 - accuracy: 0.6991 - val_loss: 0.9429 - val_accuracy: 0.7191\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9919 - accuracy: 0.7097 - val_loss: 0.9150 - val_accuracy: 0.7270\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9690 - accuracy: 0.7153 - val_loss: 0.9149 - val_accuracy: 0.7240\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9546 - accuracy: 0.7211 - val_loss: 0.8705 - val_accuracy: 0.7437\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9208 - accuracy: 0.7308 - val_loss: 0.8938 - val_accuracy: 0.7338\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8963 - accuracy: 0.7385 - val_loss: 0.8594 - val_accuracy: 0.7428\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8895 - accuracy: 0.7434 - val_loss: 0.8620 - val_accuracy: 0.7497\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8684 - accuracy: 0.7508 - val_loss: 0.8776 - val_accuracy: 0.7408\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8604 - accuracy: 0.7539 - val_loss: 0.9414 - val_accuracy: 0.7229\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8335 - accuracy: 0.7649 - val_loss: 0.8229 - val_accuracy: 0.7659\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8287 - accuracy: 0.7641 - val_loss: 0.8541 - val_accuracy: 0.7571\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8073 - accuracy: 0.7706 - val_loss: 0.8202 - val_accuracy: 0.7676\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7968 - accuracy: 0.7739 - val_loss: 0.7995 - val_accuracy: 0.7688\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7875 - accuracy: 0.7789 - val_loss: 0.8003 - val_accuracy: 0.7722\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7709 - accuracy: 0.7852 - val_loss: 0.7491 - val_accuracy: 0.7888\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7628 - accuracy: 0.7891 - val_loss: 0.7399 - val_accuracy: 0.7925\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7578 - accuracy: 0.7899 - val_loss: 0.7376 - val_accuracy: 0.7930\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7382 - accuracy: 0.7957 - val_loss: 0.7057 - val_accuracy: 0.8014\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7327 - accuracy: 0.7982 - val_loss: 0.7331 - val_accuracy: 0.7956\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7350 - accuracy: 0.7995 - val_loss: 0.7144 - val_accuracy: 0.8033\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7187 - accuracy: 0.8051 - val_loss: 0.7503 - val_accuracy: 0.7935\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7216 - accuracy: 0.8026 - val_loss: 0.7881 - val_accuracy: 0.7876\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7077 - accuracy: 0.8073 - val_loss: 0.7570 - val_accuracy: 0.7900\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6957 - accuracy: 0.8137 - val_loss: 0.7122 - val_accuracy: 0.8014\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6948 - accuracy: 0.8141 - val_loss: 0.7912 - val_accuracy: 0.7863\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6827 - accuracy: 0.8167 - val_loss: 0.7409 - val_accuracy: 0.8034\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6740 - accuracy: 0.8223 - val_loss: 0.7256 - val_accuracy: 0.8056\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6770 - accuracy: 0.8204 - val_loss: 0.7267 - val_accuracy: 0.8080\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6733 - accuracy: 0.8224 - val_loss: 0.6805 - val_accuracy: 0.8204\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6635 - accuracy: 0.8251 - val_loss: 0.7540 - val_accuracy: 0.7973\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6554 - accuracy: 0.8271 - val_loss: 0.7469 - val_accuracy: 0.7997\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6690 - accuracy: 0.8211 - val_loss: 0.8330 - val_accuracy: 0.7756\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6533 - accuracy: 0.8292 - val_loss: 0.7041 - val_accuracy: 0.8154\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6460 - accuracy: 0.8347 - val_loss: 0.7235 - val_accuracy: 0.8066\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6436 - accuracy: 0.8320 - val_loss: 0.7145 - val_accuracy: 0.8197\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6406 - accuracy: 0.8352 - val_loss: 0.6986 - val_accuracy: 0.8185\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6324 - accuracy: 0.8358 - val_loss: 0.7044 - val_accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6286 - accuracy: 0.8396 - val_loss: 0.7541 - val_accuracy: 0.8069\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6222 - accuracy: 0.8405 - val_loss: 0.6747 - val_accuracy: 0.8269\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6202 - accuracy: 0.8430 - val_loss: 0.7179 - val_accuracy: 0.8208\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6112 - accuracy: 0.8461 - val_loss: 0.6922 - val_accuracy: 0.8242\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6141 - accuracy: 0.8437 - val_loss: 0.6737 - val_accuracy: 0.8311\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6141 - accuracy: 0.8447 - val_loss: 0.6890 - val_accuracy: 0.8261\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6089 - accuracy: 0.8487 - val_loss: 0.6738 - val_accuracy: 0.8295\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6076 - accuracy: 0.8482 - val_loss: 0.6689 - val_accuracy: 0.8330\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6091 - accuracy: 0.8482 - val_loss: 0.6925 - val_accuracy: 0.8252\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6013 - accuracy: 0.8492 - val_loss: 0.6920 - val_accuracy: 0.8218\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5979 - accuracy: 0.8521 - val_loss: 0.7008 - val_accuracy: 0.8268\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5923 - accuracy: 0.8541 - val_loss: 0.6830 - val_accuracy: 0.8293\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5962 - accuracy: 0.8526 - val_loss: 0.6633 - val_accuracy: 0.8321\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5863 - accuracy: 0.8557 - val_loss: 0.6629 - val_accuracy: 0.8336\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5907 - accuracy: 0.8539 - val_loss: 0.6482 - val_accuracy: 0.8387\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5783 - accuracy: 0.8597 - val_loss: 0.7081 - val_accuracy: 0.8160\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5841 - accuracy: 0.8574 - val_loss: 0.7195 - val_accuracy: 0.8212\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5798 - accuracy: 0.8579 - val_loss: 0.6654 - val_accuracy: 0.8293\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5791 - accuracy: 0.8588 - val_loss: 0.6905 - val_accuracy: 0.8328\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5792 - accuracy: 0.8590 - val_loss: 0.6525 - val_accuracy: 0.8349\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5686 - accuracy: 0.8632 - val_loss: 0.6525 - val_accuracy: 0.8388\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5716 - accuracy: 0.8618 - val_loss: 0.6983 - val_accuracy: 0.8244\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5737 - accuracy: 0.8606 - val_loss: 0.6500 - val_accuracy: 0.8407\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5655 - accuracy: 0.8648 - val_loss: 0.6429 - val_accuracy: 0.8418\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5600 - accuracy: 0.8675 - val_loss: 0.6906 - val_accuracy: 0.8336\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5669 - accuracy: 0.8637 - val_loss: 0.6643 - val_accuracy: 0.8392\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5661 - accuracy: 0.8645 - val_loss: 0.6694 - val_accuracy: 0.8369\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5718 - accuracy: 0.8625 - val_loss: 0.6975 - val_accuracy: 0.8306\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5583 - accuracy: 0.8655 - val_loss: 0.6836 - val_accuracy: 0.8318\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5635 - accuracy: 0.8650 - val_loss: 0.6661 - val_accuracy: 0.8376\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5541 - accuracy: 0.8675 - val_loss: 0.6919 - val_accuracy: 0.8305\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5611 - accuracy: 0.8664 - val_loss: 0.6652 - val_accuracy: 0.8398\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5560 - accuracy: 0.8684 - val_loss: 0.6931 - val_accuracy: 0.8327\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5585 - accuracy: 0.8691 - val_loss: 0.6624 - val_accuracy: 0.8368\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5448 - accuracy: 0.8707 - val_loss: 0.7094 - val_accuracy: 0.8327\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5543 - accuracy: 0.8675 - val_loss: 0.6523 - val_accuracy: 0.8454\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5462 - accuracy: 0.8707 - val_loss: 0.6392 - val_accuracy: 0.8437\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5437 - accuracy: 0.8722 - val_loss: 0.6547 - val_accuracy: 0.8431\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5444 - accuracy: 0.8718 - val_loss: 0.6502 - val_accuracy: 0.8480\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5402 - accuracy: 0.8738 - val_loss: 0.7067 - val_accuracy: 0.8315\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5423 - accuracy: 0.8736 - val_loss: 0.6878 - val_accuracy: 0.8357\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5458 - accuracy: 0.8716 - val_loss: 0.6914 - val_accuracy: 0.8342\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5359 - accuracy: 0.8755 - val_loss: 0.6932 - val_accuracy: 0.8396\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5357 - accuracy: 0.8745 - val_loss: 0.6605 - val_accuracy: 0.8454\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5401 - accuracy: 0.8739 - val_loss: 0.6918 - val_accuracy: 0.8379\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5371 - accuracy: 0.8758 - val_loss: 0.6739 - val_accuracy: 0.8394\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5362 - accuracy: 0.8771 - val_loss: 0.6743 - val_accuracy: 0.8373\n",
      "313/313 - 1s - loss: 0.6743 - accuracy: 0.8373\n",
      "Test accuracy: 0.8373000025749207\n",
      "NET  7\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.6277 - accuracy: 0.1564 - val_loss: 2.3123 - val_accuracy: 0.2116\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.2518 - accuracy: 0.2080 - val_loss: 2.1723 - val_accuracy: 0.2319\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 2.1222 - accuracy: 0.2562 - val_loss: 2.1382 - val_accuracy: 0.2595\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.9822 - accuracy: 0.3116 - val_loss: 1.9670 - val_accuracy: 0.3520\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.8595 - accuracy: 0.3704 - val_loss: 1.7684 - val_accuracy: 0.4182\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.7517 - accuracy: 0.4245 - val_loss: 1.5944 - val_accuracy: 0.4943\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.6470 - accuracy: 0.4679 - val_loss: 1.5598 - val_accuracy: 0.5205\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.5698 - accuracy: 0.4991 - val_loss: 1.4065 - val_accuracy: 0.5499\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.4838 - accuracy: 0.5325 - val_loss: 1.4062 - val_accuracy: 0.5563\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.4076 - accuracy: 0.5613 - val_loss: 1.3051 - val_accuracy: 0.6030\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.3465 - accuracy: 0.5833 - val_loss: 1.2280 - val_accuracy: 0.6225\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2868 - accuracy: 0.6053 - val_loss: 1.1833 - val_accuracy: 0.6292\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.2320 - accuracy: 0.6228 - val_loss: 1.1253 - val_accuracy: 0.6480\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1942 - accuracy: 0.6342 - val_loss: 1.0773 - val_accuracy: 0.6600\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1479 - accuracy: 0.6498 - val_loss: 1.0411 - val_accuracy: 0.6812\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.1072 - accuracy: 0.6610 - val_loss: 1.0177 - val_accuracy: 0.6940\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0723 - accuracy: 0.6716 - val_loss: 0.9537 - val_accuracy: 0.7096\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0504 - accuracy: 0.6832 - val_loss: 0.9137 - val_accuracy: 0.7301\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 1.0209 - accuracy: 0.6914 - val_loss: 0.9710 - val_accuracy: 0.6928\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9949 - accuracy: 0.6994 - val_loss: 0.9041 - val_accuracy: 0.7253\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9738 - accuracy: 0.7070 - val_loss: 0.8943 - val_accuracy: 0.7262\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9550 - accuracy: 0.7138 - val_loss: 0.9354 - val_accuracy: 0.7123\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.9342 - accuracy: 0.7203 - val_loss: 0.8385 - val_accuracy: 0.7450\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.9085 - accuracy: 0.7288 - val_loss: 0.8310 - val_accuracy: 0.7531\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8999 - accuracy: 0.7312 - val_loss: 0.8193 - val_accuracy: 0.7567\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8786 - accuracy: 0.7412 - val_loss: 0.8614 - val_accuracy: 0.7401\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8603 - accuracy: 0.7471 - val_loss: 0.8596 - val_accuracy: 0.7393\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8497 - accuracy: 0.7490 - val_loss: 0.7599 - val_accuracy: 0.7771\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8408 - accuracy: 0.7544 - val_loss: 0.7782 - val_accuracy: 0.7680\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.8198 - accuracy: 0.7621 - val_loss: 0.8467 - val_accuracy: 0.7495\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.8090 - accuracy: 0.7636 - val_loss: 0.7297 - val_accuracy: 0.7851\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.8054 - accuracy: 0.7672 - val_loss: 0.7700 - val_accuracy: 0.7770\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7942 - accuracy: 0.7709 - val_loss: 0.7581 - val_accuracy: 0.7814\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7795 - accuracy: 0.7746 - val_loss: 0.7258 - val_accuracy: 0.7870\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7681 - accuracy: 0.7800 - val_loss: 0.7735 - val_accuracy: 0.7768\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7637 - accuracy: 0.7816 - val_loss: 0.7845 - val_accuracy: 0.7723\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7615 - accuracy: 0.7848 - val_loss: 0.7424 - val_accuracy: 0.7871\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7434 - accuracy: 0.7899 - val_loss: 0.7100 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7394 - accuracy: 0.7892 - val_loss: 0.7540 - val_accuracy: 0.7845\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7310 - accuracy: 0.7931 - val_loss: 0.7360 - val_accuracy: 0.7884\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7272 - accuracy: 0.7947 - val_loss: 0.7304 - val_accuracy: 0.7916\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7123 - accuracy: 0.7993 - val_loss: 0.6873 - val_accuracy: 0.8055\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.7094 - accuracy: 0.8036 - val_loss: 0.7550 - val_accuracy: 0.7880\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.7100 - accuracy: 0.8022 - val_loss: 0.6865 - val_accuracy: 0.8027\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.7053 - accuracy: 0.8034 - val_loss: 0.6940 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6923 - accuracy: 0.8088 - val_loss: 0.6981 - val_accuracy: 0.8077\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6833 - accuracy: 0.8098 - val_loss: 0.6966 - val_accuracy: 0.8015\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6883 - accuracy: 0.8094 - val_loss: 0.7188 - val_accuracy: 0.7994\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6770 - accuracy: 0.8127 - val_loss: 0.7397 - val_accuracy: 0.7889\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6771 - accuracy: 0.8154 - val_loss: 0.7030 - val_accuracy: 0.8122\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6680 - accuracy: 0.8168 - val_loss: 0.6770 - val_accuracy: 0.8152\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6682 - accuracy: 0.8169 - val_loss: 0.7038 - val_accuracy: 0.8035\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6643 - accuracy: 0.8202 - val_loss: 0.6889 - val_accuracy: 0.8102\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6615 - accuracy: 0.8196 - val_loss: 0.6764 - val_accuracy: 0.8175\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6604 - accuracy: 0.8215 - val_loss: 0.6893 - val_accuracy: 0.8140\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6574 - accuracy: 0.8231 - val_loss: 0.6715 - val_accuracy: 0.8179\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6509 - accuracy: 0.8256 - val_loss: 0.7207 - val_accuracy: 0.8048\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6511 - accuracy: 0.8241 - val_loss: 0.6444 - val_accuracy: 0.8274\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6474 - accuracy: 0.8273 - val_loss: 0.6598 - val_accuracy: 0.8227\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6441 - accuracy: 0.8269 - val_loss: 0.6571 - val_accuracy: 0.8251\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6361 - accuracy: 0.8318 - val_loss: 0.6633 - val_accuracy: 0.8257\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6384 - accuracy: 0.8291 - val_loss: 0.7630 - val_accuracy: 0.7983\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6380 - accuracy: 0.8289 - val_loss: 0.6713 - val_accuracy: 0.8217\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6293 - accuracy: 0.8316 - val_loss: 0.6467 - val_accuracy: 0.8299\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6312 - accuracy: 0.8341 - val_loss: 0.7018 - val_accuracy: 0.8082\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6188 - accuracy: 0.8359 - val_loss: 0.7050 - val_accuracy: 0.8100\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6253 - accuracy: 0.8352 - val_loss: 0.6757 - val_accuracy: 0.8220\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6196 - accuracy: 0.8369 - val_loss: 0.6789 - val_accuracy: 0.8145\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6135 - accuracy: 0.8385 - val_loss: 0.6628 - val_accuracy: 0.8254\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6134 - accuracy: 0.8382 - val_loss: 0.6637 - val_accuracy: 0.8257\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.6082 - accuracy: 0.8396 - val_loss: 0.6461 - val_accuracy: 0.8298\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.6095 - accuracy: 0.8399 - val_loss: 0.6457 - val_accuracy: 0.8278\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.6047 - accuracy: 0.8428 - val_loss: 0.6843 - val_accuracy: 0.8223\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.6108 - accuracy: 0.8435 - val_loss: 0.6409 - val_accuracy: 0.8313\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.6042 - accuracy: 0.8432 - val_loss: 0.6448 - val_accuracy: 0.8307\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.6071 - accuracy: 0.8424 - val_loss: 0.6129 - val_accuracy: 0.8407\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.6063 - accuracy: 0.8437 - val_loss: 0.6642 - val_accuracy: 0.8256\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.6002 - accuracy: 0.8448 - val_loss: 0.6287 - val_accuracy: 0.8399\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5963 - accuracy: 0.8470 - val_loss: 0.6308 - val_accuracy: 0.8365\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.6008 - accuracy: 0.8459 - val_loss: 0.6634 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5965 - accuracy: 0.8456 - val_loss: 0.6574 - val_accuracy: 0.8288\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5896 - accuracy: 0.8459 - val_loss: 0.6134 - val_accuracy: 0.8398\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5887 - accuracy: 0.8485 - val_loss: 0.6600 - val_accuracy: 0.8283\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5883 - accuracy: 0.8490 - val_loss: 0.6471 - val_accuracy: 0.8340\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5868 - accuracy: 0.8504 - val_loss: 0.6580 - val_accuracy: 0.8303\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5839 - accuracy: 0.8504 - val_loss: 0.6456 - val_accuracy: 0.8334\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5862 - accuracy: 0.8501 - val_loss: 0.6420 - val_accuracy: 0.8338\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5876 - accuracy: 0.8511 - val_loss: 0.6223 - val_accuracy: 0.8392\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5824 - accuracy: 0.8528 - val_loss: 0.6516 - val_accuracy: 0.8330\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5808 - accuracy: 0.8541 - val_loss: 0.6358 - val_accuracy: 0.8379\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5801 - accuracy: 0.8529 - val_loss: 0.6388 - val_accuracy: 0.8348\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5848 - accuracy: 0.8520 - val_loss: 0.6128 - val_accuracy: 0.8434\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5761 - accuracy: 0.8544 - val_loss: 0.6351 - val_accuracy: 0.8405\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5774 - accuracy: 0.8514 - val_loss: 0.6337 - val_accuracy: 0.8377\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5802 - accuracy: 0.8529 - val_loss: 0.6319 - val_accuracy: 0.8378\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5771 - accuracy: 0.8551 - val_loss: 0.6402 - val_accuracy: 0.8353\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5744 - accuracy: 0.8564 - val_loss: 0.6432 - val_accuracy: 0.8384\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5714 - accuracy: 0.8574 - val_loss: 0.6615 - val_accuracy: 0.8337\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5777 - accuracy: 0.8542 - val_loss: 0.6351 - val_accuracy: 0.8433\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5672 - accuracy: 0.8566 - val_loss: 0.6360 - val_accuracy: 0.8424\n",
      "313/313 - 1s - loss: 0.6360 - accuracy: 0.8424\n",
      "Test accuracy: 0.8424000144004822\n",
      "NET  8\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.6208 - accuracy: 0.1458 - val_loss: 2.4374 - val_accuracy: 0.1884\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1622 - accuracy: 0.2451 - val_loss: 2.0752 - val_accuracy: 0.2997\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9970 - accuracy: 0.3099 - val_loss: 1.8087 - val_accuracy: 0.3986\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8413 - accuracy: 0.3919 - val_loss: 1.6683 - val_accuracy: 0.4596\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.6917 - accuracy: 0.4578 - val_loss: 1.5704 - val_accuracy: 0.4970\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.5929 - accuracy: 0.5011 - val_loss: 1.4953 - val_accuracy: 0.5280\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.4881 - accuracy: 0.5424 - val_loss: 1.3208 - val_accuracy: 0.5889\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.3951 - accuracy: 0.5762 - val_loss: 1.2634 - val_accuracy: 0.6150\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3268 - accuracy: 0.5992 - val_loss: 1.1983 - val_accuracy: 0.6307\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2605 - accuracy: 0.6214 - val_loss: 1.1114 - val_accuracy: 0.6602\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2009 - accuracy: 0.6411 - val_loss: 1.0776 - val_accuracy: 0.6705\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1707 - accuracy: 0.6514 - val_loss: 1.1207 - val_accuracy: 0.6599\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1290 - accuracy: 0.6664 - val_loss: 1.0582 - val_accuracy: 0.6828\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0879 - accuracy: 0.6772 - val_loss: 1.0428 - val_accuracy: 0.6884\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0605 - accuracy: 0.6888 - val_loss: 1.0118 - val_accuracy: 0.6878\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0220 - accuracy: 0.7003 - val_loss: 0.9095 - val_accuracy: 0.7300\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9904 - accuracy: 0.7097 - val_loss: 0.9774 - val_accuracy: 0.7029\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9755 - accuracy: 0.7149 - val_loss: 0.8721 - val_accuracy: 0.7424\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9380 - accuracy: 0.7293 - val_loss: 0.9045 - val_accuracy: 0.7278\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9248 - accuracy: 0.7321 - val_loss: 0.9053 - val_accuracy: 0.7309\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9049 - accuracy: 0.7385 - val_loss: 0.8560 - val_accuracy: 0.7469\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8843 - accuracy: 0.7455 - val_loss: 0.8135 - val_accuracy: 0.7630\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8597 - accuracy: 0.7532 - val_loss: 0.7981 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8492 - accuracy: 0.7544 - val_loss: 0.8109 - val_accuracy: 0.7648\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8399 - accuracy: 0.7632 - val_loss: 0.7644 - val_accuracy: 0.7823\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8205 - accuracy: 0.7684 - val_loss: 0.7735 - val_accuracy: 0.7752\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8070 - accuracy: 0.7713 - val_loss: 0.7506 - val_accuracy: 0.7849\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7943 - accuracy: 0.7765 - val_loss: 0.7637 - val_accuracy: 0.7803\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7881 - accuracy: 0.7802 - val_loss: 0.7741 - val_accuracy: 0.7772\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7745 - accuracy: 0.7837 - val_loss: 0.7376 - val_accuracy: 0.7929\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7607 - accuracy: 0.7867 - val_loss: 0.8085 - val_accuracy: 0.7671\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7483 - accuracy: 0.7944 - val_loss: 0.7169 - val_accuracy: 0.8025\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7423 - accuracy: 0.7958 - val_loss: 0.7167 - val_accuracy: 0.7996\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7322 - accuracy: 0.7988 - val_loss: 0.7406 - val_accuracy: 0.7924\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7262 - accuracy: 0.8011 - val_loss: 0.7057 - val_accuracy: 0.8095\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7233 - accuracy: 0.8031 - val_loss: 0.7058 - val_accuracy: 0.8085\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7186 - accuracy: 0.8067 - val_loss: 0.7086 - val_accuracy: 0.8062\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7024 - accuracy: 0.8118 - val_loss: 0.7091 - val_accuracy: 0.8065\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6974 - accuracy: 0.8118 - val_loss: 0.7028 - val_accuracy: 0.8132\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6940 - accuracy: 0.8144 - val_loss: 0.6868 - val_accuracy: 0.8143\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6896 - accuracy: 0.8161 - val_loss: 0.7014 - val_accuracy: 0.8123\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6829 - accuracy: 0.8197 - val_loss: 0.7561 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6745 - accuracy: 0.8229 - val_loss: 0.6615 - val_accuracy: 0.8264\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6649 - accuracy: 0.8249 - val_loss: 0.6990 - val_accuracy: 0.8168\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6652 - accuracy: 0.8239 - val_loss: 0.6892 - val_accuracy: 0.8205\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6621 - accuracy: 0.8257 - val_loss: 0.6945 - val_accuracy: 0.8196\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6521 - accuracy: 0.8319 - val_loss: 0.7227 - val_accuracy: 0.8065\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6511 - accuracy: 0.8321 - val_loss: 0.6677 - val_accuracy: 0.8277\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6451 - accuracy: 0.8333 - val_loss: 0.7320 - val_accuracy: 0.8092\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6439 - accuracy: 0.8342 - val_loss: 0.6712 - val_accuracy: 0.8292\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6378 - accuracy: 0.8359 - val_loss: 0.7004 - val_accuracy: 0.8212\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6356 - accuracy: 0.8370 - val_loss: 0.7139 - val_accuracy: 0.8129\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6362 - accuracy: 0.8361 - val_loss: 0.6705 - val_accuracy: 0.8233\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6303 - accuracy: 0.8408 - val_loss: 0.7147 - val_accuracy: 0.8189\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6293 - accuracy: 0.8418 - val_loss: 0.6913 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6242 - accuracy: 0.8425 - val_loss: 0.6607 - val_accuracy: 0.8283\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6216 - accuracy: 0.8431 - val_loss: 0.6416 - val_accuracy: 0.8404\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6227 - accuracy: 0.8450 - val_loss: 0.7191 - val_accuracy: 0.8139\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6191 - accuracy: 0.8443 - val_loss: 0.6658 - val_accuracy: 0.8285\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6092 - accuracy: 0.8482 - val_loss: 0.6765 - val_accuracy: 0.8263\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6161 - accuracy: 0.8478 - val_loss: 0.6604 - val_accuracy: 0.8318\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6127 - accuracy: 0.8491 - val_loss: 0.6689 - val_accuracy: 0.8287\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6068 - accuracy: 0.8468 - val_loss: 0.6594 - val_accuracy: 0.8393\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6036 - accuracy: 0.8505 - val_loss: 0.6558 - val_accuracy: 0.8358\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6012 - accuracy: 0.8509 - val_loss: 0.7172 - val_accuracy: 0.8166\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6009 - accuracy: 0.8517 - val_loss: 0.6898 - val_accuracy: 0.8232\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5975 - accuracy: 0.8535 - val_loss: 0.6642 - val_accuracy: 0.8389\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5925 - accuracy: 0.8536 - val_loss: 0.6649 - val_accuracy: 0.8394\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5925 - accuracy: 0.8545 - val_loss: 0.6708 - val_accuracy: 0.8324\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5927 - accuracy: 0.8540 - val_loss: 0.6664 - val_accuracy: 0.8341\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5904 - accuracy: 0.8571 - val_loss: 0.7179 - val_accuracy: 0.8225\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5808 - accuracy: 0.8591 - val_loss: 0.6863 - val_accuracy: 0.8326\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5848 - accuracy: 0.8586 - val_loss: 0.6812 - val_accuracy: 0.8312\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5922 - accuracy: 0.8560 - val_loss: 0.6576 - val_accuracy: 0.8386\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5794 - accuracy: 0.8590 - val_loss: 0.6623 - val_accuracy: 0.8421\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5786 - accuracy: 0.8605 - val_loss: 0.6879 - val_accuracy: 0.8314\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5775 - accuracy: 0.8621 - val_loss: 0.6332 - val_accuracy: 0.8525\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5768 - accuracy: 0.8616 - val_loss: 0.6746 - val_accuracy: 0.8378\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5764 - accuracy: 0.8610 - val_loss: 0.6400 - val_accuracy: 0.8462\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5752 - accuracy: 0.8623 - val_loss: 0.6812 - val_accuracy: 0.8380\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5695 - accuracy: 0.8651 - val_loss: 0.6406 - val_accuracy: 0.8462\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5660 - accuracy: 0.8650 - val_loss: 0.7093 - val_accuracy: 0.8250\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5708 - accuracy: 0.8625 - val_loss: 0.7114 - val_accuracy: 0.8221\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5672 - accuracy: 0.8645 - val_loss: 0.6603 - val_accuracy: 0.8430\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5652 - accuracy: 0.8648 - val_loss: 0.6898 - val_accuracy: 0.8375\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5697 - accuracy: 0.8656 - val_loss: 0.6511 - val_accuracy: 0.8406\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5680 - accuracy: 0.8657 - val_loss: 0.7404 - val_accuracy: 0.8234\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5668 - accuracy: 0.8664 - val_loss: 0.6649 - val_accuracy: 0.8404\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5605 - accuracy: 0.8679 - val_loss: 0.6434 - val_accuracy: 0.8505\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5615 - accuracy: 0.8678 - val_loss: 0.7226 - val_accuracy: 0.8274\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5569 - accuracy: 0.8699 - val_loss: 0.6475 - val_accuracy: 0.8485\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5569 - accuracy: 0.8708 - val_loss: 0.6556 - val_accuracy: 0.8479\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5641 - accuracy: 0.8676 - val_loss: 0.6746 - val_accuracy: 0.8374\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5567 - accuracy: 0.8728 - val_loss: 0.6330 - val_accuracy: 0.8506\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5505 - accuracy: 0.8715 - val_loss: 0.6755 - val_accuracy: 0.8425\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5578 - accuracy: 0.8706 - val_loss: 0.6701 - val_accuracy: 0.8423\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5514 - accuracy: 0.8705 - val_loss: 0.6925 - val_accuracy: 0.8360\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5575 - accuracy: 0.8709 - val_loss: 0.6655 - val_accuracy: 0.8440\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5524 - accuracy: 0.8721 - val_loss: 0.6729 - val_accuracy: 0.8401\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5535 - accuracy: 0.8720 - val_loss: 0.6429 - val_accuracy: 0.8473\n",
      "313/313 - 1s - loss: 0.6429 - accuracy: 0.8473\n",
      "Test accuracy: 0.8472999930381775\n",
      "NET  9\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5821 - accuracy: 0.1538 - val_loss: 2.7721 - val_accuracy: 0.1159\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1554 - accuracy: 0.2348 - val_loss: 2.0802 - val_accuracy: 0.2618\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9940 - accuracy: 0.2897 - val_loss: 1.9046 - val_accuracy: 0.3375\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8799 - accuracy: 0.3407 - val_loss: 2.0857 - val_accuracy: 0.2975\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7953 - accuracy: 0.3843 - val_loss: 1.6850 - val_accuracy: 0.4354\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6888 - accuracy: 0.4440 - val_loss: 1.5414 - val_accuracy: 0.5129\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5566 - accuracy: 0.5058 - val_loss: 1.4205 - val_accuracy: 0.5647\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4529 - accuracy: 0.5488 - val_loss: 1.3056 - val_accuracy: 0.6134\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3781 - accuracy: 0.5788 - val_loss: 1.2828 - val_accuracy: 0.6044\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3128 - accuracy: 0.6011 - val_loss: 1.2149 - val_accuracy: 0.6377\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2497 - accuracy: 0.6191 - val_loss: 1.1407 - val_accuracy: 0.6571\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2020 - accuracy: 0.6371 - val_loss: 1.1312 - val_accuracy: 0.6603\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1742 - accuracy: 0.6438 - val_loss: 1.0782 - val_accuracy: 0.6736\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1302 - accuracy: 0.6585 - val_loss: 1.0300 - val_accuracy: 0.6855\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0951 - accuracy: 0.6701 - val_loss: 1.0247 - val_accuracy: 0.6889\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0675 - accuracy: 0.6802 - val_loss: 0.9797 - val_accuracy: 0.7070\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0344 - accuracy: 0.6901 - val_loss: 0.9530 - val_accuracy: 0.7112\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0012 - accuracy: 0.7007 - val_loss: 0.9337 - val_accuracy: 0.7197\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9878 - accuracy: 0.7013 - val_loss: 0.9332 - val_accuracy: 0.7191\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9542 - accuracy: 0.7152 - val_loss: 0.8870 - val_accuracy: 0.7328\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9386 - accuracy: 0.7203 - val_loss: 0.8727 - val_accuracy: 0.7424\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9230 - accuracy: 0.7266 - val_loss: 0.8970 - val_accuracy: 0.7313\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.9060 - accuracy: 0.7330 - val_loss: 0.8761 - val_accuracy: 0.7466\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8842 - accuracy: 0.7414 - val_loss: 0.8281 - val_accuracy: 0.7549\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8752 - accuracy: 0.7434 - val_loss: 0.7999 - val_accuracy: 0.7671\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8601 - accuracy: 0.7497 - val_loss: 0.8033 - val_accuracy: 0.7677\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8345 - accuracy: 0.7586 - val_loss: 0.7763 - val_accuracy: 0.7789\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8195 - accuracy: 0.7643 - val_loss: 0.8279 - val_accuracy: 0.7575\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8193 - accuracy: 0.7641 - val_loss: 0.7848 - val_accuracy: 0.7681\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.8026 - accuracy: 0.7701 - val_loss: 0.8184 - val_accuracy: 0.7580\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7890 - accuracy: 0.7741 - val_loss: 0.7657 - val_accuracy: 0.7730\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7791 - accuracy: 0.7811 - val_loss: 0.7630 - val_accuracy: 0.7811\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7707 - accuracy: 0.7821 - val_loss: 0.7799 - val_accuracy: 0.7748\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7572 - accuracy: 0.7859 - val_loss: 0.7746 - val_accuracy: 0.7808\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7442 - accuracy: 0.7922 - val_loss: 0.7497 - val_accuracy: 0.7882\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7430 - accuracy: 0.7919 - val_loss: 0.7585 - val_accuracy: 0.7856\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7343 - accuracy: 0.7960 - val_loss: 0.7501 - val_accuracy: 0.7887\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7271 - accuracy: 0.8003 - val_loss: 0.8255 - val_accuracy: 0.7644\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7154 - accuracy: 0.8021 - val_loss: 0.6981 - val_accuracy: 0.8078\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7100 - accuracy: 0.8055 - val_loss: 0.7545 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7004 - accuracy: 0.8094 - val_loss: 0.7180 - val_accuracy: 0.8014\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6993 - accuracy: 0.8090 - val_loss: 0.7014 - val_accuracy: 0.8103\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6977 - accuracy: 0.8095 - val_loss: 0.7190 - val_accuracy: 0.8003\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6859 - accuracy: 0.8146 - val_loss: 0.6987 - val_accuracy: 0.8075\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6777 - accuracy: 0.8171 - val_loss: 0.7192 - val_accuracy: 0.7980\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6693 - accuracy: 0.8196 - val_loss: 0.7403 - val_accuracy: 0.7972\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6665 - accuracy: 0.8215 - val_loss: 0.7135 - val_accuracy: 0.8031\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6620 - accuracy: 0.8227 - val_loss: 0.7070 - val_accuracy: 0.8056\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6585 - accuracy: 0.8224 - val_loss: 0.6756 - val_accuracy: 0.8163\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6542 - accuracy: 0.8254 - val_loss: 0.7214 - val_accuracy: 0.8008\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6553 - accuracy: 0.8251 - val_loss: 0.7958 - val_accuracy: 0.7866\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6546 - accuracy: 0.8268 - val_loss: 0.6739 - val_accuracy: 0.8180\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6352 - accuracy: 0.8310 - val_loss: 0.6968 - val_accuracy: 0.8121\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6400 - accuracy: 0.8304 - val_loss: 0.6680 - val_accuracy: 0.8226\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6346 - accuracy: 0.8322 - val_loss: 0.6751 - val_accuracy: 0.8200\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6319 - accuracy: 0.8355 - val_loss: 0.6905 - val_accuracy: 0.8185\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6284 - accuracy: 0.8346 - val_loss: 0.6493 - val_accuracy: 0.8319\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6221 - accuracy: 0.8374 - val_loss: 0.6526 - val_accuracy: 0.8195\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6226 - accuracy: 0.8369 - val_loss: 0.6928 - val_accuracy: 0.8142\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6274 - accuracy: 0.8361 - val_loss: 0.6865 - val_accuracy: 0.8173\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6144 - accuracy: 0.8396 - val_loss: 0.6723 - val_accuracy: 0.8253\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6172 - accuracy: 0.8392 - val_loss: 0.7055 - val_accuracy: 0.8104\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6140 - accuracy: 0.8414 - val_loss: 0.6711 - val_accuracy: 0.8262\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6045 - accuracy: 0.8414 - val_loss: 0.6836 - val_accuracy: 0.8217\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6055 - accuracy: 0.8432 - val_loss: 0.7021 - val_accuracy: 0.8142\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6074 - accuracy: 0.8452 - val_loss: 0.6976 - val_accuracy: 0.8162\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5994 - accuracy: 0.8483 - val_loss: 0.6766 - val_accuracy: 0.8205\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6023 - accuracy: 0.8455 - val_loss: 0.7128 - val_accuracy: 0.8103\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6020 - accuracy: 0.8458 - val_loss: 0.6616 - val_accuracy: 0.8276\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5980 - accuracy: 0.8476 - val_loss: 0.6732 - val_accuracy: 0.8231\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5940 - accuracy: 0.8491 - val_loss: 0.6708 - val_accuracy: 0.8276\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5878 - accuracy: 0.8479 - val_loss: 0.6521 - val_accuracy: 0.8330\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5919 - accuracy: 0.8501 - val_loss: 0.6574 - val_accuracy: 0.8297\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5895 - accuracy: 0.8499 - val_loss: 0.6767 - val_accuracy: 0.8238\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5918 - accuracy: 0.8507 - val_loss: 0.6772 - val_accuracy: 0.8254\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5854 - accuracy: 0.8528 - val_loss: 0.6747 - val_accuracy: 0.8256\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5795 - accuracy: 0.8537 - val_loss: 0.6754 - val_accuracy: 0.8241\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5856 - accuracy: 0.8525 - val_loss: 0.6867 - val_accuracy: 0.8232\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5840 - accuracy: 0.8529 - val_loss: 0.6567 - val_accuracy: 0.8308\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5797 - accuracy: 0.8538 - val_loss: 0.6323 - val_accuracy: 0.8424\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5760 - accuracy: 0.8569 - val_loss: 0.6338 - val_accuracy: 0.8396\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5729 - accuracy: 0.8567 - val_loss: 0.6712 - val_accuracy: 0.8241\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5730 - accuracy: 0.8571 - val_loss: 0.6722 - val_accuracy: 0.8270\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5728 - accuracy: 0.8574 - val_loss: 0.6785 - val_accuracy: 0.8279\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5762 - accuracy: 0.8556 - val_loss: 0.6450 - val_accuracy: 0.8369\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5685 - accuracy: 0.8586 - val_loss: 0.6435 - val_accuracy: 0.8364\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5737 - accuracy: 0.8576 - val_loss: 0.6496 - val_accuracy: 0.8369\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5692 - accuracy: 0.8592 - val_loss: 0.6827 - val_accuracy: 0.8261\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5640 - accuracy: 0.8593 - val_loss: 0.6701 - val_accuracy: 0.8322\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5617 - accuracy: 0.8601 - val_loss: 0.6381 - val_accuracy: 0.8364\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5515 - accuracy: 0.8641 - val_loss: 0.6662 - val_accuracy: 0.8324\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5612 - accuracy: 0.8616 - val_loss: 0.6237 - val_accuracy: 0.8439\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5601 - accuracy: 0.8614 - val_loss: 0.6295 - val_accuracy: 0.8451\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5606 - accuracy: 0.8624 - val_loss: 0.6741 - val_accuracy: 0.8278\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5613 - accuracy: 0.8618 - val_loss: 0.6411 - val_accuracy: 0.8396\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5607 - accuracy: 0.8621 - val_loss: 0.6372 - val_accuracy: 0.8412\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5572 - accuracy: 0.8622 - val_loss: 0.6586 - val_accuracy: 0.8308\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5559 - accuracy: 0.8656 - val_loss: 0.6842 - val_accuracy: 0.8275\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5537 - accuracy: 0.8640 - val_loss: 0.6206 - val_accuracy: 0.8431\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5556 - accuracy: 0.8646 - val_loss: 0.7045 - val_accuracy: 0.8208\n",
      "313/313 - 1s - loss: 0.7045 - accuracy: 0.8208\n",
      "Test accuracy: 0.8208000063896179\n",
      "NET  10\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5639 - accuracy: 0.1976 - val_loss: 2.5793 - val_accuracy: 0.1923\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0849 - accuracy: 0.3127 - val_loss: 2.0202 - val_accuracy: 0.3328\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9165 - accuracy: 0.3721 - val_loss: 1.7933 - val_accuracy: 0.4186\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7898 - accuracy: 0.4188 - val_loss: 1.6680 - val_accuracy: 0.4625\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7028 - accuracy: 0.4541 - val_loss: 1.7756 - val_accuracy: 0.4440\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6218 - accuracy: 0.4861 - val_loss: 1.4633 - val_accuracy: 0.5388\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5259 - accuracy: 0.5223 - val_loss: 1.4129 - val_accuracy: 0.5580\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4422 - accuracy: 0.5518 - val_loss: 1.3872 - val_accuracy: 0.5564\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3770 - accuracy: 0.5768 - val_loss: 1.2389 - val_accuracy: 0.6070\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3088 - accuracy: 0.6001 - val_loss: 1.2570 - val_accuracy: 0.6072\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2533 - accuracy: 0.6194 - val_loss: 1.2804 - val_accuracy: 0.6004\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2096 - accuracy: 0.6328 - val_loss: 1.0805 - val_accuracy: 0.6710\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1643 - accuracy: 0.6445 - val_loss: 1.0707 - val_accuracy: 0.6640\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1386 - accuracy: 0.6535 - val_loss: 1.0287 - val_accuracy: 0.6831\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0949 - accuracy: 0.6674 - val_loss: 1.0572 - val_accuracy: 0.6730\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0651 - accuracy: 0.6768 - val_loss: 0.9814 - val_accuracy: 0.7004\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0435 - accuracy: 0.6858 - val_loss: 1.0113 - val_accuracy: 0.6876\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0080 - accuracy: 0.6992 - val_loss: 1.0278 - val_accuracy: 0.6841\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9892 - accuracy: 0.7048 - val_loss: 0.9050 - val_accuracy: 0.7262\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9571 - accuracy: 0.7120 - val_loss: 0.9092 - val_accuracy: 0.7251\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9488 - accuracy: 0.7172 - val_loss: 0.8495 - val_accuracy: 0.7456\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9201 - accuracy: 0.7288 - val_loss: 0.8855 - val_accuracy: 0.7328\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8985 - accuracy: 0.7369 - val_loss: 0.9176 - val_accuracy: 0.7209\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8783 - accuracy: 0.7423 - val_loss: 0.8345 - val_accuracy: 0.7515\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8636 - accuracy: 0.7482 - val_loss: 0.8149 - val_accuracy: 0.7622\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8466 - accuracy: 0.7537 - val_loss: 0.7916 - val_accuracy: 0.7717\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8299 - accuracy: 0.7599 - val_loss: 0.7709 - val_accuracy: 0.7762\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8210 - accuracy: 0.7620 - val_loss: 0.7733 - val_accuracy: 0.7754\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8028 - accuracy: 0.7708 - val_loss: 0.7527 - val_accuracy: 0.7786\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7956 - accuracy: 0.7717 - val_loss: 0.8033 - val_accuracy: 0.7721\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7800 - accuracy: 0.7778 - val_loss: 0.7239 - val_accuracy: 0.7904\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7681 - accuracy: 0.7824 - val_loss: 0.7483 - val_accuracy: 0.7856\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7585 - accuracy: 0.7859 - val_loss: 0.7572 - val_accuracy: 0.7816\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7408 - accuracy: 0.7912 - val_loss: 0.7489 - val_accuracy: 0.7906\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7284 - accuracy: 0.7970 - val_loss: 0.7514 - val_accuracy: 0.7840\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7251 - accuracy: 0.7970 - val_loss: 0.7186 - val_accuracy: 0.7976\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7187 - accuracy: 0.8010 - val_loss: 0.7700 - val_accuracy: 0.7858\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7120 - accuracy: 0.8036 - val_loss: 0.6896 - val_accuracy: 0.8111\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7033 - accuracy: 0.8063 - val_loss: 0.7055 - val_accuracy: 0.8027\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6974 - accuracy: 0.8089 - val_loss: 0.7674 - val_accuracy: 0.7943\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6953 - accuracy: 0.8114 - val_loss: 0.7048 - val_accuracy: 0.8040\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7038 - accuracy: 0.8061 - val_loss: 0.7270 - val_accuracy: 0.7987\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6733 - accuracy: 0.8189 - val_loss: 0.6910 - val_accuracy: 0.8110\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6781 - accuracy: 0.8178 - val_loss: 0.7119 - val_accuracy: 0.8030\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6599 - accuracy: 0.8242 - val_loss: 0.7127 - val_accuracy: 0.8030\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6575 - accuracy: 0.8238 - val_loss: 0.7028 - val_accuracy: 0.8097\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6583 - accuracy: 0.8243 - val_loss: 0.6874 - val_accuracy: 0.8161\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6522 - accuracy: 0.8262 - val_loss: 0.7712 - val_accuracy: 0.7936\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6504 - accuracy: 0.8291 - val_loss: 0.6790 - val_accuracy: 0.8165\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6448 - accuracy: 0.8277 - val_loss: 0.6637 - val_accuracy: 0.8204\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6418 - accuracy: 0.8299 - val_loss: 0.6781 - val_accuracy: 0.8197\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6373 - accuracy: 0.8328 - val_loss: 0.6647 - val_accuracy: 0.8215\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6248 - accuracy: 0.8352 - val_loss: 0.6487 - val_accuracy: 0.8277\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6238 - accuracy: 0.8367 - val_loss: 0.6599 - val_accuracy: 0.8268\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6232 - accuracy: 0.8370 - val_loss: 0.7281 - val_accuracy: 0.8088\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6210 - accuracy: 0.8391 - val_loss: 0.6468 - val_accuracy: 0.8289\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6189 - accuracy: 0.8382 - val_loss: 0.6899 - val_accuracy: 0.8208\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6175 - accuracy: 0.8397 - val_loss: 0.6350 - val_accuracy: 0.8329\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6152 - accuracy: 0.8405 - val_loss: 0.6887 - val_accuracy: 0.8223\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6103 - accuracy: 0.8436 - val_loss: 0.6750 - val_accuracy: 0.8164\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6012 - accuracy: 0.8481 - val_loss: 0.6532 - val_accuracy: 0.8298\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6040 - accuracy: 0.8462 - val_loss: 0.7082 - val_accuracy: 0.8165\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5968 - accuracy: 0.8477 - val_loss: 0.6979 - val_accuracy: 0.8193\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6055 - accuracy: 0.8449 - val_loss: 0.6606 - val_accuracy: 0.8243\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5982 - accuracy: 0.8469 - val_loss: 0.7250 - val_accuracy: 0.8113\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5907 - accuracy: 0.8490 - val_loss: 0.6520 - val_accuracy: 0.8360\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5950 - accuracy: 0.8484 - val_loss: 0.6737 - val_accuracy: 0.8278\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5885 - accuracy: 0.8500 - val_loss: 0.6677 - val_accuracy: 0.8261\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5845 - accuracy: 0.8525 - val_loss: 0.6620 - val_accuracy: 0.8311\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5818 - accuracy: 0.8527 - val_loss: 0.6931 - val_accuracy: 0.8196\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5878 - accuracy: 0.8529 - val_loss: 0.6710 - val_accuracy: 0.8314\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5825 - accuracy: 0.8538 - val_loss: 0.6653 - val_accuracy: 0.8285\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5772 - accuracy: 0.8554 - val_loss: 0.6823 - val_accuracy: 0.8266\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5690 - accuracy: 0.8573 - val_loss: 0.6470 - val_accuracy: 0.8358\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5762 - accuracy: 0.8573 - val_loss: 0.6470 - val_accuracy: 0.8346\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5731 - accuracy: 0.8560 - val_loss: 0.6563 - val_accuracy: 0.8326\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5802 - accuracy: 0.8544 - val_loss: 0.6606 - val_accuracy: 0.8354\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5701 - accuracy: 0.8591 - val_loss: 0.6602 - val_accuracy: 0.8300\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5712 - accuracy: 0.8596 - val_loss: 0.6713 - val_accuracy: 0.8283\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5660 - accuracy: 0.8590 - val_loss: 0.6380 - val_accuracy: 0.8368\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5708 - accuracy: 0.8600 - val_loss: 0.6220 - val_accuracy: 0.8451\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5674 - accuracy: 0.8592 - val_loss: 0.6196 - val_accuracy: 0.8469\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5645 - accuracy: 0.8628 - val_loss: 0.6775 - val_accuracy: 0.8291\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5582 - accuracy: 0.8612 - val_loss: 0.6586 - val_accuracy: 0.8327\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5582 - accuracy: 0.8621 - val_loss: 0.6201 - val_accuracy: 0.8451\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5559 - accuracy: 0.8643 - val_loss: 0.7254 - val_accuracy: 0.8164\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5516 - accuracy: 0.8669 - val_loss: 0.6529 - val_accuracy: 0.8352\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5571 - accuracy: 0.8644 - val_loss: 0.6372 - val_accuracy: 0.8461\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5610 - accuracy: 0.8644 - val_loss: 0.6495 - val_accuracy: 0.8405\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5444 - accuracy: 0.8678 - val_loss: 0.6737 - val_accuracy: 0.8348\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5488 - accuracy: 0.8666 - val_loss: 0.6989 - val_accuracy: 0.8242\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5493 - accuracy: 0.8662 - val_loss: 0.6728 - val_accuracy: 0.8324\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5455 - accuracy: 0.8683 - val_loss: 0.6277 - val_accuracy: 0.8434\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5414 - accuracy: 0.8686 - val_loss: 0.6925 - val_accuracy: 0.8273\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5443 - accuracy: 0.8692 - val_loss: 0.6414 - val_accuracy: 0.8407\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5451 - accuracy: 0.8679 - val_loss: 0.6216 - val_accuracy: 0.8433\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5419 - accuracy: 0.8681 - val_loss: 0.7316 - val_accuracy: 0.8191\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5467 - accuracy: 0.8690 - val_loss: 0.6357 - val_accuracy: 0.8412\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5414 - accuracy: 0.8688 - val_loss: 0.6658 - val_accuracy: 0.8348\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5437 - accuracy: 0.8702 - val_loss: 0.6947 - val_accuracy: 0.8268\n",
      "313/313 - 1s - loss: 0.6947 - accuracy: 0.8268\n",
      "Test accuracy: 0.8267999887466431\n",
      "NET  11\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5690 - accuracy: 0.1749 - val_loss: 2.5542 - val_accuracy: 0.1291\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0836 - accuracy: 0.2916 - val_loss: 2.1145 - val_accuracy: 0.3155\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.8829 - accuracy: 0.3729 - val_loss: 1.8310 - val_accuracy: 0.4080\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7478 - accuracy: 0.4345 - val_loss: 1.6710 - val_accuracy: 0.4715\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.6260 - accuracy: 0.4919 - val_loss: 1.5848 - val_accuracy: 0.5005\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.5247 - accuracy: 0.5303 - val_loss: 1.4393 - val_accuracy: 0.5636\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.4467 - accuracy: 0.5616 - val_loss: 1.3508 - val_accuracy: 0.5750\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.3699 - accuracy: 0.5903 - val_loss: 1.3039 - val_accuracy: 0.6091\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3156 - accuracy: 0.6080 - val_loss: 1.2445 - val_accuracy: 0.6250\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2612 - accuracy: 0.6241 - val_loss: 1.1450 - val_accuracy: 0.6584\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2119 - accuracy: 0.6419 - val_loss: 1.2221 - val_accuracy: 0.6235\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1653 - accuracy: 0.6541 - val_loss: 1.1617 - val_accuracy: 0.6408\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1335 - accuracy: 0.6640 - val_loss: 1.0295 - val_accuracy: 0.6902\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0906 - accuracy: 0.6787 - val_loss: 1.0602 - val_accuracy: 0.6798\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0672 - accuracy: 0.6850 - val_loss: 0.9639 - val_accuracy: 0.7107\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0291 - accuracy: 0.6981 - val_loss: 0.9639 - val_accuracy: 0.7120\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9996 - accuracy: 0.7075 - val_loss: 0.9675 - val_accuracy: 0.7141\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9820 - accuracy: 0.7126 - val_loss: 0.8875 - val_accuracy: 0.7425\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9521 - accuracy: 0.7235 - val_loss: 0.9566 - val_accuracy: 0.7180\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9362 - accuracy: 0.7282 - val_loss: 0.8439 - val_accuracy: 0.7495\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9043 - accuracy: 0.7395 - val_loss: 0.8379 - val_accuracy: 0.7524\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8867 - accuracy: 0.7451 - val_loss: 0.8471 - val_accuracy: 0.7535\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8737 - accuracy: 0.7493 - val_loss: 0.8463 - val_accuracy: 0.7525\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8491 - accuracy: 0.7583 - val_loss: 0.8110 - val_accuracy: 0.7604\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8388 - accuracy: 0.7625 - val_loss: 0.7591 - val_accuracy: 0.7780\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8278 - accuracy: 0.7650 - val_loss: 0.8068 - val_accuracy: 0.7703\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8190 - accuracy: 0.7685 - val_loss: 0.7878 - val_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7952 - accuracy: 0.7751 - val_loss: 0.7752 - val_accuracy: 0.7809\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7861 - accuracy: 0.7794 - val_loss: 0.7677 - val_accuracy: 0.7837\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7677 - accuracy: 0.7862 - val_loss: 0.7434 - val_accuracy: 0.7870\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7629 - accuracy: 0.7860 - val_loss: 0.7620 - val_accuracy: 0.7805\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7552 - accuracy: 0.7915 - val_loss: 0.7251 - val_accuracy: 0.8010\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7406 - accuracy: 0.7960 - val_loss: 0.7601 - val_accuracy: 0.7895\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7318 - accuracy: 0.7992 - val_loss: 0.7248 - val_accuracy: 0.8008\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7333 - accuracy: 0.8001 - val_loss: 0.7566 - val_accuracy: 0.7905\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7164 - accuracy: 0.8043 - val_loss: 0.7549 - val_accuracy: 0.7906\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7069 - accuracy: 0.8071 - val_loss: 0.7168 - val_accuracy: 0.8012\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7017 - accuracy: 0.8123 - val_loss: 0.7280 - val_accuracy: 0.7955\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7014 - accuracy: 0.8096 - val_loss: 0.7708 - val_accuracy: 0.7895\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6881 - accuracy: 0.8161 - val_loss: 0.7060 - val_accuracy: 0.8088\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6806 - accuracy: 0.8194 - val_loss: 0.6996 - val_accuracy: 0.8097\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6827 - accuracy: 0.8187 - val_loss: 0.7431 - val_accuracy: 0.8011\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6739 - accuracy: 0.8214 - val_loss: 0.7102 - val_accuracy: 0.8070\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6666 - accuracy: 0.8234 - val_loss: 0.6856 - val_accuracy: 0.8154\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6661 - accuracy: 0.8234 - val_loss: 0.6749 - val_accuracy: 0.8220\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6571 - accuracy: 0.8260 - val_loss: 0.7213 - val_accuracy: 0.8090\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6583 - accuracy: 0.8281 - val_loss: 0.6846 - val_accuracy: 0.8183\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6470 - accuracy: 0.8315 - val_loss: 0.7106 - val_accuracy: 0.8123\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6529 - accuracy: 0.8306 - val_loss: 0.6875 - val_accuracy: 0.8159\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6394 - accuracy: 0.8334 - val_loss: 0.6675 - val_accuracy: 0.8265\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6403 - accuracy: 0.8349 - val_loss: 0.6631 - val_accuracy: 0.8294\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6364 - accuracy: 0.8372 - val_loss: 0.7032 - val_accuracy: 0.8198\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6292 - accuracy: 0.8367 - val_loss: 0.6725 - val_accuracy: 0.8226\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6292 - accuracy: 0.8384 - val_loss: 0.6884 - val_accuracy: 0.8268\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6218 - accuracy: 0.8411 - val_loss: 0.6709 - val_accuracy: 0.8268\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6211 - accuracy: 0.8406 - val_loss: 0.6587 - val_accuracy: 0.8283\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6180 - accuracy: 0.8420 - val_loss: 0.6670 - val_accuracy: 0.8273\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6112 - accuracy: 0.8449 - val_loss: 0.7235 - val_accuracy: 0.8134\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6177 - accuracy: 0.8426 - val_loss: 0.6710 - val_accuracy: 0.8328\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6052 - accuracy: 0.8480 - val_loss: 0.6761 - val_accuracy: 0.8306\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6103 - accuracy: 0.8450 - val_loss: 0.6954 - val_accuracy: 0.8235\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6100 - accuracy: 0.8468 - val_loss: 0.6897 - val_accuracy: 0.8207\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6085 - accuracy: 0.8481 - val_loss: 0.6806 - val_accuracy: 0.8312\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5980 - accuracy: 0.8509 - val_loss: 0.6639 - val_accuracy: 0.8327\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5955 - accuracy: 0.8508 - val_loss: 0.6881 - val_accuracy: 0.8234\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5875 - accuracy: 0.8529 - val_loss: 0.6669 - val_accuracy: 0.8309\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5900 - accuracy: 0.8556 - val_loss: 0.7202 - val_accuracy: 0.8158\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5889 - accuracy: 0.8540 - val_loss: 0.6674 - val_accuracy: 0.8334\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5930 - accuracy: 0.8524 - val_loss: 0.6650 - val_accuracy: 0.8345\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5870 - accuracy: 0.8537 - val_loss: 0.7011 - val_accuracy: 0.8233\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5961 - accuracy: 0.8532 - val_loss: 0.6725 - val_accuracy: 0.8316\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5770 - accuracy: 0.8592 - val_loss: 0.6806 - val_accuracy: 0.8289\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5862 - accuracy: 0.8560 - val_loss: 0.6694 - val_accuracy: 0.8322\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5767 - accuracy: 0.8584 - val_loss: 0.6541 - val_accuracy: 0.8354\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5817 - accuracy: 0.8583 - val_loss: 0.6671 - val_accuracy: 0.8335\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5790 - accuracy: 0.8592 - val_loss: 0.6822 - val_accuracy: 0.8283\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5701 - accuracy: 0.8599 - val_loss: 0.6919 - val_accuracy: 0.8293\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5737 - accuracy: 0.8585 - val_loss: 0.6569 - val_accuracy: 0.8382\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5734 - accuracy: 0.8604 - val_loss: 0.6898 - val_accuracy: 0.8311\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5691 - accuracy: 0.8620 - val_loss: 0.7074 - val_accuracy: 0.8257\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5732 - accuracy: 0.8610 - val_loss: 0.6840 - val_accuracy: 0.8295\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5666 - accuracy: 0.8625 - val_loss: 0.6541 - val_accuracy: 0.8403\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5650 - accuracy: 0.8638 - val_loss: 0.6748 - val_accuracy: 0.8359\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5688 - accuracy: 0.8633 - val_loss: 0.6694 - val_accuracy: 0.8367\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5626 - accuracy: 0.8651 - val_loss: 0.6455 - val_accuracy: 0.8422\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5546 - accuracy: 0.8688 - val_loss: 0.6831 - val_accuracy: 0.8351\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5614 - accuracy: 0.8653 - val_loss: 0.6519 - val_accuracy: 0.8398\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5530 - accuracy: 0.8683 - val_loss: 0.6555 - val_accuracy: 0.8447\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5580 - accuracy: 0.8662 - val_loss: 0.6959 - val_accuracy: 0.8316\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5539 - accuracy: 0.8677 - val_loss: 0.7021 - val_accuracy: 0.8335\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5515 - accuracy: 0.8700 - val_loss: 0.6244 - val_accuracy: 0.8484\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5487 - accuracy: 0.8701 - val_loss: 0.6717 - val_accuracy: 0.8441\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5534 - accuracy: 0.8688 - val_loss: 0.6964 - val_accuracy: 0.8270\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5571 - accuracy: 0.8696 - val_loss: 0.6477 - val_accuracy: 0.8448\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5482 - accuracy: 0.8705 - val_loss: 0.6913 - val_accuracy: 0.8328\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5462 - accuracy: 0.8700 - val_loss: 0.6543 - val_accuracy: 0.8419\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5449 - accuracy: 0.8713 - val_loss: 0.6561 - val_accuracy: 0.8439\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5424 - accuracy: 0.8744 - val_loss: 0.6661 - val_accuracy: 0.8395\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5458 - accuracy: 0.8720 - val_loss: 0.6339 - val_accuracy: 0.8451\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5446 - accuracy: 0.8736 - val_loss: 0.6472 - val_accuracy: 0.8435\n",
      "313/313 - 1s - loss: 0.6472 - accuracy: 0.8435\n",
      "Test accuracy: 0.843500018119812\n",
      "NET  12\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5665 - accuracy: 0.1679 - val_loss: 2.3072 - val_accuracy: 0.2127\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1958 - accuracy: 0.2299 - val_loss: 2.1403 - val_accuracy: 0.2728\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 2.0642 - accuracy: 0.2991 - val_loss: 1.9185 - val_accuracy: 0.3582\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.9127 - accuracy: 0.3569 - val_loss: 1.7479 - val_accuracy: 0.4288\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7970 - accuracy: 0.4036 - val_loss: 1.7134 - val_accuracy: 0.4357\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.7145 - accuracy: 0.4345 - val_loss: 1.7651 - val_accuracy: 0.4286\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.6360 - accuracy: 0.4655 - val_loss: 1.5530 - val_accuracy: 0.4884\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.5629 - accuracy: 0.4911 - val_loss: 1.4784 - val_accuracy: 0.5144\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.4928 - accuracy: 0.5193 - val_loss: 1.3708 - val_accuracy: 0.5662\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.4313 - accuracy: 0.5462 - val_loss: 1.3579 - val_accuracy: 0.5749\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.3636 - accuracy: 0.5711 - val_loss: 1.2685 - val_accuracy: 0.5977\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.3080 - accuracy: 0.5915 - val_loss: 1.2083 - val_accuracy: 0.6153\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.2572 - accuracy: 0.6099 - val_loss: 1.2019 - val_accuracy: 0.6171\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.2015 - accuracy: 0.6280 - val_loss: 1.1763 - val_accuracy: 0.6206\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1591 - accuracy: 0.6437 - val_loss: 1.0849 - val_accuracy: 0.6612\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.1186 - accuracy: 0.6549 - val_loss: 1.0630 - val_accuracy: 0.6631\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0772 - accuracy: 0.6700 - val_loss: 0.9963 - val_accuracy: 0.6984\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0556 - accuracy: 0.6792 - val_loss: 1.0039 - val_accuracy: 0.6847\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 1.0170 - accuracy: 0.6883 - val_loss: 0.9508 - val_accuracy: 0.7063\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9884 - accuracy: 0.7016 - val_loss: 0.9695 - val_accuracy: 0.7016\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9713 - accuracy: 0.7085 - val_loss: 0.8778 - val_accuracy: 0.7358\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9413 - accuracy: 0.7153 - val_loss: 0.8718 - val_accuracy: 0.7353\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.9179 - accuracy: 0.7262 - val_loss: 0.8559 - val_accuracy: 0.7434\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8936 - accuracy: 0.7334 - val_loss: 0.8754 - val_accuracy: 0.7350\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8823 - accuracy: 0.7376 - val_loss: 0.8456 - val_accuracy: 0.7442\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8662 - accuracy: 0.7428 - val_loss: 0.8237 - val_accuracy: 0.7586\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8497 - accuracy: 0.7493 - val_loss: 0.8080 - val_accuracy: 0.7625\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8312 - accuracy: 0.7544 - val_loss: 0.8053 - val_accuracy: 0.7615\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8191 - accuracy: 0.7601 - val_loss: 0.8020 - val_accuracy: 0.7651\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.8082 - accuracy: 0.7664 - val_loss: 0.7561 - val_accuracy: 0.7835\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7984 - accuracy: 0.7702 - val_loss: 0.7653 - val_accuracy: 0.7796\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7822 - accuracy: 0.7751 - val_loss: 0.7827 - val_accuracy: 0.7754\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7756 - accuracy: 0.7769 - val_loss: 0.7883 - val_accuracy: 0.7744\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7703 - accuracy: 0.7820 - val_loss: 0.7524 - val_accuracy: 0.7825\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7554 - accuracy: 0.7834 - val_loss: 0.7344 - val_accuracy: 0.7922\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7499 - accuracy: 0.7872 - val_loss: 0.7283 - val_accuracy: 0.7929\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7406 - accuracy: 0.7919 - val_loss: 0.7146 - val_accuracy: 0.8008\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7237 - accuracy: 0.7980 - val_loss: 0.7142 - val_accuracy: 0.7982\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7272 - accuracy: 0.7949 - val_loss: 0.7224 - val_accuracy: 0.7983\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7152 - accuracy: 0.8037 - val_loss: 0.6898 - val_accuracy: 0.8081\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7156 - accuracy: 0.8011 - val_loss: 0.7472 - val_accuracy: 0.7925\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7146 - accuracy: 0.8025 - val_loss: 0.7189 - val_accuracy: 0.7996\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6935 - accuracy: 0.8089 - val_loss: 0.7363 - val_accuracy: 0.7948\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6929 - accuracy: 0.8106 - val_loss: 0.7262 - val_accuracy: 0.7950\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6783 - accuracy: 0.8160 - val_loss: 0.7262 - val_accuracy: 0.8002\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6875 - accuracy: 0.8129 - val_loss: 0.6650 - val_accuracy: 0.8187\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6736 - accuracy: 0.8174 - val_loss: 0.6863 - val_accuracy: 0.8148\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6634 - accuracy: 0.8204 - val_loss: 0.7381 - val_accuracy: 0.8001\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6650 - accuracy: 0.8201 - val_loss: 0.7027 - val_accuracy: 0.8076\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6561 - accuracy: 0.8256 - val_loss: 0.7075 - val_accuracy: 0.8071\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6567 - accuracy: 0.8253 - val_loss: 0.6570 - val_accuracy: 0.8240\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6570 - accuracy: 0.8233 - val_loss: 0.7029 - val_accuracy: 0.8097\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6462 - accuracy: 0.8269 - val_loss: 0.6913 - val_accuracy: 0.8139\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6497 - accuracy: 0.8280 - val_loss: 0.7181 - val_accuracy: 0.8066\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6432 - accuracy: 0.8312 - val_loss: 0.6472 - val_accuracy: 0.8304\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6397 - accuracy: 0.8310 - val_loss: 0.7128 - val_accuracy: 0.8071\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6362 - accuracy: 0.8341 - val_loss: 0.6830 - val_accuracy: 0.8153\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6281 - accuracy: 0.8345 - val_loss: 0.6704 - val_accuracy: 0.8226\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6231 - accuracy: 0.8368 - val_loss: 0.6846 - val_accuracy: 0.8187\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6208 - accuracy: 0.8380 - val_loss: 0.6621 - val_accuracy: 0.8242\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6244 - accuracy: 0.8371 - val_loss: 0.6881 - val_accuracy: 0.8172\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6191 - accuracy: 0.8389 - val_loss: 0.6944 - val_accuracy: 0.8123\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6156 - accuracy: 0.8410 - val_loss: 0.7071 - val_accuracy: 0.8144\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6093 - accuracy: 0.8420 - val_loss: 0.6887 - val_accuracy: 0.8178\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6201 - accuracy: 0.8394 - val_loss: 0.6965 - val_accuracy: 0.8174\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6042 - accuracy: 0.8437 - val_loss: 0.6830 - val_accuracy: 0.8217\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6030 - accuracy: 0.8452 - val_loss: 0.6494 - val_accuracy: 0.8326\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6010 - accuracy: 0.8475 - val_loss: 0.6466 - val_accuracy: 0.8330\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5986 - accuracy: 0.8486 - val_loss: 0.6652 - val_accuracy: 0.8285\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5930 - accuracy: 0.8493 - val_loss: 0.6473 - val_accuracy: 0.8335\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5929 - accuracy: 0.8486 - val_loss: 0.6340 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5944 - accuracy: 0.8486 - val_loss: 0.7343 - val_accuracy: 0.8121\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5955 - accuracy: 0.8485 - val_loss: 0.6997 - val_accuracy: 0.8207\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5885 - accuracy: 0.8510 - val_loss: 0.6554 - val_accuracy: 0.8328\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5926 - accuracy: 0.8505 - val_loss: 0.6754 - val_accuracy: 0.8194\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5886 - accuracy: 0.8508 - val_loss: 0.6801 - val_accuracy: 0.8239\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5888 - accuracy: 0.8500 - val_loss: 0.6760 - val_accuracy: 0.8240\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5837 - accuracy: 0.8539 - val_loss: 0.6886 - val_accuracy: 0.8206\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5848 - accuracy: 0.8540 - val_loss: 0.7483 - val_accuracy: 0.8073\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5790 - accuracy: 0.8546 - val_loss: 0.6486 - val_accuracy: 0.8320\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5744 - accuracy: 0.8568 - val_loss: 0.6502 - val_accuracy: 0.8345\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5744 - accuracy: 0.8572 - val_loss: 0.6539 - val_accuracy: 0.8296\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5742 - accuracy: 0.8571 - val_loss: 0.6507 - val_accuracy: 0.8352\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5730 - accuracy: 0.8585 - val_loss: 0.6343 - val_accuracy: 0.8437\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5684 - accuracy: 0.8587 - val_loss: 0.6751 - val_accuracy: 0.8305\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5712 - accuracy: 0.8571 - val_loss: 0.6644 - val_accuracy: 0.8299\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5579 - accuracy: 0.8632 - val_loss: 0.6397 - val_accuracy: 0.8350\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5683 - accuracy: 0.8609 - val_loss: 0.6861 - val_accuracy: 0.8218\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5624 - accuracy: 0.8614 - val_loss: 0.6381 - val_accuracy: 0.8412\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5558 - accuracy: 0.8654 - val_loss: 0.6401 - val_accuracy: 0.8407\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5594 - accuracy: 0.8619 - val_loss: 0.6425 - val_accuracy: 0.8400\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5633 - accuracy: 0.8592 - val_loss: 0.6904 - val_accuracy: 0.8295\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5569 - accuracy: 0.8624 - val_loss: 0.6448 - val_accuracy: 0.8353\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5547 - accuracy: 0.8634 - val_loss: 0.6401 - val_accuracy: 0.8360\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5595 - accuracy: 0.8635 - val_loss: 0.6407 - val_accuracy: 0.8399\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5566 - accuracy: 0.8638 - val_loss: 0.6331 - val_accuracy: 0.8397\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5578 - accuracy: 0.8652 - val_loss: 0.6426 - val_accuracy: 0.8376\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5595 - accuracy: 0.8644 - val_loss: 0.6539 - val_accuracy: 0.8397\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5559 - accuracy: 0.8641 - val_loss: 0.6669 - val_accuracy: 0.8328\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5488 - accuracy: 0.8693 - val_loss: 0.6676 - val_accuracy: 0.8332\n",
      "313/313 - 1s - loss: 0.6676 - accuracy: 0.8332\n",
      "Test accuracy: 0.8331999778747559\n",
      "NET  13\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5527 - accuracy: 0.1696 - val_loss: 2.5003 - val_accuracy: 0.1943\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0579 - accuracy: 0.3057 - val_loss: 1.9534 - val_accuracy: 0.3510\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.8344 - accuracy: 0.4007 - val_loss: 1.6964 - val_accuracy: 0.4594\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7024 - accuracy: 0.4576 - val_loss: 1.6866 - val_accuracy: 0.4781\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.5810 - accuracy: 0.5110 - val_loss: 1.6132 - val_accuracy: 0.5110\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.4735 - accuracy: 0.5523 - val_loss: 1.3294 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.3953 - accuracy: 0.5823 - val_loss: 1.2513 - val_accuracy: 0.6285\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.3198 - accuracy: 0.6044 - val_loss: 1.2142 - val_accuracy: 0.6347\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.2665 - accuracy: 0.6259 - val_loss: 1.2039 - val_accuracy: 0.6373\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2104 - accuracy: 0.6401 - val_loss: 1.1624 - val_accuracy: 0.6560\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.1597 - accuracy: 0.6558 - val_loss: 1.1741 - val_accuracy: 0.6463\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1213 - accuracy: 0.6693 - val_loss: 1.0926 - val_accuracy: 0.6692\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.0860 - accuracy: 0.6800 - val_loss: 1.0374 - val_accuracy: 0.6986\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0458 - accuracy: 0.6944 - val_loss: 1.0831 - val_accuracy: 0.6712\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0192 - accuracy: 0.6996 - val_loss: 0.9824 - val_accuracy: 0.7013\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 0.9867 - accuracy: 0.7119 - val_loss: 0.9170 - val_accuracy: 0.7277\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9698 - accuracy: 0.7185 - val_loss: 1.0900 - val_accuracy: 0.6758\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9302 - accuracy: 0.7297 - val_loss: 0.8560 - val_accuracy: 0.7507\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9152 - accuracy: 0.7365 - val_loss: 1.0557 - val_accuracy: 0.6926\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.8997 - accuracy: 0.7407 - val_loss: 0.8652 - val_accuracy: 0.7350\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.8785 - accuracy: 0.7510 - val_loss: 0.9708 - val_accuracy: 0.7253\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8585 - accuracy: 0.7549 - val_loss: 0.8956 - val_accuracy: 0.7300\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8412 - accuracy: 0.7624 - val_loss: 0.8283 - val_accuracy: 0.7653\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8275 - accuracy: 0.7658 - val_loss: 0.8294 - val_accuracy: 0.7540\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8143 - accuracy: 0.7708 - val_loss: 0.8074 - val_accuracy: 0.7694\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.7986 - accuracy: 0.7764 - val_loss: 0.7899 - val_accuracy: 0.7730\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.7830 - accuracy: 0.7821 - val_loss: 0.8255 - val_accuracy: 0.7612\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7740 - accuracy: 0.7854 - val_loss: 0.7782 - val_accuracy: 0.7795\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7665 - accuracy: 0.7880 - val_loss: 0.7681 - val_accuracy: 0.7834\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7517 - accuracy: 0.7933 - val_loss: 0.7602 - val_accuracy: 0.7858\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7504 - accuracy: 0.7945 - val_loss: 0.7455 - val_accuracy: 0.7889\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7324 - accuracy: 0.7995 - val_loss: 0.7139 - val_accuracy: 0.8032\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7272 - accuracy: 0.8007 - val_loss: 0.7153 - val_accuracy: 0.8009\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7244 - accuracy: 0.8027 - val_loss: 0.7227 - val_accuracy: 0.8006\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7176 - accuracy: 0.8057 - val_loss: 0.8071 - val_accuracy: 0.7795\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7086 - accuracy: 0.8092 - val_loss: 0.7348 - val_accuracy: 0.7918\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7024 - accuracy: 0.8126 - val_loss: 0.7294 - val_accuracy: 0.8013\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.6967 - accuracy: 0.8152 - val_loss: 0.7108 - val_accuracy: 0.8039\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6938 - accuracy: 0.8158 - val_loss: 0.7095 - val_accuracy: 0.8070\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6846 - accuracy: 0.8189 - val_loss: 0.7107 - val_accuracy: 0.8028\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6745 - accuracy: 0.8241 - val_loss: 0.7805 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6703 - accuracy: 0.8235 - val_loss: 0.7731 - val_accuracy: 0.7947\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6672 - accuracy: 0.8236 - val_loss: 0.6926 - val_accuracy: 0.8159\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6655 - accuracy: 0.8246 - val_loss: 0.7474 - val_accuracy: 0.7979\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6560 - accuracy: 0.8286 - val_loss: 0.6803 - val_accuracy: 0.8194\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6547 - accuracy: 0.8301 - val_loss: 0.7260 - val_accuracy: 0.8079\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6484 - accuracy: 0.8322 - val_loss: 0.7927 - val_accuracy: 0.7901\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6439 - accuracy: 0.8315 - val_loss: 0.7148 - val_accuracy: 0.8055\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6387 - accuracy: 0.8338 - val_loss: 0.6852 - val_accuracy: 0.8198\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6294 - accuracy: 0.8376 - val_loss: 0.7472 - val_accuracy: 0.8050\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6288 - accuracy: 0.8370 - val_loss: 0.7155 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6328 - accuracy: 0.8367 - val_loss: 0.7669 - val_accuracy: 0.8007\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6292 - accuracy: 0.8384 - val_loss: 0.6781 - val_accuracy: 0.8254\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6128 - accuracy: 0.8439 - val_loss: 0.6869 - val_accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6153 - accuracy: 0.8451 - val_loss: 0.8072 - val_accuracy: 0.7949\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6092 - accuracy: 0.8463 - val_loss: 0.6787 - val_accuracy: 0.8268\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6011 - accuracy: 0.8481 - val_loss: 0.6831 - val_accuracy: 0.8245\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6076 - accuracy: 0.8482 - val_loss: 0.6619 - val_accuracy: 0.8300\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6020 - accuracy: 0.8489 - val_loss: 0.6818 - val_accuracy: 0.8252\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6014 - accuracy: 0.8516 - val_loss: 0.6672 - val_accuracy: 0.8322\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.5978 - accuracy: 0.8506 - val_loss: 0.6567 - val_accuracy: 0.8336\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5889 - accuracy: 0.8537 - val_loss: 0.6864 - val_accuracy: 0.8251\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5977 - accuracy: 0.8522 - val_loss: 0.6794 - val_accuracy: 0.8222\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5898 - accuracy: 0.8537 - val_loss: 0.6776 - val_accuracy: 0.8262\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5879 - accuracy: 0.8561 - val_loss: 0.6652 - val_accuracy: 0.8284\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5900 - accuracy: 0.8563 - val_loss: 0.6804 - val_accuracy: 0.8270\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5856 - accuracy: 0.8567 - val_loss: 0.6712 - val_accuracy: 0.8326\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5822 - accuracy: 0.8576 - val_loss: 0.6607 - val_accuracy: 0.8355\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5779 - accuracy: 0.8586 - val_loss: 0.6890 - val_accuracy: 0.8256\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5714 - accuracy: 0.8587 - val_loss: 0.7234 - val_accuracy: 0.8246\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5772 - accuracy: 0.8595 - val_loss: 0.7159 - val_accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5711 - accuracy: 0.8609 - val_loss: 0.6875 - val_accuracy: 0.8315\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5752 - accuracy: 0.8610 - val_loss: 0.7235 - val_accuracy: 0.8185\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5713 - accuracy: 0.8621 - val_loss: 0.6742 - val_accuracy: 0.8330\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5651 - accuracy: 0.8655 - val_loss: 0.6807 - val_accuracy: 0.8345\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5659 - accuracy: 0.8639 - val_loss: 0.6475 - val_accuracy: 0.8404\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5583 - accuracy: 0.8675 - val_loss: 0.6521 - val_accuracy: 0.8411\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5664 - accuracy: 0.8653 - val_loss: 0.6970 - val_accuracy: 0.8231\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5610 - accuracy: 0.8650 - val_loss: 0.6306 - val_accuracy: 0.8455\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5598 - accuracy: 0.8663 - val_loss: 0.6711 - val_accuracy: 0.8351\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5562 - accuracy: 0.8686 - val_loss: 0.6622 - val_accuracy: 0.8394\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5591 - accuracy: 0.8668 - val_loss: 0.6775 - val_accuracy: 0.8343\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5589 - accuracy: 0.8678 - val_loss: 0.6657 - val_accuracy: 0.8338\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5553 - accuracy: 0.8684 - val_loss: 0.6894 - val_accuracy: 0.8302\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5525 - accuracy: 0.8690 - val_loss: 0.6456 - val_accuracy: 0.8392\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5503 - accuracy: 0.8719 - val_loss: 0.6656 - val_accuracy: 0.8402\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5473 - accuracy: 0.8716 - val_loss: 0.6339 - val_accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5515 - accuracy: 0.8701 - val_loss: 0.6351 - val_accuracy: 0.8473\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5533 - accuracy: 0.8711 - val_loss: 0.6587 - val_accuracy: 0.8352\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5444 - accuracy: 0.8719 - val_loss: 0.6441 - val_accuracy: 0.8454\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5435 - accuracy: 0.8721 - val_loss: 0.6840 - val_accuracy: 0.8318\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5433 - accuracy: 0.8739 - val_loss: 0.6555 - val_accuracy: 0.8399\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5416 - accuracy: 0.8740 - val_loss: 0.6386 - val_accuracy: 0.8447\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5450 - accuracy: 0.8714 - val_loss: 0.7414 - val_accuracy: 0.8238\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5379 - accuracy: 0.8756 - val_loss: 0.6756 - val_accuracy: 0.8377\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5340 - accuracy: 0.8767 - val_loss: 0.6918 - val_accuracy: 0.8301\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5395 - accuracy: 0.8739 - val_loss: 0.7251 - val_accuracy: 0.8244\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5292 - accuracy: 0.8773 - val_loss: 0.6473 - val_accuracy: 0.8451\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5419 - accuracy: 0.8723 - val_loss: 0.6726 - val_accuracy: 0.8362\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5347 - accuracy: 0.8771 - val_loss: 0.7004 - val_accuracy: 0.8289\n",
      "313/313 - 1s - loss: 0.7004 - accuracy: 0.8289\n",
      "Test accuracy: 0.8288999795913696\n",
      "NET  14\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5451 - accuracy: 0.1852 - val_loss: 2.7053 - val_accuracy: 0.1467\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1021 - accuracy: 0.2921 - val_loss: 2.3546 - val_accuracy: 0.2476\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9325 - accuracy: 0.3590 - val_loss: 1.9028 - val_accuracy: 0.3748\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8167 - accuracy: 0.4101 - val_loss: 1.7247 - val_accuracy: 0.4418\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7133 - accuracy: 0.4454 - val_loss: 1.6535 - val_accuracy: 0.4755\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6276 - accuracy: 0.4821 - val_loss: 1.5029 - val_accuracy: 0.5236\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5473 - accuracy: 0.5153 - val_loss: 1.5053 - val_accuracy: 0.5323\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4803 - accuracy: 0.5402 - val_loss: 1.3939 - val_accuracy: 0.5787\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.4087 - accuracy: 0.5644 - val_loss: 1.2765 - val_accuracy: 0.6076\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3532 - accuracy: 0.5851 - val_loss: 1.2327 - val_accuracy: 0.6288\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.3063 - accuracy: 0.6031 - val_loss: 1.2062 - val_accuracy: 0.6341\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2491 - accuracy: 0.6228 - val_loss: 1.1557 - val_accuracy: 0.6472\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.2101 - accuracy: 0.6336 - val_loss: 1.1853 - val_accuracy: 0.6316\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1669 - accuracy: 0.6468 - val_loss: 1.1308 - val_accuracy: 0.6613\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1352 - accuracy: 0.6591 - val_loss: 1.0504 - val_accuracy: 0.6882\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0973 - accuracy: 0.6707 - val_loss: 1.0760 - val_accuracy: 0.6700\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0733 - accuracy: 0.6764 - val_loss: 1.0517 - val_accuracy: 0.6744\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0411 - accuracy: 0.6856 - val_loss: 1.0298 - val_accuracy: 0.6779\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 1.0163 - accuracy: 0.6940 - val_loss: 1.0310 - val_accuracy: 0.6871\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9903 - accuracy: 0.7030 - val_loss: 0.9275 - val_accuracy: 0.7226\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9787 - accuracy: 0.7071 - val_loss: 0.9900 - val_accuracy: 0.6933\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9553 - accuracy: 0.7127 - val_loss: 1.1329 - val_accuracy: 0.6502\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.9366 - accuracy: 0.7214 - val_loss: 0.9474 - val_accuracy: 0.7062\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.9231 - accuracy: 0.7257 - val_loss: 1.0171 - val_accuracy: 0.6878\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.9098 - accuracy: 0.7314 - val_loss: 0.8756 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8879 - accuracy: 0.7368 - val_loss: 0.8743 - val_accuracy: 0.7365\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8805 - accuracy: 0.7403 - val_loss: 0.8393 - val_accuracy: 0.7476\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8571 - accuracy: 0.7482 - val_loss: 0.8204 - val_accuracy: 0.7557\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8495 - accuracy: 0.7508 - val_loss: 0.8459 - val_accuracy: 0.7461\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.8377 - accuracy: 0.7566 - val_loss: 0.7606 - val_accuracy: 0.7760\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.8259 - accuracy: 0.7605 - val_loss: 0.7805 - val_accuracy: 0.7770\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.8186 - accuracy: 0.7641 - val_loss: 0.8203 - val_accuracy: 0.7596\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.8091 - accuracy: 0.7674 - val_loss: 0.7566 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7893 - accuracy: 0.7732 - val_loss: 0.7515 - val_accuracy: 0.7791\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7860 - accuracy: 0.7755 - val_loss: 0.8318 - val_accuracy: 0.7616\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7797 - accuracy: 0.7779 - val_loss: 0.7552 - val_accuracy: 0.7805\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7630 - accuracy: 0.7833 - val_loss: 0.7853 - val_accuracy: 0.7709\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7567 - accuracy: 0.7860 - val_loss: 0.7317 - val_accuracy: 0.7897\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7513 - accuracy: 0.7886 - val_loss: 0.7128 - val_accuracy: 0.7954\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7432 - accuracy: 0.7915 - val_loss: 0.7093 - val_accuracy: 0.8017\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7336 - accuracy: 0.7953 - val_loss: 0.7448 - val_accuracy: 0.7934\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7284 - accuracy: 0.7967 - val_loss: 0.7663 - val_accuracy: 0.7823\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.7231 - accuracy: 0.7992 - val_loss: 0.7183 - val_accuracy: 0.7984\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.7125 - accuracy: 0.8027 - val_loss: 0.7178 - val_accuracy: 0.8001\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.7046 - accuracy: 0.8052 - val_loss: 0.7063 - val_accuracy: 0.8040\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.7079 - accuracy: 0.8061 - val_loss: 0.7510 - val_accuracy: 0.7893\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.7072 - accuracy: 0.8060 - val_loss: 0.6888 - val_accuracy: 0.8099\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6955 - accuracy: 0.8095 - val_loss: 0.8234 - val_accuracy: 0.7598\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6953 - accuracy: 0.8101 - val_loss: 0.7391 - val_accuracy: 0.7968\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6954 - accuracy: 0.8120 - val_loss: 0.7258 - val_accuracy: 0.8019\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6791 - accuracy: 0.8157 - val_loss: 0.7008 - val_accuracy: 0.8079\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6825 - accuracy: 0.8150 - val_loss: 0.7122 - val_accuracy: 0.8092\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6715 - accuracy: 0.8190 - val_loss: 0.6979 - val_accuracy: 0.8135\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6737 - accuracy: 0.8179 - val_loss: 0.6517 - val_accuracy: 0.8261\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6669 - accuracy: 0.8195 - val_loss: 0.6852 - val_accuracy: 0.8154\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6604 - accuracy: 0.8229 - val_loss: 0.7350 - val_accuracy: 0.7980\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6586 - accuracy: 0.8241 - val_loss: 0.7443 - val_accuracy: 0.7983\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6523 - accuracy: 0.8258 - val_loss: 0.7070 - val_accuracy: 0.8090\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6511 - accuracy: 0.8253 - val_loss: 0.7589 - val_accuracy: 0.7971\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6551 - accuracy: 0.8282 - val_loss: 0.6840 - val_accuracy: 0.8198\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6465 - accuracy: 0.8282 - val_loss: 0.6913 - val_accuracy: 0.8160\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6462 - accuracy: 0.8292 - val_loss: 0.6717 - val_accuracy: 0.8209\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6368 - accuracy: 0.8325 - val_loss: 0.6608 - val_accuracy: 0.8228\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6437 - accuracy: 0.8286 - val_loss: 0.7069 - val_accuracy: 0.8135\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6373 - accuracy: 0.8329 - val_loss: 0.6996 - val_accuracy: 0.8147\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6353 - accuracy: 0.8318 - val_loss: 0.6412 - val_accuracy: 0.8303\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6338 - accuracy: 0.8334 - val_loss: 0.6976 - val_accuracy: 0.8139\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6333 - accuracy: 0.8347 - val_loss: 0.6651 - val_accuracy: 0.8245\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6234 - accuracy: 0.8384 - val_loss: 0.6496 - val_accuracy: 0.8276\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6231 - accuracy: 0.8354 - val_loss: 0.6855 - val_accuracy: 0.8202\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.6261 - accuracy: 0.8384 - val_loss: 0.7474 - val_accuracy: 0.8015\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.6223 - accuracy: 0.8379 - val_loss: 0.6938 - val_accuracy: 0.8204\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.6157 - accuracy: 0.8410 - val_loss: 0.6599 - val_accuracy: 0.8301\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.6130 - accuracy: 0.8431 - val_loss: 0.6760 - val_accuracy: 0.8261\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.6147 - accuracy: 0.8416 - val_loss: 0.6903 - val_accuracy: 0.8229\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.6146 - accuracy: 0.8412 - val_loss: 0.6675 - val_accuracy: 0.8273\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.6107 - accuracy: 0.8441 - val_loss: 0.6866 - val_accuracy: 0.8229\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.6160 - accuracy: 0.8407 - val_loss: 0.6408 - val_accuracy: 0.8353\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.6065 - accuracy: 0.8452 - val_loss: 0.6497 - val_accuracy: 0.8313\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.6032 - accuracy: 0.8469 - val_loss: 0.6834 - val_accuracy: 0.8230\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.6141 - accuracy: 0.8428 - val_loss: 0.6531 - val_accuracy: 0.8303\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.6052 - accuracy: 0.8456 - val_loss: 0.6491 - val_accuracy: 0.8361\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.6041 - accuracy: 0.8466 - val_loss: 0.7162 - val_accuracy: 0.8122\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5965 - accuracy: 0.8473 - val_loss: 0.6634 - val_accuracy: 0.8348\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.6007 - accuracy: 0.8471 - val_loss: 0.7098 - val_accuracy: 0.8159\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.6074 - accuracy: 0.8463 - val_loss: 0.6596 - val_accuracy: 0.8279\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5970 - accuracy: 0.8496 - val_loss: 0.6445 - val_accuracy: 0.8365\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5965 - accuracy: 0.8499 - val_loss: 0.7029 - val_accuracy: 0.8178\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.6004 - accuracy: 0.8469 - val_loss: 0.6922 - val_accuracy: 0.8214\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5879 - accuracy: 0.8516 - val_loss: 0.7066 - val_accuracy: 0.8154\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5902 - accuracy: 0.8506 - val_loss: 0.8180 - val_accuracy: 0.7911\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5956 - accuracy: 0.8502 - val_loss: 0.6684 - val_accuracy: 0.8256\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5903 - accuracy: 0.8508 - val_loss: 0.6589 - val_accuracy: 0.8316\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5887 - accuracy: 0.8522 - val_loss: 0.6879 - val_accuracy: 0.8196\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5878 - accuracy: 0.8520 - val_loss: 0.6454 - val_accuracy: 0.8342\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5804 - accuracy: 0.8541 - val_loss: 0.6696 - val_accuracy: 0.8276\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5826 - accuracy: 0.8537 - val_loss: 0.6605 - val_accuracy: 0.8324\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5866 - accuracy: 0.8547 - val_loss: 0.7112 - val_accuracy: 0.8201\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5822 - accuracy: 0.8553 - val_loss: 0.7172 - val_accuracy: 0.8191\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5827 - accuracy: 0.8566 - val_loss: 0.6598 - val_accuracy: 0.8347\n",
      "313/313 - 1s - loss: 0.6598 - accuracy: 0.8347\n",
      "Test accuracy: 0.8346999883651733\n",
      "NET  15\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5687 - accuracy: 0.1710 - val_loss: 2.7408 - val_accuracy: 0.1216\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1542 - accuracy: 0.2684 - val_loss: 2.1654 - val_accuracy: 0.2719\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9778 - accuracy: 0.3316 - val_loss: 1.8670 - val_accuracy: 0.3844\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8429 - accuracy: 0.3826 - val_loss: 1.8048 - val_accuracy: 0.4126\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7353 - accuracy: 0.4264 - val_loss: 1.6584 - val_accuracy: 0.4524\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6245 - accuracy: 0.4728 - val_loss: 1.5920 - val_accuracy: 0.4892\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5347 - accuracy: 0.5079 - val_loss: 1.5164 - val_accuracy: 0.5135\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4643 - accuracy: 0.5378 - val_loss: 1.4630 - val_accuracy: 0.5463\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3838 - accuracy: 0.5704 - val_loss: 1.3431 - val_accuracy: 0.5828\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3174 - accuracy: 0.5919 - val_loss: 1.2383 - val_accuracy: 0.6135\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2663 - accuracy: 0.6108 - val_loss: 1.1418 - val_accuracy: 0.6502\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2027 - accuracy: 0.6329 - val_loss: 1.1824 - val_accuracy: 0.6312\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1569 - accuracy: 0.6456 - val_loss: 1.0457 - val_accuracy: 0.6859\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1111 - accuracy: 0.6608 - val_loss: 1.0501 - val_accuracy: 0.6821\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0782 - accuracy: 0.6707 - val_loss: 1.0534 - val_accuracy: 0.6779\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0467 - accuracy: 0.6826 - val_loss: 0.9669 - val_accuracy: 0.7012\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0246 - accuracy: 0.6883 - val_loss: 0.9791 - val_accuracy: 0.7008\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9940 - accuracy: 0.7002 - val_loss: 0.9623 - val_accuracy: 0.7054\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9608 - accuracy: 0.7156 - val_loss: 0.8973 - val_accuracy: 0.7252\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9453 - accuracy: 0.7169 - val_loss: 0.9157 - val_accuracy: 0.7244\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9115 - accuracy: 0.7279 - val_loss: 0.8807 - val_accuracy: 0.7331\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9057 - accuracy: 0.7331 - val_loss: 0.8842 - val_accuracy: 0.7326\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8772 - accuracy: 0.7390 - val_loss: 0.8713 - val_accuracy: 0.7371\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8690 - accuracy: 0.7425 - val_loss: 0.8309 - val_accuracy: 0.7560\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8566 - accuracy: 0.7510 - val_loss: 0.8368 - val_accuracy: 0.7555\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8315 - accuracy: 0.7602 - val_loss: 0.8504 - val_accuracy: 0.7536\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8247 - accuracy: 0.7636 - val_loss: 0.7976 - val_accuracy: 0.7700\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8117 - accuracy: 0.7674 - val_loss: 0.7629 - val_accuracy: 0.7791\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7934 - accuracy: 0.7730 - val_loss: 0.8233 - val_accuracy: 0.7576\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7790 - accuracy: 0.7801 - val_loss: 0.7847 - val_accuracy: 0.7751\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7718 - accuracy: 0.7812 - val_loss: 0.7712 - val_accuracy: 0.7846\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7541 - accuracy: 0.7878 - val_loss: 0.7598 - val_accuracy: 0.7849\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7554 - accuracy: 0.7881 - val_loss: 0.7381 - val_accuracy: 0.7949\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7396 - accuracy: 0.7936 - val_loss: 0.7430 - val_accuracy: 0.7962\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7319 - accuracy: 0.7984 - val_loss: 0.7606 - val_accuracy: 0.7878\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7202 - accuracy: 0.8022 - val_loss: 0.7305 - val_accuracy: 0.7954\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7143 - accuracy: 0.8058 - val_loss: 0.7519 - val_accuracy: 0.7962\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7049 - accuracy: 0.8080 - val_loss: 0.7011 - val_accuracy: 0.8068\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6977 - accuracy: 0.8102 - val_loss: 0.7193 - val_accuracy: 0.8061\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6904 - accuracy: 0.8148 - val_loss: 0.7100 - val_accuracy: 0.8040\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6871 - accuracy: 0.8122 - val_loss: 0.6944 - val_accuracy: 0.8156\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6805 - accuracy: 0.8161 - val_loss: 0.7512 - val_accuracy: 0.7981\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6827 - accuracy: 0.8169 - val_loss: 0.6795 - val_accuracy: 0.8168\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6682 - accuracy: 0.8233 - val_loss: 0.6723 - val_accuracy: 0.8176\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6611 - accuracy: 0.8241 - val_loss: 0.6786 - val_accuracy: 0.8172\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6654 - accuracy: 0.8209 - val_loss: 0.7055 - val_accuracy: 0.8105\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6578 - accuracy: 0.8261 - val_loss: 0.6960 - val_accuracy: 0.8153\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6553 - accuracy: 0.8279 - val_loss: 0.7469 - val_accuracy: 0.7988\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6424 - accuracy: 0.8314 - val_loss: 0.6592 - val_accuracy: 0.8227\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6394 - accuracy: 0.8345 - val_loss: 0.6692 - val_accuracy: 0.8212\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6415 - accuracy: 0.8326 - val_loss: 0.7138 - val_accuracy: 0.8148\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6372 - accuracy: 0.8326 - val_loss: 0.6661 - val_accuracy: 0.8258\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6352 - accuracy: 0.8341 - val_loss: 0.7113 - val_accuracy: 0.8083\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6300 - accuracy: 0.8380 - val_loss: 0.6714 - val_accuracy: 0.8207\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6222 - accuracy: 0.8392 - val_loss: 0.6658 - val_accuracy: 0.8273\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6244 - accuracy: 0.8396 - val_loss: 0.7090 - val_accuracy: 0.8180\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6158 - accuracy: 0.8412 - val_loss: 0.7047 - val_accuracy: 0.8195\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6091 - accuracy: 0.8432 - val_loss: 0.6613 - val_accuracy: 0.8289\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6137 - accuracy: 0.8429 - val_loss: 0.7505 - val_accuracy: 0.8079\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6104 - accuracy: 0.8436 - val_loss: 0.7049 - val_accuracy: 0.8207\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6008 - accuracy: 0.8476 - val_loss: 0.6600 - val_accuracy: 0.8324\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5970 - accuracy: 0.8478 - val_loss: 0.6569 - val_accuracy: 0.8350\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5924 - accuracy: 0.8493 - val_loss: 0.6573 - val_accuracy: 0.8300\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5939 - accuracy: 0.8493 - val_loss: 0.6528 - val_accuracy: 0.8331\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5981 - accuracy: 0.8496 - val_loss: 0.7216 - val_accuracy: 0.8083\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5937 - accuracy: 0.8512 - val_loss: 0.7025 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5955 - accuracy: 0.8507 - val_loss: 0.6540 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5835 - accuracy: 0.8538 - val_loss: 0.6616 - val_accuracy: 0.8315\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5947 - accuracy: 0.8526 - val_loss: 0.6869 - val_accuracy: 0.8246\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5798 - accuracy: 0.8567 - val_loss: 0.6359 - val_accuracy: 0.8402\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5737 - accuracy: 0.8577 - val_loss: 0.6561 - val_accuracy: 0.8306\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5744 - accuracy: 0.8572 - val_loss: 0.6572 - val_accuracy: 0.8365\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5822 - accuracy: 0.8542 - val_loss: 0.6365 - val_accuracy: 0.8366\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5779 - accuracy: 0.8588 - val_loss: 0.6606 - val_accuracy: 0.8313\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5791 - accuracy: 0.8564 - val_loss: 0.6496 - val_accuracy: 0.8367\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5758 - accuracy: 0.8576 - val_loss: 0.6876 - val_accuracy: 0.8344\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5644 - accuracy: 0.8628 - val_loss: 0.6790 - val_accuracy: 0.8325\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5682 - accuracy: 0.8615 - val_loss: 0.6383 - val_accuracy: 0.8444\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5668 - accuracy: 0.8606 - val_loss: 0.6817 - val_accuracy: 0.8255\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5631 - accuracy: 0.8629 - val_loss: 0.6688 - val_accuracy: 0.8314\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5684 - accuracy: 0.8616 - val_loss: 0.6536 - val_accuracy: 0.8382\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5590 - accuracy: 0.8636 - val_loss: 0.6764 - val_accuracy: 0.8310\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5579 - accuracy: 0.8629 - val_loss: 0.6589 - val_accuracy: 0.8348\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5610 - accuracy: 0.8628 - val_loss: 0.6313 - val_accuracy: 0.8457\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5507 - accuracy: 0.8655 - val_loss: 0.6240 - val_accuracy: 0.8448\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5569 - accuracy: 0.8644 - val_loss: 0.6680 - val_accuracy: 0.8267\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5527 - accuracy: 0.8661 - val_loss: 0.6628 - val_accuracy: 0.8371\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5528 - accuracy: 0.8664 - val_loss: 0.6281 - val_accuracy: 0.8441\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5488 - accuracy: 0.8660 - val_loss: 0.6878 - val_accuracy: 0.8322\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5552 - accuracy: 0.8659 - val_loss: 0.6616 - val_accuracy: 0.8393\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5580 - accuracy: 0.8651 - val_loss: 0.6588 - val_accuracy: 0.8346\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5464 - accuracy: 0.8696 - val_loss: 0.6715 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5438 - accuracy: 0.8691 - val_loss: 0.6250 - val_accuracy: 0.8474\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5412 - accuracy: 0.8723 - val_loss: 0.6320 - val_accuracy: 0.8444\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5482 - accuracy: 0.8717 - val_loss: 0.6571 - val_accuracy: 0.8439\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5448 - accuracy: 0.8710 - val_loss: 0.6705 - val_accuracy: 0.8338\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5483 - accuracy: 0.8695 - val_loss: 0.6617 - val_accuracy: 0.8360\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5409 - accuracy: 0.8715 - val_loss: 0.6771 - val_accuracy: 0.8281\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5374 - accuracy: 0.8728 - val_loss: 0.6375 - val_accuracy: 0.8470\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5376 - accuracy: 0.8728 - val_loss: 0.6737 - val_accuracy: 0.8378\n",
      "313/313 - 1s - loss: 0.6737 - accuracy: 0.8378\n",
      "Test accuracy: 0.8378000259399414\n",
      "NET  16\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5947 - accuracy: 0.1828 - val_loss: 2.5803 - val_accuracy: 0.1478\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1444 - accuracy: 0.2753 - val_loss: 2.4411 - val_accuracy: 0.2107\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9900 - accuracy: 0.3255 - val_loss: 2.1540 - val_accuracy: 0.3041\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8724 - accuracy: 0.3758 - val_loss: 1.7662 - val_accuracy: 0.4250\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7673 - accuracy: 0.4152 - val_loss: 1.6783 - val_accuracy: 0.4446\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6659 - accuracy: 0.4568 - val_loss: 1.6515 - val_accuracy: 0.4578\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5734 - accuracy: 0.4955 - val_loss: 1.5064 - val_accuracy: 0.5353\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4874 - accuracy: 0.5285 - val_loss: 1.4330 - val_accuracy: 0.5563\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.4182 - accuracy: 0.5590 - val_loss: 1.3829 - val_accuracy: 0.5660\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.3465 - accuracy: 0.5878 - val_loss: 1.2596 - val_accuracy: 0.6212\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2957 - accuracy: 0.6055 - val_loss: 1.2133 - val_accuracy: 0.6393\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.2337 - accuracy: 0.6256 - val_loss: 1.1622 - val_accuracy: 0.6419\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1887 - accuracy: 0.6402 - val_loss: 1.0770 - val_accuracy: 0.6691\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1452 - accuracy: 0.6546 - val_loss: 1.0884 - val_accuracy: 0.6727\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.1032 - accuracy: 0.6686 - val_loss: 1.0643 - val_accuracy: 0.6769\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0725 - accuracy: 0.6798 - val_loss: 1.0538 - val_accuracy: 0.6821\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0416 - accuracy: 0.6891 - val_loss: 1.0220 - val_accuracy: 0.6953\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0113 - accuracy: 0.6985 - val_loss: 0.9939 - val_accuracy: 0.6949\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9880 - accuracy: 0.7072 - val_loss: 0.9729 - val_accuracy: 0.7121\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9631 - accuracy: 0.7151 - val_loss: 0.8936 - val_accuracy: 0.7388\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9414 - accuracy: 0.7227 - val_loss: 0.8617 - val_accuracy: 0.7393\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9142 - accuracy: 0.7314 - val_loss: 0.9403 - val_accuracy: 0.7240\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8937 - accuracy: 0.7387 - val_loss: 0.8799 - val_accuracy: 0.7349\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8764 - accuracy: 0.7443 - val_loss: 0.8175 - val_accuracy: 0.7586\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8601 - accuracy: 0.7507 - val_loss: 0.8359 - val_accuracy: 0.7528\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8438 - accuracy: 0.7573 - val_loss: 0.7878 - val_accuracy: 0.7657\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8320 - accuracy: 0.7621 - val_loss: 0.8078 - val_accuracy: 0.7667\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8159 - accuracy: 0.7680 - val_loss: 0.7820 - val_accuracy: 0.7708\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8016 - accuracy: 0.7719 - val_loss: 0.7880 - val_accuracy: 0.7739\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7860 - accuracy: 0.7771 - val_loss: 0.8104 - val_accuracy: 0.7699\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7787 - accuracy: 0.7797 - val_loss: 0.7771 - val_accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7747 - accuracy: 0.7823 - val_loss: 0.7687 - val_accuracy: 0.7855\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7632 - accuracy: 0.7845 - val_loss: 0.7768 - val_accuracy: 0.7779\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7514 - accuracy: 0.7907 - val_loss: 0.7363 - val_accuracy: 0.7949\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7396 - accuracy: 0.7930 - val_loss: 0.7647 - val_accuracy: 0.7876\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7318 - accuracy: 0.7972 - val_loss: 0.7866 - val_accuracy: 0.7836\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7245 - accuracy: 0.7990 - val_loss: 0.7428 - val_accuracy: 0.7948\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7135 - accuracy: 0.8049 - val_loss: 0.7228 - val_accuracy: 0.7983\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7177 - accuracy: 0.8034 - val_loss: 0.7217 - val_accuracy: 0.8029\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7014 - accuracy: 0.8079 - val_loss: 0.7675 - val_accuracy: 0.7909\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7033 - accuracy: 0.8083 - val_loss: 0.7317 - val_accuracy: 0.8035\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6970 - accuracy: 0.8107 - val_loss: 0.7107 - val_accuracy: 0.8059\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6837 - accuracy: 0.8144 - val_loss: 0.7325 - val_accuracy: 0.7961\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6801 - accuracy: 0.8167 - val_loss: 0.6864 - val_accuracy: 0.8120\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6711 - accuracy: 0.8174 - val_loss: 0.7266 - val_accuracy: 0.7984\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6789 - accuracy: 0.8161 - val_loss: 0.7270 - val_accuracy: 0.7980\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6659 - accuracy: 0.8211 - val_loss: 0.7386 - val_accuracy: 0.8020\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6602 - accuracy: 0.8238 - val_loss: 0.7341 - val_accuracy: 0.8013\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6593 - accuracy: 0.8238 - val_loss: 0.6966 - val_accuracy: 0.8136\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6584 - accuracy: 0.8252 - val_loss: 0.7164 - val_accuracy: 0.8080\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6448 - accuracy: 0.8297 - val_loss: 0.7618 - val_accuracy: 0.8012\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6521 - accuracy: 0.8266 - val_loss: 0.6820 - val_accuracy: 0.8198\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6482 - accuracy: 0.8281 - val_loss: 0.7283 - val_accuracy: 0.8063\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6405 - accuracy: 0.8296 - val_loss: 0.7115 - val_accuracy: 0.8131\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6356 - accuracy: 0.8340 - val_loss: 0.6950 - val_accuracy: 0.8210\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6359 - accuracy: 0.8363 - val_loss: 0.7145 - val_accuracy: 0.8093\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6315 - accuracy: 0.8353 - val_loss: 0.7046 - val_accuracy: 0.8119\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6299 - accuracy: 0.8349 - val_loss: 0.6758 - val_accuracy: 0.8214\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6248 - accuracy: 0.8397 - val_loss: 0.7163 - val_accuracy: 0.8132\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6157 - accuracy: 0.8396 - val_loss: 0.7140 - val_accuracy: 0.8141\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6235 - accuracy: 0.8383 - val_loss: 0.6865 - val_accuracy: 0.8234\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6171 - accuracy: 0.8408 - val_loss: 0.6686 - val_accuracy: 0.8278\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6116 - accuracy: 0.8431 - val_loss: 0.7202 - val_accuracy: 0.8130\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6089 - accuracy: 0.8438 - val_loss: 0.6646 - val_accuracy: 0.8308\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6092 - accuracy: 0.8433 - val_loss: 0.6788 - val_accuracy: 0.8248\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6050 - accuracy: 0.8439 - val_loss: 0.6888 - val_accuracy: 0.8214\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5953 - accuracy: 0.8490 - val_loss: 0.6595 - val_accuracy: 0.8322\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5996 - accuracy: 0.8476 - val_loss: 0.7014 - val_accuracy: 0.8218\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6032 - accuracy: 0.8462 - val_loss: 0.6987 - val_accuracy: 0.8199\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6019 - accuracy: 0.8490 - val_loss: 0.6870 - val_accuracy: 0.8190\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5975 - accuracy: 0.8504 - val_loss: 0.7157 - val_accuracy: 0.8152\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5921 - accuracy: 0.8498 - val_loss: 0.6961 - val_accuracy: 0.8225\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5942 - accuracy: 0.8497 - val_loss: 0.7034 - val_accuracy: 0.8191\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5845 - accuracy: 0.8548 - val_loss: 0.7107 - val_accuracy: 0.8181\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5825 - accuracy: 0.8542 - val_loss: 0.6677 - val_accuracy: 0.8308\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5847 - accuracy: 0.8536 - val_loss: 0.6666 - val_accuracy: 0.8308\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5752 - accuracy: 0.8553 - val_loss: 0.6937 - val_accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5760 - accuracy: 0.8580 - val_loss: 0.7161 - val_accuracy: 0.8203\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5856 - accuracy: 0.8533 - val_loss: 0.6683 - val_accuracy: 0.8312\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5771 - accuracy: 0.8561 - val_loss: 0.6841 - val_accuracy: 0.8310\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5818 - accuracy: 0.8560 - val_loss: 0.6578 - val_accuracy: 0.8345\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5735 - accuracy: 0.8569 - val_loss: 0.7175 - val_accuracy: 0.8195\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5733 - accuracy: 0.8596 - val_loss: 0.6932 - val_accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5764 - accuracy: 0.8578 - val_loss: 0.6663 - val_accuracy: 0.8325\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5769 - accuracy: 0.8571 - val_loss: 0.7570 - val_accuracy: 0.8114\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5688 - accuracy: 0.8602 - val_loss: 0.6926 - val_accuracy: 0.8253\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5680 - accuracy: 0.8593 - val_loss: 0.6600 - val_accuracy: 0.8336\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5724 - accuracy: 0.8591 - val_loss: 0.6839 - val_accuracy: 0.8212\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5738 - accuracy: 0.8612 - val_loss: 0.6692 - val_accuracy: 0.8243\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5613 - accuracy: 0.8609 - val_loss: 0.6743 - val_accuracy: 0.8354\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5628 - accuracy: 0.8622 - val_loss: 0.6466 - val_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5610 - accuracy: 0.8628 - val_loss: 0.6954 - val_accuracy: 0.8271\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5602 - accuracy: 0.8640 - val_loss: 0.6823 - val_accuracy: 0.8306\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5601 - accuracy: 0.8638 - val_loss: 0.6514 - val_accuracy: 0.8385\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5581 - accuracy: 0.8646 - val_loss: 0.6750 - val_accuracy: 0.8325\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5582 - accuracy: 0.8641 - val_loss: 0.6521 - val_accuracy: 0.8382\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5517 - accuracy: 0.8668 - val_loss: 0.6878 - val_accuracy: 0.8357\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5549 - accuracy: 0.8646 - val_loss: 0.6595 - val_accuracy: 0.8378\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5590 - accuracy: 0.8648 - val_loss: 0.6776 - val_accuracy: 0.8363\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5519 - accuracy: 0.8663 - val_loss: 0.6498 - val_accuracy: 0.8386\n",
      "313/313 - 1s - loss: 0.6498 - accuracy: 0.8386\n",
      "Test accuracy: 0.8385999798774719\n",
      "NET  17\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5430 - accuracy: 0.1785 - val_loss: 2.6835 - val_accuracy: 0.2001\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0817 - accuracy: 0.3015 - val_loss: 2.2856 - val_accuracy: 0.2744\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.8847 - accuracy: 0.3837 - val_loss: 1.9270 - val_accuracy: 0.4016\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7374 - accuracy: 0.4468 - val_loss: 1.6456 - val_accuracy: 0.5030\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.6325 - accuracy: 0.4906 - val_loss: 1.4786 - val_accuracy: 0.5499\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.5387 - accuracy: 0.5287 - val_loss: 1.4249 - val_accuracy: 0.5637\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.4548 - accuracy: 0.5591 - val_loss: 1.2948 - val_accuracy: 0.6071\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.3785 - accuracy: 0.5864 - val_loss: 1.2532 - val_accuracy: 0.6281\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3204 - accuracy: 0.6028 - val_loss: 1.2410 - val_accuracy: 0.6256\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2641 - accuracy: 0.6192 - val_loss: 1.1768 - val_accuracy: 0.6413\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2180 - accuracy: 0.6349 - val_loss: 1.1321 - val_accuracy: 0.6590\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1788 - accuracy: 0.6452 - val_loss: 1.1064 - val_accuracy: 0.6705\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1384 - accuracy: 0.6588 - val_loss: 1.0461 - val_accuracy: 0.6822\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0961 - accuracy: 0.6723 - val_loss: 1.0070 - val_accuracy: 0.7014\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0726 - accuracy: 0.6789 - val_loss: 0.9790 - val_accuracy: 0.7078\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0350 - accuracy: 0.6921 - val_loss: 0.9899 - val_accuracy: 0.6975\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0084 - accuracy: 0.7017 - val_loss: 0.9250 - val_accuracy: 0.7251\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9693 - accuracy: 0.7142 - val_loss: 0.9198 - val_accuracy: 0.7307\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9531 - accuracy: 0.7234 - val_loss: 0.9139 - val_accuracy: 0.7308\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9283 - accuracy: 0.7259 - val_loss: 0.8255 - val_accuracy: 0.7558\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9024 - accuracy: 0.7396 - val_loss: 0.8622 - val_accuracy: 0.7475\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8816 - accuracy: 0.7464 - val_loss: 0.8017 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8645 - accuracy: 0.7514 - val_loss: 0.8098 - val_accuracy: 0.7646\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8475 - accuracy: 0.7581 - val_loss: 0.8239 - val_accuracy: 0.7628\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8339 - accuracy: 0.7642 - val_loss: 0.7846 - val_accuracy: 0.7776\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8169 - accuracy: 0.7693 - val_loss: 0.7547 - val_accuracy: 0.7828\n",
      "Epoch 27/100\n",
      "196/196 - 5s - loss: 0.8058 - accuracy: 0.7740 - val_loss: 0.7860 - val_accuracy: 0.7743\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7877 - accuracy: 0.7795 - val_loss: 0.7959 - val_accuracy: 0.7710\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7700 - accuracy: 0.7871 - val_loss: 0.7824 - val_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7670 - accuracy: 0.7869 - val_loss: 0.7619 - val_accuracy: 0.7822\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7465 - accuracy: 0.7953 - val_loss: 0.7132 - val_accuracy: 0.8053\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7427 - accuracy: 0.7940 - val_loss: 0.7142 - val_accuracy: 0.8026\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7279 - accuracy: 0.8007 - val_loss: 0.7086 - val_accuracy: 0.8089\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7255 - accuracy: 0.8017 - val_loss: 0.7166 - val_accuracy: 0.8048\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7166 - accuracy: 0.8027 - val_loss: 0.6969 - val_accuracy: 0.8109\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7034 - accuracy: 0.8087 - val_loss: 0.7207 - val_accuracy: 0.7998\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.6987 - accuracy: 0.8117 - val_loss: 0.6823 - val_accuracy: 0.8125\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.6900 - accuracy: 0.8140 - val_loss: 0.7114 - val_accuracy: 0.8073\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6816 - accuracy: 0.8151 - val_loss: 0.7495 - val_accuracy: 0.8007\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6822 - accuracy: 0.8188 - val_loss: 0.7183 - val_accuracy: 0.8100\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6716 - accuracy: 0.8220 - val_loss: 0.6781 - val_accuracy: 0.8225\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6726 - accuracy: 0.8212 - val_loss: 0.7130 - val_accuracy: 0.8048\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6606 - accuracy: 0.8253 - val_loss: 0.7094 - val_accuracy: 0.8203\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6588 - accuracy: 0.8243 - val_loss: 0.6608 - val_accuracy: 0.8264\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6551 - accuracy: 0.8269 - val_loss: 0.6703 - val_accuracy: 0.8199\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6470 - accuracy: 0.8317 - val_loss: 0.6668 - val_accuracy: 0.8310\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6448 - accuracy: 0.8314 - val_loss: 0.6825 - val_accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6380 - accuracy: 0.8343 - val_loss: 0.6775 - val_accuracy: 0.8230\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6372 - accuracy: 0.8354 - val_loss: 0.6649 - val_accuracy: 0.8292\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6293 - accuracy: 0.8364 - val_loss: 0.6669 - val_accuracy: 0.8238\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6298 - accuracy: 0.8395 - val_loss: 0.6923 - val_accuracy: 0.8213\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6240 - accuracy: 0.8407 - val_loss: 0.6556 - val_accuracy: 0.8279\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6134 - accuracy: 0.8433 - val_loss: 0.6846 - val_accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6200 - accuracy: 0.8401 - val_loss: 0.6976 - val_accuracy: 0.8231\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6199 - accuracy: 0.8420 - val_loss: 0.6731 - val_accuracy: 0.8277\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6101 - accuracy: 0.8459 - val_loss: 0.6512 - val_accuracy: 0.8324\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6094 - accuracy: 0.8463 - val_loss: 0.6426 - val_accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6084 - accuracy: 0.8464 - val_loss: 0.6731 - val_accuracy: 0.8280\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6036 - accuracy: 0.8481 - val_loss: 0.6471 - val_accuracy: 0.8351\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.5984 - accuracy: 0.8489 - val_loss: 0.6946 - val_accuracy: 0.8233\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6006 - accuracy: 0.8491 - val_loss: 0.6505 - val_accuracy: 0.8355\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5836 - accuracy: 0.8551 - val_loss: 0.7228 - val_accuracy: 0.8081\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5918 - accuracy: 0.8523 - val_loss: 0.6354 - val_accuracy: 0.8396\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5820 - accuracy: 0.8564 - val_loss: 0.6437 - val_accuracy: 0.8338\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5842 - accuracy: 0.8540 - val_loss: 0.6394 - val_accuracy: 0.8417\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5836 - accuracy: 0.8568 - val_loss: 0.6491 - val_accuracy: 0.8392\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5799 - accuracy: 0.8581 - val_loss: 0.6848 - val_accuracy: 0.8298\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5753 - accuracy: 0.8589 - val_loss: 0.6556 - val_accuracy: 0.8372\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5774 - accuracy: 0.8579 - val_loss: 0.6395 - val_accuracy: 0.8416\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5756 - accuracy: 0.8587 - val_loss: 0.6681 - val_accuracy: 0.8337\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5743 - accuracy: 0.8606 - val_loss: 0.6618 - val_accuracy: 0.8411\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5748 - accuracy: 0.8598 - val_loss: 0.6341 - val_accuracy: 0.8438\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5651 - accuracy: 0.8637 - val_loss: 0.6686 - val_accuracy: 0.8363\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5629 - accuracy: 0.8640 - val_loss: 0.6580 - val_accuracy: 0.8402\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5592 - accuracy: 0.8654 - val_loss: 0.6893 - val_accuracy: 0.8310\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5627 - accuracy: 0.8627 - val_loss: 0.6728 - val_accuracy: 0.8356\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5619 - accuracy: 0.8646 - val_loss: 0.6608 - val_accuracy: 0.8377\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5680 - accuracy: 0.8630 - val_loss: 0.6637 - val_accuracy: 0.8398\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5614 - accuracy: 0.8658 - val_loss: 0.6463 - val_accuracy: 0.8411\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5535 - accuracy: 0.8680 - val_loss: 0.6724 - val_accuracy: 0.8325\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5553 - accuracy: 0.8672 - val_loss: 0.6536 - val_accuracy: 0.8446\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5499 - accuracy: 0.8665 - val_loss: 0.6495 - val_accuracy: 0.8460\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5461 - accuracy: 0.8716 - val_loss: 0.6537 - val_accuracy: 0.8339\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5490 - accuracy: 0.8691 - val_loss: 0.6927 - val_accuracy: 0.8330\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5514 - accuracy: 0.8689 - val_loss: 0.6237 - val_accuracy: 0.8511\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5454 - accuracy: 0.8723 - val_loss: 0.6568 - val_accuracy: 0.8477\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5391 - accuracy: 0.8734 - val_loss: 0.6476 - val_accuracy: 0.8432\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5457 - accuracy: 0.8726 - val_loss: 0.6529 - val_accuracy: 0.8402\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5423 - accuracy: 0.8726 - val_loss: 0.6444 - val_accuracy: 0.8468\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5468 - accuracy: 0.8731 - val_loss: 0.6861 - val_accuracy: 0.8316\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5450 - accuracy: 0.8712 - val_loss: 0.7029 - val_accuracy: 0.8336\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5390 - accuracy: 0.8747 - val_loss: 0.6763 - val_accuracy: 0.8419\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5406 - accuracy: 0.8730 - val_loss: 0.6480 - val_accuracy: 0.8466\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5358 - accuracy: 0.8744 - val_loss: 0.6354 - val_accuracy: 0.8502\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5361 - accuracy: 0.8751 - val_loss: 0.6370 - val_accuracy: 0.8561\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5286 - accuracy: 0.8765 - val_loss: 0.6394 - val_accuracy: 0.8532\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5336 - accuracy: 0.8775 - val_loss: 0.6440 - val_accuracy: 0.8478\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5326 - accuracy: 0.8770 - val_loss: 0.6740 - val_accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5290 - accuracy: 0.8774 - val_loss: 0.6345 - val_accuracy: 0.8505\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5336 - accuracy: 0.8771 - val_loss: 0.6594 - val_accuracy: 0.8483\n",
      "313/313 - 1s - loss: 0.6594 - accuracy: 0.8483\n",
      "Test accuracy: 0.8482999801635742\n",
      "NET  18\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.6319 - accuracy: 0.1716 - val_loss: 2.5156 - val_accuracy: 0.1844\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1261 - accuracy: 0.2931 - val_loss: 2.1561 - val_accuracy: 0.2881\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9646 - accuracy: 0.3464 - val_loss: 1.9128 - val_accuracy: 0.3686\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.8354 - accuracy: 0.3996 - val_loss: 1.7132 - val_accuracy: 0.4483\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.7057 - accuracy: 0.4542 - val_loss: 1.6433 - val_accuracy: 0.4724\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.6078 - accuracy: 0.4956 - val_loss: 1.5444 - val_accuracy: 0.5285\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.5078 - accuracy: 0.5418 - val_loss: 1.5066 - val_accuracy: 0.5422\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4251 - accuracy: 0.5752 - val_loss: 1.3575 - val_accuracy: 0.5808\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3430 - accuracy: 0.6018 - val_loss: 1.3080 - val_accuracy: 0.5969\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2788 - accuracy: 0.6202 - val_loss: 1.1689 - val_accuracy: 0.6585\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2129 - accuracy: 0.6435 - val_loss: 1.1370 - val_accuracy: 0.6627\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1726 - accuracy: 0.6581 - val_loss: 1.0961 - val_accuracy: 0.6730\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1223 - accuracy: 0.6707 - val_loss: 1.0588 - val_accuracy: 0.6963\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0828 - accuracy: 0.6865 - val_loss: 1.0449 - val_accuracy: 0.6939\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0489 - accuracy: 0.6948 - val_loss: 0.9647 - val_accuracy: 0.7267\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0224 - accuracy: 0.7040 - val_loss: 0.9586 - val_accuracy: 0.7197\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9908 - accuracy: 0.7128 - val_loss: 0.9345 - val_accuracy: 0.7229\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9616 - accuracy: 0.7240 - val_loss: 0.8872 - val_accuracy: 0.7454\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9340 - accuracy: 0.7354 - val_loss: 0.9057 - val_accuracy: 0.7418\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9082 - accuracy: 0.7400 - val_loss: 0.9512 - val_accuracy: 0.7192\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.8913 - accuracy: 0.7460 - val_loss: 0.8405 - val_accuracy: 0.7565\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8763 - accuracy: 0.7541 - val_loss: 0.8724 - val_accuracy: 0.7538\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8568 - accuracy: 0.7596 - val_loss: 0.8082 - val_accuracy: 0.7718\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8319 - accuracy: 0.7666 - val_loss: 0.7835 - val_accuracy: 0.7832\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8200 - accuracy: 0.7713 - val_loss: 0.7778 - val_accuracy: 0.7842\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.8058 - accuracy: 0.7787 - val_loss: 0.7924 - val_accuracy: 0.7739\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.7853 - accuracy: 0.7839 - val_loss: 0.7874 - val_accuracy: 0.7794\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7815 - accuracy: 0.7842 - val_loss: 0.7609 - val_accuracy: 0.7884\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7616 - accuracy: 0.7921 - val_loss: 0.7346 - val_accuracy: 0.7975\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7577 - accuracy: 0.7940 - val_loss: 0.7472 - val_accuracy: 0.7922\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7474 - accuracy: 0.7966 - val_loss: 0.7459 - val_accuracy: 0.7956\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7427 - accuracy: 0.7975 - val_loss: 0.7194 - val_accuracy: 0.8054\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7183 - accuracy: 0.8062 - val_loss: 0.7303 - val_accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7089 - accuracy: 0.8087 - val_loss: 0.7346 - val_accuracy: 0.8018\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7015 - accuracy: 0.8110 - val_loss: 0.6977 - val_accuracy: 0.8129\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.6974 - accuracy: 0.8151 - val_loss: 0.6844 - val_accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.6962 - accuracy: 0.8145 - val_loss: 0.7260 - val_accuracy: 0.8058\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.6860 - accuracy: 0.8178 - val_loss: 0.7300 - val_accuracy: 0.8010\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6819 - accuracy: 0.8186 - val_loss: 0.7399 - val_accuracy: 0.7987\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6730 - accuracy: 0.8225 - val_loss: 0.6961 - val_accuracy: 0.8155\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6583 - accuracy: 0.8268 - val_loss: 0.6914 - val_accuracy: 0.8136\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6583 - accuracy: 0.8292 - val_loss: 0.6981 - val_accuracy: 0.8134\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6564 - accuracy: 0.8261 - val_loss: 0.7125 - val_accuracy: 0.8030\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6478 - accuracy: 0.8312 - val_loss: 0.7216 - val_accuracy: 0.8076\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6460 - accuracy: 0.8304 - val_loss: 0.6791 - val_accuracy: 0.8257\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6428 - accuracy: 0.8362 - val_loss: 0.6498 - val_accuracy: 0.8295\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6381 - accuracy: 0.8351 - val_loss: 0.6502 - val_accuracy: 0.8265\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6275 - accuracy: 0.8359 - val_loss: 0.6888 - val_accuracy: 0.8241\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6344 - accuracy: 0.8346 - val_loss: 0.6772 - val_accuracy: 0.8206\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6300 - accuracy: 0.8382 - val_loss: 0.7431 - val_accuracy: 0.8096\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6286 - accuracy: 0.8378 - val_loss: 0.6539 - val_accuracy: 0.8322\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6219 - accuracy: 0.8415 - val_loss: 0.6864 - val_accuracy: 0.8278\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6196 - accuracy: 0.8411 - val_loss: 0.6925 - val_accuracy: 0.8289\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6091 - accuracy: 0.8443 - val_loss: 0.6813 - val_accuracy: 0.8279\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6110 - accuracy: 0.8428 - val_loss: 0.6847 - val_accuracy: 0.8244\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6116 - accuracy: 0.8461 - val_loss: 0.7418 - val_accuracy: 0.8079\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6062 - accuracy: 0.8494 - val_loss: 0.6530 - val_accuracy: 0.8357\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.5970 - accuracy: 0.8508 - val_loss: 0.6779 - val_accuracy: 0.8321\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6020 - accuracy: 0.8480 - val_loss: 0.6422 - val_accuracy: 0.8412\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.5939 - accuracy: 0.8520 - val_loss: 0.6500 - val_accuracy: 0.8372\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.5878 - accuracy: 0.8551 - val_loss: 0.6483 - val_accuracy: 0.8391\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5915 - accuracy: 0.8538 - val_loss: 0.6453 - val_accuracy: 0.8431\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5797 - accuracy: 0.8568 - val_loss: 0.6510 - val_accuracy: 0.8383\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5820 - accuracy: 0.8553 - val_loss: 0.6643 - val_accuracy: 0.8367\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5744 - accuracy: 0.8570 - val_loss: 0.6550 - val_accuracy: 0.8392\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5811 - accuracy: 0.8575 - val_loss: 0.6488 - val_accuracy: 0.8397\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5788 - accuracy: 0.8585 - val_loss: 0.6775 - val_accuracy: 0.8327\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5716 - accuracy: 0.8598 - val_loss: 0.6290 - val_accuracy: 0.8488\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5702 - accuracy: 0.8637 - val_loss: 0.6664 - val_accuracy: 0.8358\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5696 - accuracy: 0.8606 - val_loss: 0.6844 - val_accuracy: 0.8302\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5650 - accuracy: 0.8623 - val_loss: 0.6727 - val_accuracy: 0.8338\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5618 - accuracy: 0.8633 - val_loss: 0.6468 - val_accuracy: 0.8405\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5679 - accuracy: 0.8628 - val_loss: 0.6774 - val_accuracy: 0.8349\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5626 - accuracy: 0.8636 - val_loss: 0.6833 - val_accuracy: 0.8351\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5536 - accuracy: 0.8675 - val_loss: 0.6674 - val_accuracy: 0.8374\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5619 - accuracy: 0.8636 - val_loss: 0.6445 - val_accuracy: 0.8417\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5607 - accuracy: 0.8666 - val_loss: 0.6326 - val_accuracy: 0.8456\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5646 - accuracy: 0.8653 - val_loss: 0.6870 - val_accuracy: 0.8282\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5568 - accuracy: 0.8676 - val_loss: 0.6759 - val_accuracy: 0.8349\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5527 - accuracy: 0.8685 - val_loss: 0.6573 - val_accuracy: 0.8412\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5518 - accuracy: 0.8683 - val_loss: 0.6205 - val_accuracy: 0.8501\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5550 - accuracy: 0.8689 - val_loss: 0.6537 - val_accuracy: 0.8423\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5436 - accuracy: 0.8708 - val_loss: 0.6487 - val_accuracy: 0.8409\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5545 - accuracy: 0.8687 - val_loss: 0.6775 - val_accuracy: 0.8354\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5503 - accuracy: 0.8719 - val_loss: 0.6490 - val_accuracy: 0.8468\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5458 - accuracy: 0.8704 - val_loss: 0.6420 - val_accuracy: 0.8439\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5417 - accuracy: 0.8725 - val_loss: 0.6447 - val_accuracy: 0.8440\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5468 - accuracy: 0.8727 - val_loss: 0.6387 - val_accuracy: 0.8415\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5365 - accuracy: 0.8744 - val_loss: 0.6137 - val_accuracy: 0.8527\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5475 - accuracy: 0.8719 - val_loss: 0.6631 - val_accuracy: 0.8441\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5444 - accuracy: 0.8748 - val_loss: 0.6628 - val_accuracy: 0.8383\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5431 - accuracy: 0.8719 - val_loss: 0.6346 - val_accuracy: 0.8490\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5430 - accuracy: 0.8723 - val_loss: 0.6467 - val_accuracy: 0.8423\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5397 - accuracy: 0.8736 - val_loss: 0.6353 - val_accuracy: 0.8529\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5377 - accuracy: 0.8745 - val_loss: 0.6511 - val_accuracy: 0.8470\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5259 - accuracy: 0.8770 - val_loss: 0.6678 - val_accuracy: 0.8452\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5347 - accuracy: 0.8771 - val_loss: 0.6661 - val_accuracy: 0.8415\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5300 - accuracy: 0.8779 - val_loss: 0.6208 - val_accuracy: 0.8565\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5315 - accuracy: 0.8771 - val_loss: 0.6088 - val_accuracy: 0.8549\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5249 - accuracy: 0.8805 - val_loss: 0.6665 - val_accuracy: 0.8463\n",
      "313/313 - 1s - loss: 0.6665 - accuracy: 0.8463\n",
      "Test accuracy: 0.8463000059127808\n",
      "NET  19\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5951 - accuracy: 0.1566 - val_loss: 2.2541 - val_accuracy: 0.2160\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.1100 - accuracy: 0.2889 - val_loss: 1.9907 - val_accuracy: 0.3441\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.8756 - accuracy: 0.3865 - val_loss: 1.7124 - val_accuracy: 0.4625\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7116 - accuracy: 0.4567 - val_loss: 1.5237 - val_accuracy: 0.5260\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.5804 - accuracy: 0.5093 - val_loss: 1.4650 - val_accuracy: 0.5568\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.4796 - accuracy: 0.5514 - val_loss: 1.3696 - val_accuracy: 0.5794\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.3846 - accuracy: 0.5829 - val_loss: 1.2799 - val_accuracy: 0.6063\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.3071 - accuracy: 0.6088 - val_loss: 1.2325 - val_accuracy: 0.6350\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.2475 - accuracy: 0.6300 - val_loss: 1.1370 - val_accuracy: 0.6573\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.1956 - accuracy: 0.6465 - val_loss: 1.0727 - val_accuracy: 0.6791\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.1549 - accuracy: 0.6595 - val_loss: 1.0660 - val_accuracy: 0.6833\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1042 - accuracy: 0.6772 - val_loss: 1.0042 - val_accuracy: 0.7049\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.0671 - accuracy: 0.6880 - val_loss: 0.9807 - val_accuracy: 0.7094\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.0326 - accuracy: 0.7000 - val_loss: 0.9396 - val_accuracy: 0.7268\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0054 - accuracy: 0.7109 - val_loss: 1.0441 - val_accuracy: 0.6963\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 0.9778 - accuracy: 0.7166 - val_loss: 0.8956 - val_accuracy: 0.7402\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9537 - accuracy: 0.7244 - val_loss: 0.9198 - val_accuracy: 0.7374\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.9239 - accuracy: 0.7323 - val_loss: 0.8478 - val_accuracy: 0.7543\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9017 - accuracy: 0.7425 - val_loss: 0.8924 - val_accuracy: 0.7452\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.8826 - accuracy: 0.7491 - val_loss: 0.8537 - val_accuracy: 0.7568\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.8589 - accuracy: 0.7563 - val_loss: 0.8367 - val_accuracy: 0.7618\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8459 - accuracy: 0.7617 - val_loss: 0.8051 - val_accuracy: 0.7730\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8206 - accuracy: 0.7706 - val_loss: 0.7995 - val_accuracy: 0.7715\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8041 - accuracy: 0.7762 - val_loss: 0.7969 - val_accuracy: 0.7769\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.7946 - accuracy: 0.7771 - val_loss: 0.7775 - val_accuracy: 0.7805\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.7843 - accuracy: 0.7823 - val_loss: 0.7933 - val_accuracy: 0.7811\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.7630 - accuracy: 0.7876 - val_loss: 0.7306 - val_accuracy: 0.7924\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7560 - accuracy: 0.7931 - val_loss: 0.8110 - val_accuracy: 0.7711\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7471 - accuracy: 0.7956 - val_loss: 0.7861 - val_accuracy: 0.7834\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7418 - accuracy: 0.7985 - val_loss: 0.7297 - val_accuracy: 0.8017\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7221 - accuracy: 0.8026 - val_loss: 0.7243 - val_accuracy: 0.8038\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7220 - accuracy: 0.8061 - val_loss: 0.8436 - val_accuracy: 0.7701\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7014 - accuracy: 0.8127 - val_loss: 0.7205 - val_accuracy: 0.8085\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7016 - accuracy: 0.8155 - val_loss: 0.7179 - val_accuracy: 0.8097\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.6867 - accuracy: 0.8179 - val_loss: 0.7391 - val_accuracy: 0.8040\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.6938 - accuracy: 0.8161 - val_loss: 0.7018 - val_accuracy: 0.8143\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.6830 - accuracy: 0.8191 - val_loss: 0.7028 - val_accuracy: 0.8136\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.6711 - accuracy: 0.8246 - val_loss: 0.7051 - val_accuracy: 0.8127\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.6778 - accuracy: 0.8251 - val_loss: 0.6843 - val_accuracy: 0.8162\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.6589 - accuracy: 0.8295 - val_loss: 0.7088 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6562 - accuracy: 0.8299 - val_loss: 0.7070 - val_accuracy: 0.8120\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6502 - accuracy: 0.8305 - val_loss: 0.6758 - val_accuracy: 0.8275\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6476 - accuracy: 0.8319 - val_loss: 0.6973 - val_accuracy: 0.8201\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6423 - accuracy: 0.8346 - val_loss: 0.7329 - val_accuracy: 0.8127\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6495 - accuracy: 0.8335 - val_loss: 0.6736 - val_accuracy: 0.8278\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6313 - accuracy: 0.8386 - val_loss: 0.6847 - val_accuracy: 0.8262\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6307 - accuracy: 0.8397 - val_loss: 0.6913 - val_accuracy: 0.8237\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6260 - accuracy: 0.8423 - val_loss: 0.6947 - val_accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6251 - accuracy: 0.8431 - val_loss: 0.6960 - val_accuracy: 0.8249\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6206 - accuracy: 0.8448 - val_loss: 0.6665 - val_accuracy: 0.8322\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6120 - accuracy: 0.8493 - val_loss: 0.7041 - val_accuracy: 0.8248\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6141 - accuracy: 0.8470 - val_loss: 0.6676 - val_accuracy: 0.8325\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6147 - accuracy: 0.8471 - val_loss: 0.7035 - val_accuracy: 0.8334\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6080 - accuracy: 0.8498 - val_loss: 0.6876 - val_accuracy: 0.8288\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6002 - accuracy: 0.8527 - val_loss: 0.6801 - val_accuracy: 0.8356\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6025 - accuracy: 0.8515 - val_loss: 0.7432 - val_accuracy: 0.8146\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.5911 - accuracy: 0.8571 - val_loss: 0.6620 - val_accuracy: 0.8372\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.5861 - accuracy: 0.8561 - val_loss: 0.6884 - val_accuracy: 0.8299\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.5875 - accuracy: 0.8580 - val_loss: 0.7076 - val_accuracy: 0.8243\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.5917 - accuracy: 0.8559 - val_loss: 0.7167 - val_accuracy: 0.8207\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.5880 - accuracy: 0.8575 - val_loss: 0.6630 - val_accuracy: 0.8366\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.5825 - accuracy: 0.8587 - val_loss: 0.6488 - val_accuracy: 0.8421\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.5770 - accuracy: 0.8630 - val_loss: 0.7464 - val_accuracy: 0.8144\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.5841 - accuracy: 0.8595 - val_loss: 0.6719 - val_accuracy: 0.8372\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.5737 - accuracy: 0.8625 - val_loss: 0.6449 - val_accuracy: 0.8428\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.5751 - accuracy: 0.8607 - val_loss: 0.6785 - val_accuracy: 0.8351\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.5759 - accuracy: 0.8628 - val_loss: 0.6598 - val_accuracy: 0.8398\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.5757 - accuracy: 0.8621 - val_loss: 0.7194 - val_accuracy: 0.8293\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.5670 - accuracy: 0.8640 - val_loss: 0.6704 - val_accuracy: 0.8415\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.5681 - accuracy: 0.8659 - val_loss: 0.6699 - val_accuracy: 0.8362\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.5602 - accuracy: 0.8669 - val_loss: 0.6452 - val_accuracy: 0.8482\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.5603 - accuracy: 0.8656 - val_loss: 0.7538 - val_accuracy: 0.8195\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.5689 - accuracy: 0.8649 - val_loss: 0.7331 - val_accuracy: 0.8242\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.5556 - accuracy: 0.8684 - val_loss: 0.6449 - val_accuracy: 0.8474\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.5564 - accuracy: 0.8703 - val_loss: 0.6510 - val_accuracy: 0.8425\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.5493 - accuracy: 0.8718 - val_loss: 0.6313 - val_accuracy: 0.8524\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5564 - accuracy: 0.8689 - val_loss: 0.6514 - val_accuracy: 0.8446\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5523 - accuracy: 0.8713 - val_loss: 0.6438 - val_accuracy: 0.8478\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5497 - accuracy: 0.8712 - val_loss: 0.6396 - val_accuracy: 0.8512\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5558 - accuracy: 0.8698 - val_loss: 0.7167 - val_accuracy: 0.8344\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5640 - accuracy: 0.8702 - val_loss: 0.6563 - val_accuracy: 0.8418\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5467 - accuracy: 0.8732 - val_loss: 0.6351 - val_accuracy: 0.8506\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5414 - accuracy: 0.8746 - val_loss: 0.6665 - val_accuracy: 0.8425\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5426 - accuracy: 0.8731 - val_loss: 0.6662 - val_accuracy: 0.8443\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5433 - accuracy: 0.8749 - val_loss: 0.6552 - val_accuracy: 0.8487\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5362 - accuracy: 0.8777 - val_loss: 0.6727 - val_accuracy: 0.8403\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5489 - accuracy: 0.8722 - val_loss: 0.6541 - val_accuracy: 0.8438\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5376 - accuracy: 0.8775 - val_loss: 0.6551 - val_accuracy: 0.8454\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5432 - accuracy: 0.8758 - val_loss: 0.6447 - val_accuracy: 0.8522\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5347 - accuracy: 0.8768 - val_loss: 0.6401 - val_accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5351 - accuracy: 0.8776 - val_loss: 0.6778 - val_accuracy: 0.8422\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5424 - accuracy: 0.8771 - val_loss: 0.6355 - val_accuracy: 0.8488\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5337 - accuracy: 0.8801 - val_loss: 0.6497 - val_accuracy: 0.8475\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5288 - accuracy: 0.8795 - val_loss: 0.6971 - val_accuracy: 0.8421\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5315 - accuracy: 0.8794 - val_loss: 0.7001 - val_accuracy: 0.8375\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5279 - accuracy: 0.8813 - val_loss: 0.6524 - val_accuracy: 0.8532\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5270 - accuracy: 0.8817 - val_loss: 0.6724 - val_accuracy: 0.8502\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5263 - accuracy: 0.8823 - val_loss: 0.6559 - val_accuracy: 0.8519\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5337 - accuracy: 0.8791 - val_loss: 0.6728 - val_accuracy: 0.8448\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5271 - accuracy: 0.8826 - val_loss: 0.6609 - val_accuracy: 0.8496\n",
      "313/313 - 1s - loss: 0.6609 - accuracy: 0.8496\n",
      "Test accuracy: 0.8496000170707703\n",
      "NET  20\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.5118 - accuracy: 0.1961 - val_loss: 2.3759 - val_accuracy: 0.1986\n",
      "Epoch 2/100\n",
      "196/196 - 4s - loss: 2.0521 - accuracy: 0.3091 - val_loss: 2.1246 - val_accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "196/196 - 4s - loss: 1.9064 - accuracy: 0.3704 - val_loss: 1.8721 - val_accuracy: 0.4061\n",
      "Epoch 4/100\n",
      "196/196 - 4s - loss: 1.7779 - accuracy: 0.4253 - val_loss: 1.6232 - val_accuracy: 0.4968\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.6623 - accuracy: 0.4772 - val_loss: 1.5807 - val_accuracy: 0.5057\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.5525 - accuracy: 0.5195 - val_loss: 1.4928 - val_accuracy: 0.5487\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.4862 - accuracy: 0.5450 - val_loss: 1.4759 - val_accuracy: 0.5548\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.4076 - accuracy: 0.5691 - val_loss: 1.3202 - val_accuracy: 0.6084\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.3428 - accuracy: 0.5919 - val_loss: 1.2757 - val_accuracy: 0.6150\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.2968 - accuracy: 0.6060 - val_loss: 1.2338 - val_accuracy: 0.6229\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.2464 - accuracy: 0.6253 - val_loss: 1.1859 - val_accuracy: 0.6455\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.1992 - accuracy: 0.6374 - val_loss: 1.1488 - val_accuracy: 0.6453\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.1611 - accuracy: 0.6493 - val_loss: 1.1747 - val_accuracy: 0.6464\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 1.1199 - accuracy: 0.6625 - val_loss: 1.0300 - val_accuracy: 0.6893\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 1.0916 - accuracy: 0.6718 - val_loss: 1.0675 - val_accuracy: 0.6810\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 1.0575 - accuracy: 0.6793 - val_loss: 0.9563 - val_accuracy: 0.7149\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 1.0263 - accuracy: 0.6902 - val_loss: 1.0152 - val_accuracy: 0.6849\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 1.0031 - accuracy: 0.6980 - val_loss: 0.9993 - val_accuracy: 0.6925\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.9782 - accuracy: 0.7071 - val_loss: 0.9750 - val_accuracy: 0.7081\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.9626 - accuracy: 0.7146 - val_loss: 0.9070 - val_accuracy: 0.7208\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.9363 - accuracy: 0.7193 - val_loss: 0.8933 - val_accuracy: 0.7321\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.9173 - accuracy: 0.7282 - val_loss: 0.9433 - val_accuracy: 0.7177\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.9029 - accuracy: 0.7351 - val_loss: 0.8679 - val_accuracy: 0.7401\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8773 - accuracy: 0.7423 - val_loss: 0.8745 - val_accuracy: 0.7428\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8720 - accuracy: 0.7445 - val_loss: 0.8075 - val_accuracy: 0.7601\n",
      "Epoch 26/100\n",
      "196/196 - 5s - loss: 0.8505 - accuracy: 0.7511 - val_loss: 0.8207 - val_accuracy: 0.7589\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.8412 - accuracy: 0.7561 - val_loss: 0.8005 - val_accuracy: 0.7638\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.8254 - accuracy: 0.7597 - val_loss: 0.7753 - val_accuracy: 0.7797\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.8163 - accuracy: 0.7641 - val_loss: 0.8683 - val_accuracy: 0.7450\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7920 - accuracy: 0.7715 - val_loss: 0.7348 - val_accuracy: 0.7884\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7883 - accuracy: 0.7742 - val_loss: 0.7490 - val_accuracy: 0.7796\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7764 - accuracy: 0.7785 - val_loss: 0.7771 - val_accuracy: 0.7699\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7725 - accuracy: 0.7824 - val_loss: 0.7392 - val_accuracy: 0.7887\n",
      "Epoch 34/100\n",
      "196/196 - 4s - loss: 0.7594 - accuracy: 0.7830 - val_loss: 0.7457 - val_accuracy: 0.7903\n",
      "Epoch 35/100\n",
      "196/196 - 4s - loss: 0.7568 - accuracy: 0.7849 - val_loss: 0.7564 - val_accuracy: 0.7844\n",
      "Epoch 36/100\n",
      "196/196 - 4s - loss: 0.7472 - accuracy: 0.7881 - val_loss: 0.7223 - val_accuracy: 0.7954\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7339 - accuracy: 0.7942 - val_loss: 0.6911 - val_accuracy: 0.8060\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7343 - accuracy: 0.7957 - val_loss: 0.7299 - val_accuracy: 0.7951\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7259 - accuracy: 0.7976 - val_loss: 0.7449 - val_accuracy: 0.7931\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7162 - accuracy: 0.7994 - val_loss: 0.6923 - val_accuracy: 0.8025\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.7087 - accuracy: 0.8038 - val_loss: 0.7131 - val_accuracy: 0.8020\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.7075 - accuracy: 0.8062 - val_loss: 0.6930 - val_accuracy: 0.8014\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.7090 - accuracy: 0.8046 - val_loss: 0.7241 - val_accuracy: 0.7963\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6985 - accuracy: 0.8097 - val_loss: 0.6782 - val_accuracy: 0.8136\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6884 - accuracy: 0.8091 - val_loss: 0.6948 - val_accuracy: 0.8033\n",
      "Epoch 46/100\n",
      "196/196 - 4s - loss: 0.6832 - accuracy: 0.8125 - val_loss: 0.7423 - val_accuracy: 0.7974\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6837 - accuracy: 0.8129 - val_loss: 0.6804 - val_accuracy: 0.8131\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6675 - accuracy: 0.8178 - val_loss: 0.7067 - val_accuracy: 0.8092\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6764 - accuracy: 0.8186 - val_loss: 0.6766 - val_accuracy: 0.8154\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6686 - accuracy: 0.8185 - val_loss: 0.7005 - val_accuracy: 0.8068\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6626 - accuracy: 0.8220 - val_loss: 0.7574 - val_accuracy: 0.7973\n",
      "Epoch 52/100\n",
      "196/196 - 4s - loss: 0.6675 - accuracy: 0.8217 - val_loss: 0.6847 - val_accuracy: 0.8140\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6596 - accuracy: 0.8239 - val_loss: 0.7442 - val_accuracy: 0.7937\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6506 - accuracy: 0.8270 - val_loss: 0.6690 - val_accuracy: 0.8190\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6494 - accuracy: 0.8266 - val_loss: 0.7610 - val_accuracy: 0.7953\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6453 - accuracy: 0.8282 - val_loss: 0.6402 - val_accuracy: 0.8301\n",
      "Epoch 57/100\n",
      "196/196 - 4s - loss: 0.6449 - accuracy: 0.8293 - val_loss: 0.6474 - val_accuracy: 0.8259\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6372 - accuracy: 0.8312 - val_loss: 0.6998 - val_accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "196/196 - 4s - loss: 0.6343 - accuracy: 0.8327 - val_loss: 0.6569 - val_accuracy: 0.8265\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6375 - accuracy: 0.8305 - val_loss: 0.6622 - val_accuracy: 0.8213\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6298 - accuracy: 0.8339 - val_loss: 0.6610 - val_accuracy: 0.8233\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6282 - accuracy: 0.8352 - val_loss: 0.6429 - val_accuracy: 0.8327\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6269 - accuracy: 0.8350 - val_loss: 0.6438 - val_accuracy: 0.8331\n",
      "Epoch 64/100\n",
      "196/196 - 4s - loss: 0.6249 - accuracy: 0.8369 - val_loss: 0.6342 - val_accuracy: 0.8335\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6260 - accuracy: 0.8374 - val_loss: 0.6821 - val_accuracy: 0.8188\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6153 - accuracy: 0.8400 - val_loss: 0.6932 - val_accuracy: 0.8185\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6161 - accuracy: 0.8397 - val_loss: 0.6734 - val_accuracy: 0.8223\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6179 - accuracy: 0.8386 - val_loss: 0.6433 - val_accuracy: 0.8345\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6123 - accuracy: 0.8414 - val_loss: 0.6625 - val_accuracy: 0.8288\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6055 - accuracy: 0.8443 - val_loss: 0.6897 - val_accuracy: 0.8188\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.6045 - accuracy: 0.8446 - val_loss: 0.7583 - val_accuracy: 0.8050\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.6067 - accuracy: 0.8430 - val_loss: 0.7099 - val_accuracy: 0.8167\n",
      "Epoch 73/100\n",
      "196/196 - 4s - loss: 0.6034 - accuracy: 0.8450 - val_loss: 0.6520 - val_accuracy: 0.8289\n",
      "Epoch 74/100\n",
      "196/196 - 4s - loss: 0.6021 - accuracy: 0.8455 - val_loss: 0.6340 - val_accuracy: 0.8364\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.6059 - accuracy: 0.8443 - val_loss: 0.6953 - val_accuracy: 0.8220\n",
      "Epoch 76/100\n",
      "196/196 - 4s - loss: 0.6022 - accuracy: 0.8455 - val_loss: 0.6406 - val_accuracy: 0.8357\n",
      "Epoch 77/100\n",
      "196/196 - 4s - loss: 0.5910 - accuracy: 0.8495 - val_loss: 0.6550 - val_accuracy: 0.8302\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.5971 - accuracy: 0.8453 - val_loss: 0.6528 - val_accuracy: 0.8295\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.5924 - accuracy: 0.8478 - val_loss: 0.6672 - val_accuracy: 0.8278\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.5881 - accuracy: 0.8516 - val_loss: 0.6774 - val_accuracy: 0.8283\n",
      "Epoch 81/100\n",
      "196/196 - 4s - loss: 0.5900 - accuracy: 0.8505 - val_loss: 0.6541 - val_accuracy: 0.8301\n",
      "Epoch 82/100\n",
      "196/196 - 4s - loss: 0.5819 - accuracy: 0.8521 - val_loss: 0.6604 - val_accuracy: 0.8312\n",
      "Epoch 83/100\n",
      "196/196 - 4s - loss: 0.5875 - accuracy: 0.8508 - val_loss: 0.6829 - val_accuracy: 0.8216\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5878 - accuracy: 0.8509 - val_loss: 0.6455 - val_accuracy: 0.8385\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5836 - accuracy: 0.8525 - val_loss: 0.6687 - val_accuracy: 0.8265\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5851 - accuracy: 0.8527 - val_loss: 0.6399 - val_accuracy: 0.8343\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5783 - accuracy: 0.8548 - val_loss: 0.7157 - val_accuracy: 0.8118\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5796 - accuracy: 0.8555 - val_loss: 0.6818 - val_accuracy: 0.8238\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5795 - accuracy: 0.8547 - val_loss: 0.6392 - val_accuracy: 0.8400\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5800 - accuracy: 0.8552 - val_loss: 0.6856 - val_accuracy: 0.8303\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5705 - accuracy: 0.8574 - val_loss: 0.6355 - val_accuracy: 0.8379\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5773 - accuracy: 0.8546 - val_loss: 0.6847 - val_accuracy: 0.8281\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5750 - accuracy: 0.8540 - val_loss: 0.6608 - val_accuracy: 0.8296\n",
      "Epoch 94/100\n",
      "196/196 - 4s - loss: 0.5646 - accuracy: 0.8606 - val_loss: 0.6433 - val_accuracy: 0.8388\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5716 - accuracy: 0.8572 - val_loss: 0.7372 - val_accuracy: 0.8147\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5733 - accuracy: 0.8577 - val_loss: 0.6100 - val_accuracy: 0.8432\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5681 - accuracy: 0.8585 - val_loss: 0.6266 - val_accuracy: 0.8409\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5677 - accuracy: 0.8582 - val_loss: 0.6779 - val_accuracy: 0.8304\n",
      "Epoch 99/100\n",
      "196/196 - 4s - loss: 0.5673 - accuracy: 0.8571 - val_loss: 0.6170 - val_accuracy: 0.8442\n",
      "Epoch 100/100\n",
      "196/196 - 4s - loss: 0.5671 - accuracy: 0.8594 - val_loss: 0.6144 - val_accuracy: 0.8458\n",
      "313/313 - 1s - loss: 0.6144 - accuracy: 0.8458\n",
      "Test accuracy: 0.84579998254776\n"
     ]
    }
   ],
   "source": [
    "# (OPTIONAL) create data generator\n",
    "datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "history = [0] * NUM_NETS\n",
    "\n",
    "for j in range(NUM_NETS):\n",
    "        print('NET ', j+1)\n",
    "        history[j] = model[j].fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE), steps_per_epoch=len(x_train)//BATCH_SIZE,\n",
    "                                  epochs=EPOCHS, verbose=2, validation_data=(x_test,y_test))\n",
    "        # history[j] = model[j].fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2, validation_data=(x_test,y_test))\n",
    "        score = model[j].evaluate(x_test, y_test, verbose = VERBOSE)\n",
    "        print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history[0].history['accuracy'])\n",
    "plt.plot(history[0].history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## HAY un ERROR EN LA RED ANTERIOR ?\n",
    "## En este caso no llega a haber ninguna capa de tamaño impar,\n",
    "## con lo que el MaxPooling no tendrá problema\n",
    "\n",
    "## Red 845Kparámetros"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,305,002\n",
      "Trainable params: 1,304,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Alternativa más segura. con strides=2\n",
    "model = [0] * NUM_NETS\n",
    "\n",
    "for j in range(NUM_NETS):\n",
    "    model[j] = Sequential()\n",
    "    model[j].add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same', input_shape=(32, 32, 3)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, (3, 3), activation='relu', strides=2, kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.2))\n",
    "    model[j].add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Conv2D(64, (3, 3), activation='relu', strides=2, kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Dropout(0.3))\n",
    "    model[j].add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Conv2D(128, (3, 3), activation='relu', strides=2, kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Conv2D(256, (3, 3), activation='relu', strides=2, kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), padding='same'))\n",
    "    model[j].add(Dropout(0.5))\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)))\n",
    "    model[j].add(Dropout(0.5))\n",
    "    model[j].add(Dense(NUM_CLASES, activation='softmax'))\n",
    "\n",
    "    model[j].summary()\n",
    "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Los parametros en este caso son de nuevo 845K parámetros, los mismos\n",
    "## La duda es si aprenderá mejor."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET  1\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 1.7275 - accuracy: 0.3662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "313/313 - 0s - loss: 1.4087 - accuracy: 0.4895\n",
      "Test accuracy: 0.4894999861717224\n"
     ]
    }
   ],
   "source": [
    "history = [0] * NUM_NETS\n",
    "\n",
    "for j in range(NUM_NETS):\n",
    "        print('NET ', j+1)\n",
    "        history[j] = model[j].fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = 1, verbose = 1)\n",
    "        score = model[j].evaluate(x_test, y_test, verbose = VERBOSE)\n",
    "        print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET  1\n",
      "Epoch 1/100\n",
      "196/196 - 4s - loss: 2.2494 - accuracy: 0.2275 - val_loss: 2.0820 - val_accuracy: 0.3131\n",
      "Epoch 2/100\n",
      "196/196 - 3s - loss: 1.7961 - accuracy: 0.4114 - val_loss: 1.7974 - val_accuracy: 0.4109\n",
      "Epoch 3/100\n",
      "196/196 - 3s - loss: 1.6171 - accuracy: 0.4770 - val_loss: 1.4704 - val_accuracy: 0.5350\n",
      "Epoch 4/100\n",
      "196/196 - 3s - loss: 1.4970 - accuracy: 0.5247 - val_loss: 1.4168 - val_accuracy: 0.5586\n",
      "Epoch 5/100\n",
      "196/196 - 4s - loss: 1.3966 - accuracy: 0.5642 - val_loss: 1.3120 - val_accuracy: 0.5903\n",
      "Epoch 6/100\n",
      "196/196 - 4s - loss: 1.3221 - accuracy: 0.5917 - val_loss: 1.2184 - val_accuracy: 0.6231\n",
      "Epoch 7/100\n",
      "196/196 - 4s - loss: 1.2452 - accuracy: 0.6223 - val_loss: 1.1562 - val_accuracy: 0.6533\n",
      "Epoch 8/100\n",
      "196/196 - 4s - loss: 1.1973 - accuracy: 0.6396 - val_loss: 1.1563 - val_accuracy: 0.6535\n",
      "Epoch 9/100\n",
      "196/196 - 4s - loss: 1.1449 - accuracy: 0.6617 - val_loss: 1.1467 - val_accuracy: 0.6574\n",
      "Epoch 10/100\n",
      "196/196 - 4s - loss: 1.1073 - accuracy: 0.6794 - val_loss: 1.1089 - val_accuracy: 0.6765\n",
      "Epoch 11/100\n",
      "196/196 - 4s - loss: 1.0694 - accuracy: 0.6925 - val_loss: 1.0239 - val_accuracy: 0.7107\n",
      "Epoch 12/100\n",
      "196/196 - 4s - loss: 1.0292 - accuracy: 0.7088 - val_loss: 1.0467 - val_accuracy: 0.7063\n",
      "Epoch 13/100\n",
      "196/196 - 4s - loss: 1.0167 - accuracy: 0.7161 - val_loss: 0.9698 - val_accuracy: 0.7272\n",
      "Epoch 14/100\n",
      "196/196 - 4s - loss: 0.9819 - accuracy: 0.7299 - val_loss: 0.9941 - val_accuracy: 0.7224\n",
      "Epoch 15/100\n",
      "196/196 - 4s - loss: 0.9589 - accuracy: 0.7396 - val_loss: 0.9882 - val_accuracy: 0.7289\n",
      "Epoch 16/100\n",
      "196/196 - 4s - loss: 0.9391 - accuracy: 0.7473 - val_loss: 0.9589 - val_accuracy: 0.7381\n",
      "Epoch 17/100\n",
      "196/196 - 4s - loss: 0.9228 - accuracy: 0.7554 - val_loss: 0.9321 - val_accuracy: 0.7582\n",
      "Epoch 18/100\n",
      "196/196 - 4s - loss: 0.8926 - accuracy: 0.7662 - val_loss: 0.9477 - val_accuracy: 0.7533\n",
      "Epoch 19/100\n",
      "196/196 - 4s - loss: 0.8820 - accuracy: 0.7732 - val_loss: 0.9446 - val_accuracy: 0.7510\n",
      "Epoch 20/100\n",
      "196/196 - 4s - loss: 0.8699 - accuracy: 0.7782 - val_loss: 1.0038 - val_accuracy: 0.7488\n",
      "Epoch 21/100\n",
      "196/196 - 4s - loss: 0.8543 - accuracy: 0.7849 - val_loss: 0.9688 - val_accuracy: 0.7478\n",
      "Epoch 22/100\n",
      "196/196 - 4s - loss: 0.8327 - accuracy: 0.7928 - val_loss: 0.9309 - val_accuracy: 0.7653\n",
      "Epoch 23/100\n",
      "196/196 - 4s - loss: 0.8329 - accuracy: 0.7954 - val_loss: 0.9137 - val_accuracy: 0.7707\n",
      "Epoch 24/100\n",
      "196/196 - 4s - loss: 0.8152 - accuracy: 0.8020 - val_loss: 1.0608 - val_accuracy: 0.7265\n",
      "Epoch 25/100\n",
      "196/196 - 4s - loss: 0.8145 - accuracy: 0.8038 - val_loss: 0.8993 - val_accuracy: 0.7853\n",
      "Epoch 26/100\n",
      "196/196 - 4s - loss: 0.7923 - accuracy: 0.8098 - val_loss: 0.9060 - val_accuracy: 0.7815\n",
      "Epoch 27/100\n",
      "196/196 - 4s - loss: 0.7786 - accuracy: 0.8160 - val_loss: 0.9181 - val_accuracy: 0.7782\n",
      "Epoch 28/100\n",
      "196/196 - 4s - loss: 0.7805 - accuracy: 0.8180 - val_loss: 0.8684 - val_accuracy: 0.7925\n",
      "Epoch 29/100\n",
      "196/196 - 4s - loss: 0.7684 - accuracy: 0.8238 - val_loss: 0.9434 - val_accuracy: 0.7728\n",
      "Epoch 30/100\n",
      "196/196 - 4s - loss: 0.7630 - accuracy: 0.8248 - val_loss: 0.8785 - val_accuracy: 0.7953\n",
      "Epoch 31/100\n",
      "196/196 - 4s - loss: 0.7526 - accuracy: 0.8286 - val_loss: 0.9370 - val_accuracy: 0.7824\n",
      "Epoch 32/100\n",
      "196/196 - 4s - loss: 0.7387 - accuracy: 0.8353 - val_loss: 0.9102 - val_accuracy: 0.7901\n",
      "Epoch 33/100\n",
      "196/196 - 4s - loss: 0.7458 - accuracy: 0.8331 - val_loss: 0.8893 - val_accuracy: 0.8018\n",
      "Epoch 34/100\n",
      "196/196 - 3s - loss: 0.7334 - accuracy: 0.8382 - val_loss: 0.8632 - val_accuracy: 0.8011\n",
      "Epoch 35/100\n",
      "196/196 - 3s - loss: 0.7271 - accuracy: 0.8406 - val_loss: 0.9536 - val_accuracy: 0.7872\n",
      "Epoch 36/100\n",
      "196/196 - 3s - loss: 0.7244 - accuracy: 0.8420 - val_loss: 0.8639 - val_accuracy: 0.8032\n",
      "Epoch 37/100\n",
      "196/196 - 4s - loss: 0.7198 - accuracy: 0.8431 - val_loss: 0.8609 - val_accuracy: 0.8063\n",
      "Epoch 38/100\n",
      "196/196 - 4s - loss: 0.7019 - accuracy: 0.8504 - val_loss: 0.9026 - val_accuracy: 0.7985\n",
      "Epoch 39/100\n",
      "196/196 - 4s - loss: 0.7042 - accuracy: 0.8497 - val_loss: 0.8621 - val_accuracy: 0.8062\n",
      "Epoch 40/100\n",
      "196/196 - 4s - loss: 0.7022 - accuracy: 0.8512 - val_loss: 0.8970 - val_accuracy: 0.8009\n",
      "Epoch 41/100\n",
      "196/196 - 4s - loss: 0.6929 - accuracy: 0.8560 - val_loss: 0.9039 - val_accuracy: 0.7929\n",
      "Epoch 42/100\n",
      "196/196 - 4s - loss: 0.6924 - accuracy: 0.8566 - val_loss: 0.9104 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "196/196 - 4s - loss: 0.6921 - accuracy: 0.8569 - val_loss: 0.8999 - val_accuracy: 0.8038\n",
      "Epoch 44/100\n",
      "196/196 - 4s - loss: 0.6876 - accuracy: 0.8591 - val_loss: 0.9008 - val_accuracy: 0.8046\n",
      "Epoch 45/100\n",
      "196/196 - 4s - loss: 0.6732 - accuracy: 0.8647 - val_loss: 0.9122 - val_accuracy: 0.8014\n",
      "Epoch 46/100\n",
      "196/196 - 3s - loss: 0.6733 - accuracy: 0.8624 - val_loss: 0.8852 - val_accuracy: 0.8111\n",
      "Epoch 47/100\n",
      "196/196 - 4s - loss: 0.6706 - accuracy: 0.8658 - val_loss: 0.8947 - val_accuracy: 0.8104\n",
      "Epoch 48/100\n",
      "196/196 - 4s - loss: 0.6684 - accuracy: 0.8686 - val_loss: 0.9746 - val_accuracy: 0.7833\n",
      "Epoch 49/100\n",
      "196/196 - 4s - loss: 0.6644 - accuracy: 0.8677 - val_loss: 0.8764 - val_accuracy: 0.8141\n",
      "Epoch 50/100\n",
      "196/196 - 4s - loss: 0.6656 - accuracy: 0.8690 - val_loss: 0.9377 - val_accuracy: 0.7972\n",
      "Epoch 51/100\n",
      "196/196 - 4s - loss: 0.6578 - accuracy: 0.8744 - val_loss: 0.9081 - val_accuracy: 0.8044\n",
      "Epoch 52/100\n",
      "196/196 - 3s - loss: 0.6587 - accuracy: 0.8732 - val_loss: 0.8777 - val_accuracy: 0.8228\n",
      "Epoch 53/100\n",
      "196/196 - 4s - loss: 0.6542 - accuracy: 0.8754 - val_loss: 0.9014 - val_accuracy: 0.8072\n",
      "Epoch 54/100\n",
      "196/196 - 4s - loss: 0.6580 - accuracy: 0.8721 - val_loss: 0.9031 - val_accuracy: 0.8046\n",
      "Epoch 55/100\n",
      "196/196 - 4s - loss: 0.6483 - accuracy: 0.8778 - val_loss: 0.9158 - val_accuracy: 0.8119\n",
      "Epoch 56/100\n",
      "196/196 - 4s - loss: 0.6508 - accuracy: 0.8779 - val_loss: 0.8819 - val_accuracy: 0.8139\n",
      "Epoch 57/100\n",
      "196/196 - 3s - loss: 0.6468 - accuracy: 0.8787 - val_loss: 0.8869 - val_accuracy: 0.8142\n",
      "Epoch 58/100\n",
      "196/196 - 4s - loss: 0.6448 - accuracy: 0.8787 - val_loss: 0.8837 - val_accuracy: 0.8156\n",
      "Epoch 59/100\n",
      "196/196 - 3s - loss: 0.6447 - accuracy: 0.8793 - val_loss: 1.0255 - val_accuracy: 0.7882\n",
      "Epoch 60/100\n",
      "196/196 - 4s - loss: 0.6441 - accuracy: 0.8795 - val_loss: 0.8751 - val_accuracy: 0.8200\n",
      "Epoch 61/100\n",
      "196/196 - 4s - loss: 0.6423 - accuracy: 0.8817 - val_loss: 0.9133 - val_accuracy: 0.8118\n",
      "Epoch 62/100\n",
      "196/196 - 4s - loss: 0.6295 - accuracy: 0.8834 - val_loss: 1.0367 - val_accuracy: 0.7772\n",
      "Epoch 63/100\n",
      "196/196 - 4s - loss: 0.6353 - accuracy: 0.8844 - val_loss: 0.9352 - val_accuracy: 0.8084\n",
      "Epoch 64/100\n",
      "196/196 - 3s - loss: 0.6352 - accuracy: 0.8843 - val_loss: 0.8877 - val_accuracy: 0.8168\n",
      "Epoch 65/100\n",
      "196/196 - 4s - loss: 0.6250 - accuracy: 0.8864 - val_loss: 0.9047 - val_accuracy: 0.8155\n",
      "Epoch 66/100\n",
      "196/196 - 4s - loss: 0.6279 - accuracy: 0.8868 - val_loss: 0.9077 - val_accuracy: 0.8189\n",
      "Epoch 67/100\n",
      "196/196 - 4s - loss: 0.6263 - accuracy: 0.8865 - val_loss: 0.8859 - val_accuracy: 0.8249\n",
      "Epoch 68/100\n",
      "196/196 - 4s - loss: 0.6150 - accuracy: 0.8899 - val_loss: 0.8719 - val_accuracy: 0.8236\n",
      "Epoch 69/100\n",
      "196/196 - 4s - loss: 0.6171 - accuracy: 0.8913 - val_loss: 0.9225 - val_accuracy: 0.8113\n",
      "Epoch 70/100\n",
      "196/196 - 4s - loss: 0.6177 - accuracy: 0.8904 - val_loss: 0.8694 - val_accuracy: 0.8230\n",
      "Epoch 71/100\n",
      "196/196 - 4s - loss: 0.6164 - accuracy: 0.8901 - val_loss: 0.9287 - val_accuracy: 0.8075\n",
      "Epoch 72/100\n",
      "196/196 - 4s - loss: 0.6154 - accuracy: 0.8919 - val_loss: 0.8681 - val_accuracy: 0.8210\n",
      "Epoch 73/100\n",
      "196/196 - 3s - loss: 0.6129 - accuracy: 0.8932 - val_loss: 0.8780 - val_accuracy: 0.8274\n",
      "Epoch 74/100\n",
      "196/196 - 3s - loss: 0.6126 - accuracy: 0.8927 - val_loss: 0.8739 - val_accuracy: 0.8277\n",
      "Epoch 75/100\n",
      "196/196 - 4s - loss: 0.6172 - accuracy: 0.8924 - val_loss: 0.8647 - val_accuracy: 0.8249\n",
      "Epoch 76/100\n",
      "196/196 - 3s - loss: 0.6111 - accuracy: 0.8939 - val_loss: 0.8891 - val_accuracy: 0.8238\n",
      "Epoch 77/100\n",
      "196/196 - 3s - loss: 0.6160 - accuracy: 0.8945 - val_loss: 0.8717 - val_accuracy: 0.8270\n",
      "Epoch 78/100\n",
      "196/196 - 4s - loss: 0.6026 - accuracy: 0.8977 - val_loss: 0.9018 - val_accuracy: 0.8161\n",
      "Epoch 79/100\n",
      "196/196 - 4s - loss: 0.6067 - accuracy: 0.8968 - val_loss: 0.8867 - val_accuracy: 0.8296\n",
      "Epoch 80/100\n",
      "196/196 - 4s - loss: 0.6038 - accuracy: 0.8998 - val_loss: 0.9385 - val_accuracy: 0.8200\n",
      "Epoch 81/100\n",
      "196/196 - 3s - loss: 0.6085 - accuracy: 0.8961 - val_loss: 0.8699 - val_accuracy: 0.8303\n",
      "Epoch 82/100\n",
      "196/196 - 3s - loss: 0.5988 - accuracy: 0.9005 - val_loss: 0.9105 - val_accuracy: 0.8197\n",
      "Epoch 83/100\n",
      "196/196 - 3s - loss: 0.6019 - accuracy: 0.8977 - val_loss: 0.8831 - val_accuracy: 0.8266\n",
      "Epoch 84/100\n",
      "196/196 - 4s - loss: 0.5978 - accuracy: 0.8992 - val_loss: 0.8624 - val_accuracy: 0.8341\n",
      "Epoch 85/100\n",
      "196/196 - 4s - loss: 0.5967 - accuracy: 0.9007 - val_loss: 0.8708 - val_accuracy: 0.8304\n",
      "Epoch 86/100\n",
      "196/196 - 4s - loss: 0.5994 - accuracy: 0.8994 - val_loss: 0.9168 - val_accuracy: 0.8264\n",
      "Epoch 87/100\n",
      "196/196 - 4s - loss: 0.5996 - accuracy: 0.8992 - val_loss: 0.9280 - val_accuracy: 0.8167\n",
      "Epoch 88/100\n",
      "196/196 - 4s - loss: 0.5935 - accuracy: 0.9025 - val_loss: 0.9169 - val_accuracy: 0.8222\n",
      "Epoch 89/100\n",
      "196/196 - 4s - loss: 0.5936 - accuracy: 0.9035 - val_loss: 0.8570 - val_accuracy: 0.8329\n",
      "Epoch 90/100\n",
      "196/196 - 4s - loss: 0.5953 - accuracy: 0.9018 - val_loss: 0.9296 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "196/196 - 4s - loss: 0.5924 - accuracy: 0.9030 - val_loss: 0.9370 - val_accuracy: 0.8222\n",
      "Epoch 92/100\n",
      "196/196 - 4s - loss: 0.5948 - accuracy: 0.9024 - val_loss: 0.8965 - val_accuracy: 0.8265\n",
      "Epoch 93/100\n",
      "196/196 - 4s - loss: 0.5941 - accuracy: 0.9035 - val_loss: 0.8684 - val_accuracy: 0.8310\n",
      "Epoch 94/100\n",
      "196/196 - 3s - loss: 0.5895 - accuracy: 0.9033 - val_loss: 0.9039 - val_accuracy: 0.8253\n",
      "Epoch 95/100\n",
      "196/196 - 4s - loss: 0.5882 - accuracy: 0.9062 - val_loss: 0.8959 - val_accuracy: 0.8280\n",
      "Epoch 96/100\n",
      "196/196 - 4s - loss: 0.5895 - accuracy: 0.9051 - val_loss: 0.8808 - val_accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "196/196 - 4s - loss: 0.5827 - accuracy: 0.9094 - val_loss: 0.8729 - val_accuracy: 0.8325\n",
      "Epoch 98/100\n",
      "196/196 - 4s - loss: 0.5807 - accuracy: 0.9083 - val_loss: 0.9357 - val_accuracy: 0.8199\n",
      "Epoch 99/100\n",
      "196/196 - 3s - loss: 0.5896 - accuracy: 0.9050 - val_loss: 0.8843 - val_accuracy: 0.8335\n",
      "Epoch 100/100\n",
      "196/196 - 3s - loss: 0.5874 - accuracy: 0.9066 - val_loss: 0.9527 - val_accuracy: 0.8191\n",
      "313/313 - 1s - loss: 0.9527 - accuracy: 0.8191\n",
      "Test accuracy: 0.819100022315979\n"
     ]
    }
   ],
   "source": [
    "history = [0] * NUM_NETS\n",
    "\n",
    "for j in range(NUM_NETS):\n",
    "        print('NET ', j+1)\n",
    "        history[j] = model[j].fit(x_train, y_train, batch_size = BATCH_SIZE,\n",
    "                                  epochs = EPOCHS, verbose = 2, validation_data=(x_test,y_test))\n",
    "        score = model[j].evaluate(x_test, y_test, verbose = VERBOSE)\n",
    "        print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history[0].history['accuracy'])\n",
    "plt.plot(history[0].history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy NET  0 0.861\n",
      "Accuracy NET  1 0.8441\n",
      "Accuracy NET  2 0.8407\n",
      "Accuracy NET  3 0.8235\n",
      "Accuracy NET  4 0.8409\n",
      "Accuracy NET  5 0.8373\n",
      "Accuracy NET  6 0.8424\n",
      "Accuracy NET  7 0.8473\n",
      "Accuracy NET  8 0.8208\n",
      "Accuracy NET  9 0.8268\n",
      "Accuracy NET  10 0.8435\n",
      "Accuracy NET  11 0.8332\n",
      "Accuracy NET  12 0.8289\n",
      "Accuracy NET  13 0.8347\n",
      "Accuracy NET  14 0.8378\n",
      "Accuracy NET  15 0.8386\n",
      "Accuracy NET  16 0.8483\n",
      "Accuracy NET  17 0.8463\n",
      "Accuracy NET  18 0.8496\n",
      "Accuracy NET  19 0.8458\n"
     ]
    }
   ],
   "source": [
    "resultados = np.zeros((y_test.shape[0], NUM_CLASES))\n",
    "\n",
    "for j in range(NUM_NETS):\n",
    "        y_pred = model[j].predict(x_test)\n",
    "        resultados = resultados + y_pred\n",
    "# Reconvertimos la codificacion One Shot a una etiqueta de clase (0-9)\n",
    "        y_pred = np.argmax (y_pred, axis=1)\n",
    "        print ('Accuracy NET ', j, accuracy_score(yy_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Ensemble  0.8897\n"
     ]
    }
   ],
   "source": [
    "# La suma de salidas la reconvertimos de One Shot Encoding a la etiqueta de clase correspondiente (0-9)\n",
    "resultados = np.argmax(resultados, axis=1)\n",
    "print ('Accuracy Ensemble ', accuracy_score(yy_test, resultados))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7294 - accuracy: 0.8621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.7294270396232605, 0.8621000051498413]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "CLASSES = np.array(['airplane', 'automobile', 'bird',\n",
    "    'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "preds = model[0].predict(x_test)\n",
    "preds_single = CLASSES[np.argmax(preds, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x216 with 10 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.text(0.5, -0.7, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-37f62952",
   "language": "python",
   "display_name": "PyCharm (cancer_drug)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
